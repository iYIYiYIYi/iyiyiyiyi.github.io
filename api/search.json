[{"id":"622fbcd79d3811e5898cc0046d22e71d","title":"AlphaGenome：多分辨率基因组模型","content":"AbstractAlphaGenome 模型将长 DNA 序列作为输入（多达 100 万个字母，也称为碱基对），并预测其调控活动的数千种分子特性。它还可以通过比较变异序列和未变异序列的预测结果，对基因变异或突变的影响进行评分。\n预测的属性包括基因在不同细胞类型和组织中的起始和终止位置、基因的拼接位置、产生的 RNA 数量，以及哪些 DNA 碱基可被访问、相互靠近或被某些蛋白质结合。训练数据来自大型公共联盟，包括 ENCODE、GTEx、4D Nucleome 和 FANTOM5，它们通过实验测量了这些属性，涵盖了数百种人类和小鼠细胞类型和组织的重要基因调控模式。\nAlphaGenome 架构使用卷积层初步检测基因组序列中的简短模式，使用变换器在序列的所有位置传递信息，最后使用一系列层将检测到的模式转化为不同模式的预测结果。在训练过程中，针对单个序列的计算分布在多个相互连接的张量处理单元（TPU）上。\n该模型建立在 Enformer 的基础上，是对 AlphaMissense 的补充，后者专门对蛋白质编码区域内的变异影响进行分类。这些区域占基因组的 2%。剩下的 98% 被称为非编码区，对于协调基因活动至关重要，其中包含许多与疾病相关的变异。AlphaGenome 为解读这些广阔的序列及其中的变异提供了一个新的视角。\nModelAlphaGenome 模型使用编解码器结构，通过将碱基进行先升维再降维的方式进行特征提取。模型的主要组成部分为：\n\nDNA embedder\nDownres block\nTransformer tower\nUpres block\nOutput embedder\n\n\n升维(Downres)和降维(Upres)组件的基础单元均为1D卷积层。由于卷积网络对数据维度提升后会减少数据长度，因此被描述为分辨率降低(Downres)，反之为分辨率提升(Upres)。\n\n升维和降维组件的之间存在残差连接，保证在提升分辨率的过程中不会由于池化操作丢失信息。每一个升维组件都与对应的降维组件进行连接。\n\nTransformer tower是模型理解力的核心。 通过多个注意力机制组成的残差网络构建多个分辨率的输出。同时将原始的1D输入通过Pair update block提升至2D输出。\n\nDNA embedder是与Downres相似的卷积结构，在卷积核尺寸上存在差别。Output embedder将多个分辨率的输出混合增强后进行输出，由Dense网络组成。 \n\n此外，模型采用多头书簇合机制，每一个头由Dense网络组成，并添加了对上层输出的碱基互补链的处理。针对不同的下游任务，每一个输出头都有一个定制的损失函数进行训练。\n\nEvo2 &amp;&amp; AlphaGenome\n\n\n\nEvo 2\nAlphaGenome\n\n\n\n基础模型\nStripeHyena2\nCNN+Transformer+CNN+多输出头\n\n\n训练数据\nOpenGenome2, 包含真核生物和原核生物\n人类和老鼠的参考基因组以及注解\n\n\n训练方式\n预训练+微调\n预训练+蒸馏\n\n\n训练框架\nnvidia bionemo\nJAX+Haiku\n\n\n碱基分词方式\n单碱基分词\n单碱基分词\n\n\n最大序列长度\n1024， 8192\n1 Mbp\n\n\n","slug":"AlphaGenome：多分辨率基因组模型","date":"2025-11-13T07:02:30.000Z","categories_index":"机器学习,LLM","tags_index":"机器学习,人工智能","author_index":"ClaRn"},{"id":"a8520b94cebc535073bd27494d823aad","title":"DeepSeek-OCR：基于光学的文本数据压缩","content":"Abstract在DeepSeek3B-MoE-A570M作为解码器的基础上，设计了一个名为DeepEncoder的OCR编码器模型，通过2D光学映射的方式进行上下文的压缩。DeepEncoder编码得到的二维图像tokens比文本tokens少十倍以上，并且在压缩比为10时，解码的准确率可以达到97%；即使压缩比达到20+，解码的准确率依然有60%。\nVision EncoderDeepEncoder是基于ViT的视觉模型，其基础是由Meta提出的SAM(Segement Anything Model)。ViT(Vision Transformer) 是Transformer架构的图像变体，通过将图片切分成多个小的像素patch(44、55 …)组合成线性序列输入模型，从而解决Transformer只能处理一维序列数据的问题。\n\n在ViT的基础上所衍生出来的视觉编码器主要有两个主流模型，其一是由Meta所提出的SAM分割模型，该模型使用文本+分割+像素区域+物体识别的方法，可以通过文本从图像中准确地提取物体的像素边界。其二是由OpenAI所开发的CLIP模型，该模型的输入是图像，输出则是经过识别后的图像物体。\nVision LLMS在现有的支持视觉的大语言模型中，主要有三种主流的编码方案可以将图像编码并输入到LLM中。\n其一（Vary、DeepSeekVL、…）是通过多个不同分辨率的SAM编码器组成的混合编码器，这种方式支持多种预设分辨率图像，但是缺少对于极端分辨率图像的处理能力，同时由于编码器的复杂性，部署起来比较困难。\n第二种（InternVL、DeepSeekVL2、…）则是将图像进行分割，每一个子图独立处理并在LLM中进行整合，这种方式支持大分辨率图像，但是对图像的切分导致模型缺少对图像整体的理解，同时由于一张图被切分为多个tile，编码器会产生大量vision token。\n第三种方式（Qwen2、Qwen2.5、Qwen3、…）则是通过将图像进行切分后打包成长序列，并通过子图的原始位置对其进行顺序编码的方式既兼顾了大分辨率图像的处理问题，也考虑到了编码器对图像的全局视野问题。然而这种方式需要编码器支持更长的序列长度，并由此而导致了模型的推理效率低下的问题。\n\nDeepSeek-OCR ModelDeepSeek-OCR的核心DeepEncoder为了解决上述三种方案中存在的问题，提出了一种新的基于SAM分割模型以及CLIP图文模型的混合结构模型。在将输入图像切分为patches之后，DeepEncoder首先通过SAM模型对图像进行切分提取其中包含内容的区块，随后通过CLIP对分割后的区块进行描述，最后生成的文本将作为LLM的输入。\n随后，DeepEncoder编码得到的结果将通过LLM进行重建，将其恢复为文本内容，此时便完成了输入文档从图像到文本的变换。\n\nDeepEncoder的训练数据是通过HTML标注的，文档中的表格和图表会被转换为HTML表格标签，便于LLM在重建时进行图表内容的恢复。几何图形数据会被使用json进行描述保存，其中的顶点位置、边的位置、符号位置等均通过json进行结构化存储。\nModel Training模型的训练分为两个步骤：DeepEncoder的训练和DeepSeek-OCR的训练。\n\nDeepEncoder的训练:\n通过NTP的方式进行训练\n使用AdamW优化器以及余弦退火调度器\n训练序列长度为4096\n一共训练了2个epoch，batchsize设置为1280\n\n\nDeepSeek-OCR的训练\n使用管道并行的方式进行训练\n使用了20个节点，每个节点包括8张A100-40G\n\n\n\nConclusionDeepSeek-OCR通过DeepEncoder和LLM相结合的混合架构，实现了对扫描文档的光学压缩以及文本重建，并且保持了重建文本的高准确性。DeepEncoder有望在LLM的上下文压缩方向进行应用，实现LLM上下文长度的进一步拓展。同时，目前的DeepSeek-OCR也可以通过将扫描文档转换为文本文件的形式为LLM的训练生成训练数据，在单张A100-40G的GPU上生成速度可以达到20w页每天。\n","slug":"DeepSeek-OCR：基于光学的文本数据压缩","date":"2025-11-12T06:04:56.000Z","categories_index":"机器学习,LLM","tags_index":"机器学习,人工智能,大语言模型","author_index":"ClaRn"},{"id":"08cca76fff38d11f0fe80e9d5364700c","title":"基于EVO-2 的基因建模与设计","content":"IntroductionEvo 2 是一个生物基础模型，使用涵盖所有可观察的进化物种的代表性快照基因组数据进行训练。相比于特定任务的优化，Evo 2更强调通用能力，并且在从分子到基因组甚至到所有生命领域都具有健壮的预测和生成能力。\nModel Architectureevo2采用StripedHyena2作为基础模型，通过多层模型的堆叠增加参数量，包含7B和40B参数的两个版本。由于生物信息学数据的高噪声低语义特点，生物模型的设计一直以来存在难点，参数量更大的模型容易陷入噪声，参数量小的模型无法识别模式。StripedHyena2作为一种序列模型，相较Transformer的长序列建模能力更好。\n\nEvo2使用到了Sequence Packing的技术对训练进行加速。\nSequence Packing序列模型中的序列长度不一致问题导致padding对齐需要产生额外的计算消耗。Sequence Packing即把多个样本或序列拼在一起。拼接后可以减少数据处理的条数，同时减少序列中pad的数目从而减少计算消耗。\n拼接算法通常使用NNLSHP （Non-Negative Least Squares Histogram Packing），该算法以数据长度的直方图为基础，选择直方图中相邻的N个符合Pack大小的长度的数据合并。由于直方图记录了数据的原始信息，因此也可以将数据还原到原来的长度。\nTrainingEvo2分为两个阶段进行训练：预训练（Pretrain）和中期训练（Midtrain），其中训练数据包含DNA序列和RNA序列。\nPretrain阶段采用NTP的方式进行训练，一共使用到了6.6T个碱基的数据，其中重复出现的碱基片段通过归一化因子降低对模型的影响。预训练阶段使用8192的上下文长度进行训练，其中40B版本的模型先使用1024的上下文长度对模型进行预热，随后将上下文窗口拓展到8192个碱基。\nMidtrain阶段是为了拓展模型的上下文而设计的，通过旋转位置编码（RoPE）和缩小位置索引对token位置进行插值的方法对上下文长度进行进一步的拓展。\n","slug":"基于EVO-2-的基因建模与设计","date":"2025-02-25T07:50:36.000Z","categories_index":"机器学习,LLM","tags_index":"机器学习,人工智能,大语言模型","author_index":"ClaRn"},{"id":"d9c45824ce239536b406f9198691a48a","title":"LLM的微调方法","content":"Supervised Fine-Tuning | 监督微调监督微调是大模型微调的常用技术，是通过使用带标签的数据集来微调预训练模型的方法，用于特定任务下的应用。\n预训练模型通常在无监督数据集上训练，以NTP形式的LLM为例，预训练的过程中只会输入大量文本让模型进行预测，从而提高模型对于语言的基本结构和语义的了解。\n在SFT的过程中，需要使用特定任务的标注数据集对模型进行训练，这些数据集会包含输入和对应的输出标签。从而达到优化模型在特定任务上的表现的目的。\n常见的监督微调方法包括全参微调、部分参数微调(LoRA)、冻结监督微调等。\n全参微调全参微调意即将模型的全部参数都纳入梯度计算，这种方式的效果最佳，但需要的算力与模型的预训练相当。\n部分参数微调部分参数微调通过只调整一部分参数进行模型的调整。\nLow-Rank AdaptionLoRA 通过引入一个低秩分解的矩阵，将原始的密集参数矩阵分解为两个低秩矩阵的乘积，从而大幅减少微调过程的参数量。\nAghajanyan的研究表明：预训练模型拥有极小的内在维度(instrisic dimension)，即存在一个极低维度的参数，微调它和在全参数空间中微调能起到相同的效果。同时在预训练后，越大的模型有越小的内在维度，这也解释了为何大模型都拥有很好的few-shot能力。因此LoRA的作者也认为，参数更新的过程也存在一个‘内在秩’，对于预训练权重矩阵，有：其中以及\n训练过程中冻结参数，仅训练和里面的参数，则如图所示，对于，前向传播变为：\n\nTransformer最核心的参数矩阵有三个：，LoRA应用到多个参数举证时的效果更好，如下表所示：\n当作用到多个参数矩阵时，即使内在秩为2也可以保证模型微调得到不错的效果。\n在训练过程中，低秩的适应矩阵仅仅放大了对下游任务有用的特征，而不是预训练模型中的主要特征。\nQuantized Low-Rank AdaptionQLoRA 是LoRA的量化版本，它通过将模型的权重量化为低精度格式从而减少内存需求。\nQLoRA 的主要思路包括以下几点：\n\n量化模型：将原始模型的权重量化为更低的数值精度（例如 4 位浮点数，FP4），显著减少内存占用。\n冻结量化权重：微调过程中，模型的量化权重保持冻结，不会更新。\n使用 LoRA 进行适配：在模型的线性层中引入 LoRA 模块（低秩矩阵），微调这些模块来适配下游任务。\n\n冻结参数微调冻结参数的核心是设置模型参数的requires_grad为False\n使用Transformers库对bert进行冻结参数的LoRA微调pythonfrom transformers import AutoTokenizer, AutoModelForCausalLM, LoraConfig, get_peft_model\nfrom peft import TaskType\n\n# 加载预训练模型和分词器\ntokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\nmodel = AutoModelForCausalLM.from_pretrained(\"bert-base-uncased\")\n\n# 冻结模型的所有参数\nfor param in model.parameters():\n    param.requires_grad = False\n\n# 配置 LoRA\nconfig = LoraConfig(\n    task_type=TaskType.CAUSAL_LM,  # 任务类型\n    target_modules=\".*query_key_value\",  # 目标模块\n    modules_to_save=[\"word_embeddings\"]  # 需要保存的模块\n)\n\n# 获取 LoRA 模型\nmodel = get_peft_model(model, config)\n\n# 打印可训练参数\nmodel.print_trainable_parameters()\n\n# 微调模型（假设已有训练代码）\n# trainer.train()使用Pytorch对ResNet18进行冻结参数微调pythonimport torch\nimport torch.nn as nn\nimport torchvision.models as models\n\n# 加载预训练的 ResNet18 模型\nmodel = models.resnet18(pretrained=True)\n\n# 冻结所有参数\nfor param in model.parameters():\n    param.requires_grad = False\n\n# 替换最后一层（全连接层）\nmodel.fc = nn.Linear(model.fc.in_features, 4)  # 假设我们有 4 个分类\n\n# 打印可训练参数\nfor name, param in model.named_parameters():\n    if param.requires_grad:\n        print(name)  # 只会打印最后一层的参数\n\n# 定义损失函数和优化器\ncriterion = nn.CrossEntropyLoss()\noptimizer = torch.optim.Adam(model.fc.parameters(), lr=0.001)\n\n# 微调模型（假设已有训练代码）\n# for inputs, labels in dataloader:\n#     outputs = model(inputs)\n#     loss = criterion(outputs, labels)\n#     optimizer.zero_grad()\n#     loss.backward()\n#     optimizer.step()Reinforcement Learning from Human Feedback | 以强化学习方式依据人类反馈优化语言模型RLHF 的思想：使用强化学习的方式直接优化带有人类反馈的语言模型。RLHF 使得在一般文本数据语料库上训练的语言模型能和复杂的人类价值观对齐。\nRLHF设计了多个模型和不同训练阶段，主要可以分解为三个步骤：\n\n预训练一个语言模型\n聚合问答数据并训练一个奖励模型\n用强化学习方式微调语言模型\n\n这三个步骤的实施可查看HuggingFace 关于RLHF的技术博客，不同的模型厂商对于实现的方式基本大同小异，数据的组织和处理方式不同也让模型性能产生了一些区别。\n","slug":"LLM的微调方法","date":"2025-02-10T18:26:30.000Z","categories_index":"机器学习,LLM","tags_index":"机器学习,人工智能,大语言模型","author_index":"ClaRn"},{"id":"964e6c226f117edbf258c81184a470c0","title":"聚类作业","content":"\n\n\n\n\n\nTIP\n1、K均值聚类给定8个数据点：。使用K=2 执行K均值聚类，将8个点分组到簇C1和C2。初始化簇中心分别为A1和A2。\n\n\n一次K均值聚类迭代后C1和C2的成员点是什么？初始化簇中心为A1和A2，计算不同数据点到A1和A2的距离有：各个数据点到A1的距离为:\n\ntxtD1 = 0.00\nD2 = 5.00\nD3 = 8.49\nD4 = 3.61\nD5 = 7.07\nD6 = 7.21\nD7 = 8.06\nD8 = 2.24各个数据点到A2的距离为：\ntxtD1 = 5.00\nD2 = 0.00\nD3 = 6.08\nD4 = 4.24\nD5 = 5.00\nD6 = 4.12\nD7 = 3.16\nD8 = 4.47故可以将数据点划分为两类：可得到类的成员点为：，类的成员点为：\n\n第二次K均值聚类迭代后C1和C2的成员点是什么？各个数据点到的距离为:\n\ntxtD1 = 1.94\nD2 = 4.33\nD3 = 6.62\nD4 = 1.67\nD5 = 5.21\nD6 = 5.52\nD7 = 7.49\nD8 = 0.33各个数据点到的距离为：\ntxtD1 = 6.62\nD2 = 2.97\nD3 = 3.20\nD4 = 4.00\nD5 = 2.42\nD6 = 1.20\nD7 = 4.29\nD8 = 5.06故可以将数据点划分为两类：可得到类的成员点为：，类的成员点为：\n\n\n\n\n\n\nTIP\n2、使用内部评价指标：轮廓系数（Silhouette Coefficient）评估第1题中K均值聚类结果。在单个样本层面、簇层面和整体层面，轮廓系数值高意味着什么？第1题中K均值聚类结果的轮廓系数是多少？\n\n在轮廓系数的不同层面（单个样本、簇层面和整体层面）上，高轮廓系数值通常表示以下情况：\n\n单个样本层面：\n\n对于单个样本，轮廓系数值高表示该样本与其所在簇内的其他样本距离较近，簇内紧密度高。\n\n\n簇层面：\n\n在簇层面上，高轮廓系数意味着簇内样本之间的平均距离相对较小，簇内紧密度高，即簇内的数据点更趋向于彼此接近，形成了紧凑的簇。\n\n\n整体层面：\n\n在整体层面上，高轮廓系数表示簇间的分离度相对较大，不同簇之间的距离较远，簇与簇之间的分离度好。\n\n\n\n总的来说，高轮廓系数值表明了一个比较好的聚类结果，其中簇内的数据点相对紧密，并且不同簇之间相互分离，这说明聚类结果较为理想。\n第一问中的分类为：\n在簇内，不同样本到其它样本之间距离的平均值为：因此内样本间平均距离为：\n在簇内，不同样本到其它样本之间距离的平均值为：因此内样本间平均距离为：\n样本到样本的簇间分离度为：因此类别到类别的平均簇间分离度为\n样本到样本的簇间分离度为：因此类别到类别的平均簇间分离度为\n对A中的样本计算轮廓系数得：故A的轮廓系数\n\n\n\n\n\n\nTIP\n3、下图给出了6个数据集A、B、C、D、E、F用两种聚类算法得到的聚类结果，已知其中一种聚类算法是K均值聚类。请问对每个数据集，哪个最可能是K均值聚类的结果。如果K均值聚类结果不够理想，对每个数据集，你建议采用哪种聚类算法？\n\nK均值聚类的结果有：A2, B2, C1, D1, E2, F2\nK均值聚类结果不够理想的数据集有：A, B, D, F\n\n对于A: 可以使用最小距离层次聚类\n对于B、D: 可以使用基于密度的聚类\n对于F: 可以使用高斯混合模型进行聚类\n\n","slug":"聚类作业","date":"2023-12-25T21:35:50.000Z","categories_index":"基础,机器学习,作业","tags_index":"机器学习,作业,模式识别","author_index":"ClaRn"},{"id":"07d230dc9f28974a326d4fc65ffb6691","title":"算法设计与分析-课后练习29","content":"课后练习29\n\n\npythonS = [3, 7, 5, 9]\nC = 20\nepsilon = 0.2pythondelta = epsilon / len(S)\nprint(&quot;δ = %.2f&quot; % delta)txtδ = 0.05pythonL0 = &#123;0&#125;\n\ndef add_set_num(s, n):\n    d = []\n    for item in s:\n        d.append(item+n)\n    return set(d)\n\nprint(&#39;L_%d = %s&#39; %(0, str(L0)))\ncounter = 0\nlast_set = L0\nfor i in S:\n    counter += 1\n    append_set = add_set_num(last_set, i)\n    l_set:set = append_set | last_set\n    print(&#39;L_%d = L_%d ∪ (L_%d + %d) = %s ∪ %s = %s&#39; \n        % (counter, counter-1, counter-1, i, last_set, append_set, l_set))\n    \n    for j in l_set:\n        if j != i:\n            if j * (1-delta) &lt;= i &lt;= j or j &gt; C:\n                continue\n        last_set.add(j)\n            \n    print(&#39;修正后 L_%d = %s&#39; % (counter, last_set))\n\n\n\n\n\n\n\n\nL_0 &#x3D; {0}L_1 &#x3D; L_0 ∪ (L_0 + 3) &#x3D; {0} ∪ {3} &#x3D; {0, 3}修正后 L_1 &#x3D; {0, 3}L_2 &#x3D; L_1 ∪ (L_1 + 7) &#x3D; {0, 3} ∪ {10, 7} &#x3D; {0, 10, 3, 7}修正后 L_2 &#x3D; {0, 10, 3, 7}L_3 &#x3D; L_2 ∪ (L_2 + 5) &#x3D; {0, 10, 3, 7} ∪ {8, 12, 5, 15} &#x3D; {0, 3, 5, 7, 8, 10, 12, 15}修正后 L_3 &#x3D; {0, 3, 5, 7, 8, 10, 12, 15}L_4 &#x3D; L_3 ∪ (L_3 + 9) &#x3D; {0, 3, 5, 7, 8, 10, 12, 15} ∪ {9, 12, 14, 16, 17, 19, 21, 24} &#x3D; {0, 3, 5, 7, 8, 9, 10, 12, 14, 15, 16, 17, 19, 21, 24}修正后 L_4 &#x3D; {0, 3, 5, 7, 8, 9, 10, 12, 14, 15, 16, 17, 19}\npythonmax_sum = max(last_set)\nprint(&#39;通过近似算法求解得到的最大子集和为 %d&#39; % max_sum)\n\n\n\n\n\n\n\n\n通过近似算法求解得到的最大子集和为 19\n","slug":"算法设计与分析-课后练习29","date":"2023-12-21T23:36:21.000Z","categories_index":"基础,作业,算法","tags_index":"作业,算法","author_index":"ClaRn"},{"id":"f4283db30cf0b3e79615d34f84d967a7","title":"算法设计与分析-课后练习24","content":"课后练习24\n\n\npythonn = 5\np = [6, 3, 4, 8, 5]\nt = [2, 1, 2, 1, 1]\nd = [3, 1, 4, 2, 4]pythonfrom queue import Queue\n\ndef calculate_penalty(schedule, processing_times, deadlines, penalties):\n    time, total_penalty = 0, 0\n    for job in schedule:\n        time += processing_times[job]\n        if time &gt; deadlines[job]:\n            total_penalty += penalties[job]\n    return total_penalty\n\ndef fifo_branch_and_bound(n, processing_times, deadlines, penalties):\n    best_schedule = None\n    min_penalty = float(&#39;inf&#39;)\n    mermaid_code = [&#39;graph TD\\n&#39;]\n    mermaid_nodes = &#123;&#125;\n\n    q = Queue()\n    q.put([])\n    mermaid_nodes[str([])] = &#39;node%d%s&#39; % (len(mermaid_nodes), &#39;root&#39;)\n\n    while not q.empty():\n        schedule = q.get()\n        if len(schedule) == n:\n            penalty = calculate_penalty(schedule, processing_times, deadlines, penalties)\n            if penalty &lt; min_penalty:\n                min_penalty = penalty\n                best_schedule = list(schedule)\n        else:\n            for job in range(n):\n                if job not in schedule:\n                    new_schedule = list(schedule) + [job]\n                    if calculate_penalty(new_schedule, processing_times, deadlines, penalties) &lt;= min_penalty:\n                        q.put(new_schedule)\n                        mermaid_nodes[str(new_schedule)] = &#39;node%d%s&#39; % (len(mermaid_nodes), str(new_schedule))\n                        mermaid_code.append(&#39;   %s --&gt; %s\\n&#39; % (mermaid_nodes[str(schedule)], mermaid_nodes[str(new_schedule)]))\n\n    return best_schedule, min_penalty, mermaid_code\n\nbest_schedule, min_penalty, mermaid_code = fifo_branch_and_bound(n, t, d, p)pythonbest_schedule = [job + 1 for job in best_schedule]\nbest_schedule, min_penaltytxt([4, 1, 5, 2, 3], 7)故可知最优解的罚款值为 7，生成的状态空间树如下：\n\npythonimport heapq\n\ndef lc_branch_and_bound(n, processing_times, deadlines, penalties):\n    best_schedule = None\n    min_penalty = float(&#39;inf&#39;)\n    mermaid_code = [&#39;graph TD\\n&#39;]\n    mermaid_nodes = &#123;&#125;\n\n    # Priority queue: (penalty, schedule)\n    pq = []\n    heapq.heappush(pq, (0, []))\n    mermaid_nodes[str([])] = &#39;node%d%s&#39; % (len(mermaid_nodes), &#39;[root]&#39;)\n\n    while pq:\n        penalty, schedule = heapq.heappop(pq)\n        if len(schedule) == n:\n            if penalty &lt; min_penalty:\n                min_penalty = penalty\n                best_schedule = list(schedule)\n        else:\n            for job in range(n):\n                if job not in schedule:\n                    new_schedule = list(schedule) + [job]\n                    new_penalty = calculate_penalty(new_schedule, processing_times, deadlines, penalties)\n                    if new_penalty &lt;= min_penalty:\n                        heapq.heappush(pq, (new_penalty, new_schedule))\n                        mermaid_nodes[str(new_schedule)] = &#39;node%d%s&#39; % (len(mermaid_nodes), str(new_schedule))\n                        mermaid_code.append(&#39;   %s --&gt; %s\\n&#39; % (mermaid_nodes[str(schedule)], mermaid_nodes[str(new_schedule)]))\n\n    return best_schedule, min_penalty\n\nbest_schedule, min_penalty = lc_branch_and_bound(n, t, d, p)pythonbest_schedule = [job + 1 for job in best_schedule]\nbest_schedule, min_penaltytxt([4, 1, 5, 2, 3], 7)\n","slug":"算法设计与分析-课后练习24","date":"2023-12-20T06:06:33.000Z","categories_index":"基础,作业,算法","tags_index":"作业,算法","author_index":"ClaRn"},{"id":"c73a84f87e472429cf15dcccccb6900d","title":"算法设计与分析-课后练习25","content":"课后练习25\n\n使用LC分支界限法解0-1背包问题\npythonN = 5\nM = 12\np = [10, 15, 6, 8, 4]\nw = [4, 6, 3, 4, 2]pythondef calc_w_and_p(solution, p, w):\n    total_p = 0\n    total_w = 0\n    for item in solution:\n        total_w += w[item-1]\n        total_p += p[item-1]\n    \n    return total_w, total_ppythonfrom queue import Queue\n\ndef lcbb(N, M, p, w):\n    best_solution = None\n    best_p = 0\n    best_w = 0\n    q = Queue()\n    mermaid_code = [&#39;graph TD\\n&#39;]\n    mermaid_node = &#123; &#39;[]&#39;:&#39;root&#39; &#125;\n    \n    q.put([])\n    while not q.empty():\n        solution = q.get()\n        total_w, total_p = calc_w_and_p(solution, p, w)\n        if total_w &lt;= M:\n            if len(solution) &lt; N:\n                for i in range(N):\n                    if i+1 not in solution:\n                        new_solution = solution + [i+1]\n                        new_w, new_p = calc_w_and_p(new_solution, p, w)\n                        if new_w &lt;= M and new_p &gt; best_p and new_p &gt; total_p: \n                            q.put(new_solution)\n                            mermaid_node[str(new_solution)] = &#39;node%d%s&#39; % (len(mermaid_node), str(new_solution))\n                            mermaid_code.append(&#39;    %s --&gt; %s\\n&#39; % (mermaid_node[str(solution)], mermaid_node[str(new_solution)]))\n            \n            if best_p &lt; total_p:\n                best_p = total_p\n                best_w = total_w\n                best_solution = solution\n    \n    return best_solution, best_p, best_w, mermaid_code\n\nbest_solution, best_p, best_w, mermaid_code_lcbb = lcbb(N, M, p, w)pythonprint(&#39;最高效益值为：%d，对应的物品为：%s，占用背包空间：%d&#39; %(best_p, best_solution, best_w))txt最高效益值为：29，对应的物品为：[1, 2, 5]，占用背包空间：12得到的状态空间树如下：\n\n使用FIFO分支界限法解0-1背包问题\npythonN = 5\nM = 15\np = [4, 4, 5, 8, 9]\nw = [4, 4, 5, 8, 9]pythondef fifobb(N, M, p, w):\n    best_solution = None\n    best_p = 0\n    best_w = 0\n    q = Queue()\n    mermaid_code = [&#39;graph TD\\n&#39;]\n    mermaid_node = &#123; &#39;[]&#39;:&#39;root&#39; &#125;\n    \n    q.put([])\n    while not q.empty():\n        solution = q.get()\n        total_w, total_p = calc_w_and_p(solution, p, w)\n        if total_w &lt;= M:\n            if len(solution) &lt; N:\n                for i in range(N):\n                    if i+1 not in solution:\n                        new_solution = solution + [i+1]\n                        new_w, new_p = calc_w_and_p(new_solution, p, w)\n                        if new_w &lt;= M:\n                            q.put(new_solution)\n                            mermaid_node[str(new_solution)] = &#39;node%d%s&#39; % (len(mermaid_node), str(new_solution))\n                            mermaid_code.append(&#39;    %s --&gt; %s\\n&#39; % (mermaid_node[str(solution)], mermaid_node[str(new_solution)]))\n            \n            if best_p &lt; total_p:\n                best_p = total_p\n                best_w = total_w\n                best_solution = solution\n    \n    return best_solution, best_p, best_w, mermaid_code\n\nbest_solution, best_p, best_w, mermaid_code_fifobb = fifobb(N, M, p, w)pythonprint(&#39;最高效益值为：%d，对应的物品为：%s，占用背包空间：%d&#39; %(best_p, best_solution, best_w))txt最高效益值为：14，对应的物品为：[3, 5]，占用背包空间：14得到的状态空间树如下：\n\n","slug":"算法设计与分析-课后练习25","date":"2023-12-20T06:05:43.000Z","categories_index":"基础,作业,算法","tags_index":"作业,算法","author_index":"ClaRn"},{"id":"453b2b48be068910dc7d607886c05ba1","title":"算法设计与分析-课后练习26","content":"课后练习26\npythoninf = 5000pythondef calc_cost(path, graph):\n    cost = 0\n    last_node = -1\n    for i in path:\n        if last_node != -1:\n            cost += graph[last_node][i]\n        last_node = i\n    \n    return costpythonfrom queue import Queue\n\ndef shortest_path(graph):\n    q = Queue()\n    shortest_cost = inf\n    shortest_road = []\n    \n    q.put([1])\n    while not q.empty():\n        path = q.get()\n        \n        destination = path[-1]\n        if destination == len(graph)-1:\n            cost = calc_cost(path, graph)\n            if shortest_cost &gt; cost:\n                shortest_road = path\n                shortest_cost = cost\n        else:\n            adjusts = graph[destination]\n            for next_node in range(2, len(adjusts)):\n                if adjusts[next_node] != 0 and adjusts[next_node] &lt; inf and next_node not in path:\n                    new_road = path + [next_node]\n                    q.put(new_road)\n                    \n    return shortest_road, shortest_cost第一组测试数据\npythonsample_graph1 = [\n    [0, 0, 0, 0, 0, 0],\n    [0, 0, 2, 3, inf, inf],\n    [0, inf, 0, 1, 2, inf],\n    [0, inf, inf, 0, 9, 2],\n    [0, inf, inf, inf, 0, 2],\n    [0, inf, inf, inf, inf, 0]\n]\n\nshortest_road, shortest_cost = shortest_path(sample_graph1)\nprint(&#39;最短路径代价为：%d，最短路径为: %s&#39; % (shortest_cost, str(shortest_road)))txt最短路径代价为：5，最短路径为: [1, 3, 5]第二组测试数据\npythonsample_graph2 = [\n    [0, 0, 0, 0, 0],\n    [0, 0, 2, 3, inf],\n    [0, inf, 0, 1, 2],\n    [0, inf, inf, 0, 9],\n    [0, inf, inf, inf, 0]\n]\n\nshortest_road, shortest_cost = shortest_path(sample_graph2)\nprint(&#39;最短路径代价为：%d，最短路径为: %s&#39; % (shortest_cost, str(shortest_road)))txt最短路径代价为：4，最短路径为: [1, 2, 4]第三组测试数据：\npythonsample_graph3 = [\n    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n    [0, 0, 2, 3, 4, inf, inf, inf, inf, inf, inf, inf, inf],\n    [0, inf, 0, 3, inf, 7, 2, inf, inf, inf, inf, inf],\n    [0, inf, inf, 0, inf, inf, 9, 2, inf, inf, inf, inf, inf],\n    [0, inf, inf, inf, 0, inf, inf, 2, inf, inf, inf, inf],\n    [0, inf, inf, inf, inf, 0, inf, inf, 3, 3, inf, inf],\n    [0, inf, inf, inf, inf, inf, 0, 1, inf, 3, inf, inf],\n    [0, inf, inf, inf, inf, inf, inf, 0, inf, 5, 1, inf],\n    [0, inf, inf, inf, inf, inf, inf, inf, 0, inf, inf, 3],\n    [0, inf, inf, inf, inf, inf, inf, inf, inf, 0, inf, 2],\n    [0, inf, inf, inf, inf, inf, inf, inf, inf, 2, 0, 2],\n    [0, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, 0],\n]\n\nshortest_road, shortest_cost = shortest_path(sample_graph3)\nprint(&#39;最短路径代价为：%d，最短路径为: %s&#39; % (shortest_cost, str(shortest_road)))txt最短路径代价为：8，最短路径为: [1, 3, 7, 10, 11]","slug":"算法设计与分析-课后练习26","date":"2023-12-20T06:03:59.000Z","categories_index":"基础,作业,算法","tags_index":"作业,算法","author_index":"ClaRn"},{"id":"599eb923a29a4703289f1f5bf9c3c6e4","title":"算法设计与分析-课后练习27","content":"课后练习27\n\n\npythontext = &#39;ababcabccabccacbab&#39;\npattern = &#39;abccac&#39;pythondef bf(text, pattern):\n    pattern_counter = 1\n    for i in range(len(text)-len(pattern)):\n        underline = [&#39; &#39; for _ in range(len(text))]\n        underline_pattern = [&#39; &#39; for _ in range(len(text))]\n        for j in range(len(pattern)):\n            underline_pattern[i+j] = pattern[j]\n        for j in range(len(pattern)):\n            if text[i+j] != pattern[j]:\n                break\n            underline[i+j] = &#39;↑&#39;\n            print(&#39;第%d次匹配：&#39; % pattern_counter)\n            pattern_counter += 1\n            print(text)\n            print(&#39;&#39;.join(underline))\n            print(&#39;&#39;.join(underline_pattern))\n            if j == len(pattern)-1:\n                print(&#39;匹配完成：子串 %s 在原字符串 %s 中的起始下标是 %d&#39; % (pattern, text, i))\n            \n        \nbf(text, pattern)txt第1次匹配：\nababcabccabccacbab\n↑                 \nabccac            \n第2次匹配：\nababcabccabccacbab\n↑↑                \nabccac            \n第3次匹配：\nababcabccabccacbab\n  ↑               \n  abccac          \n第4次匹配：\nababcabccabccacbab\n  ↑↑              \n  abccac          \n第5次匹配：\nababcabccabccacbab\n  ↑↑↑             \n  abccac          \n第6次匹配：\nababcabccabccacbab\n     ↑            \n     abccac       \n第7次匹配：\nababcabccabccacbab\n     ↑↑           \n     abccac       \n第8次匹配：\nababcabccabccacbab\n     ↑↑↑          \n     abccac       \n第9次匹配：\nababcabccabccacbab\n     ↑↑↑↑         \n     abccac       \n第10次匹配：\nababcabccabccacbab\n     ↑↑↑↑↑        \n     abccac       \n第11次匹配：\nababcabccabccacbab\n         ↑        \n         abccac   \n第12次匹配：\nababcabccabccacbab\n         ↑↑       \n         abccac   \n第13次匹配：\nababcabccabccacbab\n         ↑↑↑      \n         abccac   \n第14次匹配：\nababcabccabccacbab\n         ↑↑↑↑     \n         abccac   \n第15次匹配：\nababcabccabccacbab\n         ↑↑↑↑↑    \n         abccac   \n第16次匹配：\nababcabccabccacbab\n         ↑↑↑↑↑↑   \n         abccac   \n匹配完成：子串 abccac 在原字符串 ababcabccabccacbab 中的起始下标是 9pythondef kmp(text, pattern):\n    next = [0]\n    x = 1\n    now = 0\n    while x &lt; len(pattern):\n        if pattern[now] == pattern[x]:\n            now += 1\n            x += 1\n            next.append(now)\n        elif now:\n            now = next[now-1]\n        else:\n            next.append(0)\n            x += 1\n            \n    print(&#39;模式串 %s 的next数组为：%s&#39; % (pattern, next))\n    \n    tar = 0\n    pos = 0\n    \n    pattern_counter = 0\n    underline = [&#39; &#39; for _ in range(len(text))]\n    underline_pattern = [&#39; &#39; for _ in range(len(text))]\n    while tar &lt; len(text):\n        \n        if text[tar] == pattern[pos]:\n            underline[tar] = &#39;↑&#39;\n            underline_pattern = [&#39; &#39; for _ in range(len(text))]\n            for j in range(len(pattern)):\n                if j + tar - pos &lt; len(text):\n                    underline_pattern[j+tar-pos] = pattern[j]\n            tar += 1\n            pos += 1\n            pattern_counter += 1\n            print(&#39;第%d次匹配：&#39; % pattern_counter)\n            print(text)\n            print(&#39;&#39;.join(underline))\n            print(&#39;&#39;.join(underline_pattern))\n        elif pos:\n            underline = [&#39; &#39; for _ in range(len(text))]\n            underline_pattern = [&#39; &#39; for _ in range(len(text))]\n            pos = next[pos-1]\n        else:\n            underline = [&#39; &#39; for _ in range(len(text))]\n            underline_pattern = [&#39; &#39; for _ in range(len(text))]\n            tar += 1\n            \n        \n        if pos == len(pattern):\n            print(&#39;匹配完成：子串 %s 在原字符串 %s 中的起始下标是 %d&#39; % (pattern, text, tar-pos))\n            return\n\n\nkmp(text, pattern)txt模式串 abccac 的next数组为：[0, 0, 0, 0, 1, 0]\n第1次匹配：\nababcabccabccacbab\n↑                 \nabccac            \n第2次匹配：\nababcabccabccacbab\n↑↑                \nabccac            \n第3次匹配：\nababcabccabccacbab\n  ↑               \n  abccac          \n第4次匹配：\nababcabccabccacbab\n  ↑↑              \n  abccac          \n第5次匹配：\nababcabccabccacbab\n  ↑↑↑             \n  abccac          \n第6次匹配：\nababcabccabccacbab\n     ↑            \n     abccac       \n第7次匹配：\nababcabccabccacbab\n     ↑↑           \n     abccac       \n第8次匹配：\nababcabccabccacbab\n     ↑↑↑          \n     abccac       \n第9次匹配：\nababcabccabccacbab\n     ↑↑↑↑         \n     abccac       \n第10次匹配：\nababcabccabccacbab\n     ↑↑↑↑↑        \n     abccac       \n第11次匹配：\nababcabccabccacbab\n          ↑       \n         abccac   \n第12次匹配：\nababcabccabccacbab\n          ↑↑      \n         abccac   \n第13次匹配：\nababcabccabccacbab\n          ↑↑↑     \n         abccac   \n第14次匹配：\nababcabccabccacbab\n          ↑↑↑↑    \n         abccac   \n第15次匹配：\nababcabccabccacbab\n          ↑↑↑↑↑   \n         abccac   \n匹配完成：子串 abccac 在原字符串 ababcabccabccacbab 中的起始下标是 9","slug":"算法设计与分析-课后练习27","date":"2023-12-20T06:03:08.000Z","categories_index":"基础,作业,算法","tags_index":"作业,算法","author_index":"ClaRn"},{"id":"0b8d67f8201f5b754862328905883ea3","title":"算法设计与分析-课后练习28","content":"课后练习28\n\n\npythonorders = &#123;\n    &#39;q_0&#39;:[\n        (&#39;q_0&#39;, &#39;0&#39;, &#39;1&#39;, &#39;L&#39;, &#39;q_1&#39;),\n        (&#39;q_0&#39;, &#39;1&#39;, &#39;0&#39;, &#39;L&#39;, &#39;q_2&#39;),\n        (&#39;q_0&#39;, &#39;B&#39;, &#39;B&#39;, &#39;H&#39;, &#39;q_F&#39;)\n    ],\n    &#39;q_1&#39;:[\n        (&#39;q_1&#39;, &#39;0&#39;, &#39;0&#39;, &#39;L&#39;, &#39;q_1&#39;),\n        (&#39;q_1&#39;, &#39;1&#39;, &#39;1&#39;, &#39;L&#39;, &#39;q_1&#39;),\n        (&#39;q_1&#39;, &#39;B&#39;, &#39;B&#39;, &#39;H&#39;, &#39;q_F&#39;)\n    ],\n    &#39;q_2&#39;:[\n        (&#39;q_0&#39;, &#39;0&#39;, &#39;1&#39;, &#39;L&#39;, &#39;q_1&#39;),\n        (&#39;q_0&#39;, &#39;1&#39;, &#39;0&#39;, &#39;L&#39;, &#39;q_2&#39;),\n        (&#39;q_0&#39;, &#39;B&#39;, &#39;B&#39;, &#39;H&#39;, &#39;q_F&#39;)\n    ],\n    &#39;q_F&#39;:[\n        \n    ],\n&#125;\n\ndef turing_machine(data):\n    current_state = &#39;q_0&#39;\n    output = [&#39;B&#39;]\n    i = 1\n    while current_state != &#39;q_F&#39;:\n        index = len(data)-i-1\n        order_group = orders[current_state]\n        for order in order_group:\n            if order[1] == data[index]:\n                output.append(order[2])\n                current_state = order[-1]\n                if order[3] == &#39;L&#39;:\n                    i += 1\n                elif order[3] == &#39;H&#39;:\n                    pass\n    \n    output.reverse()\n    return &#39;&#39;.join(output)pythondata = &#39;B10100010B&#39;\noutput_str = turing_machine(data)\nprint(&#39;%s 按照指令执行后得到的结果为 %s&#39; % (data, output_str))txtB10100010B 按照指令执行后得到的结果为 B10100011Bpythondata = &#39;B10100011B&#39;\noutput_str = turing_machine(data)\nprint(&#39;%s 按照指令执行后得到的结果为 %s&#39; % (data, output_str))txtB10100011B 按照指令执行后得到的结果为 B10100100Bpython","slug":"算法设计与分析-课后练习28","date":"2023-12-20T06:01:28.000Z","categories_index":"基础,作业,算法","tags_index":"作业,算法","author_index":"ClaRn"},{"id":"b7f65afed6da02513803114eb0a78e80","title":"算法设计与分析-算法实现5","content":"算法实现5 \n\n \n\n\n\n\npythoninput_data = [1,2,3,7]\n\ndef solve_24(nums):\n    # 用于计算两数运算结果的函数\n    def calculate(a, b, op):\n        if op == &#39;+&#39;:\n            return a + b\n        elif op == &#39;-&#39;:\n            return a - b\n        elif op == &#39;*&#39;:\n            return a * b\n        elif op == &#39;/&#39;:\n            if b != 0:\n                return a / b\n            else:\n                return None  # 避免除以零的情况\n        return None\n\n    # 深度优先搜索\n    def dfs(elements, steps):\n        if len(elements) == 1:\n            if abs(elements[0][0] - 24) &lt; 1e-6:\n                return steps\n\n        for i in range(len(elements)):\n            for j in range(len(elements)):\n                if i != j:\n                    for op in [&#39;+&#39;, &#39;-&#39;, &#39;*&#39;, &#39;/&#39;]:\n                        # 选择两个数字进行运算\n                        a, expr_a = elements[i]\n                        b, expr_b = elements[j]\n                        result = calculate(a, b, op)\n                        if result is not None:\n                            # 构造新的表达式和步骤\n                            new_expr = f&quot;&#123;result&#125;&quot;\n                            new_step = f&quot;&#123;expr_a&#125;&#123;op&#125;&#123;expr_b&#125;=&#123;result&#125;&quot;\n                            new_steps = steps + [new_step]\n                            new_elements = [(result, new_expr)] + [elements[k] for k in range(len(elements)) if k != i and k != j]\n                            # 递归搜索\n                            solution = dfs(new_elements, new_steps)\n                            if solution:\n                                return solution\n        return None\n\n    # 初始化数字和对应的表达式\n    initial_elements = [(num, str(num)) for num in nums]\n    solution = dfs(initial_elements, [])\n\n    if solution:\n        return solution\n    else:\n        return [&quot;No answer!&quot;]\n\n\nfor i in solve_24(input_data):\n    print(i)txt1+2=3\n3*7=21\n21+3=24","slug":"算法设计与分析-算法实现5","date":"2023-12-10T23:09:35.000Z","categories_index":"基础,作业,算法","tags_index":"作业,算法","author_index":"ClaRn"},{"id":"b920aa42c0cdc455a6f0f73719d4c829","title":"An introduction to MPEG-G, the new ISO standard for genomic information representation","content":"对ISO的新型基因信息编码标准MPEG-G的简介摘要MPEG-G 的标准化是一项国际化的努力成果，它定义了一种压缩数据的格式，用于处理、传输和共享大规模的基因数据。该规范由一系列规范组成，用于描述：1.规范格式的语法 。 2.用于检索在兼容文件或者比特流中编码的信息的规范解码过程。这种解码过程可以使用最领先的压缩技术，这种技术与当前正在使用的存储格式相比表现出了显著的压缩增益。此外，该标准还提供了大量急需的功能，比如选择性访问、数据聚合、压缩数据的应用程序编程接口、支持数据保护机制的标准接口、流支持以及评估实现一致性的程序。ISO&#x2F;IEC致力于支持标准规范的维护和可用性，这保证了使用MPEG-G的引用程序的持久性。最后，该标准通过对FASTQ&#x2F;SAM&#x2F;BAM文件格式转换的支持，确保与现有基因组信息处理管道的互操作性与集成性。\n在本文中我们概述了MPEG-G规范，特别关注它提供的主要优点和新颖功能。由于该标准仅指定解码过程，因此在速度和压缩比方面的编码性能可能会根据特定的编码器实现而有所不同，并且可能会在MPEG-G的生命周期内得到改善。因此，此处提供的性能统计数据仅使标准中所含技术的指示性基线示例。\n前言高通量测序技术(HTS)的迅速发展有可能使基因组信息的使用成为许多领域的日常工作。随着因美纳发布新一代的HTS机器，整个人类基因组测序的成本已经降到不到1000美元。在接下来的几年里，这个价格可以预见地会下降得更多，到100美元附近。现在，单个测序系统可以每年提供相当于10000个完整人类基因组的测序，这相当于超过1PB的数据。这一现实导致人们预测生成的基因组数据量将很快超过天文数据量。到那个时候用于存储、转移和处理大容量基因数据的IT开销会大幅超过测序的花销。此外，缺乏适当的压缩数据表示被广泛认为使限制基因组数据在广泛的科学和公共卫生场景中使用的潜力的关键因素。注意这不是因为缺乏特定的用于基因信息的压缩器，而是缺乏一种有效、长期以及可靠的解决方案来提供一个完整的框架，它要做的远不止于压缩，而是对整个基因组信息的表示。\n基于上述现实，运动图像专家组 (MPEG)——国际标准化组织 (ISO) 和国际电工委员会 (IEC) 的联合工作组——正在与生物数据工作流程集成商 ISO 技术委员会 276&#x2F;第 5 工作组合作，制定MPEG-G，一种用于压缩、存储、传输和处理测序数据的新开放标准。在这30年的活动中，MPEG 已经开发了几代成功的标准，将媒体世界从模拟转变为数字（例如，用于音频的MP3和AAC，以及用于视频的AVC&#x2F;H.264和HEVC&#x2F;H.265）。这些标准实现了我们今天在数字媒体领域可以见证的互操作性和集成性。\nMPEG-G 是按照 MPEG 所有标准采用的开放且严格的流程开发的。第一步是为初级和次级数据分析期间产生的原始和对齐读取的压缩表示生成要求列表。该标准还包括有效传输和选择性访问压缩基因组数据的要求。确定所有需求的过程是由来自不同领域的专家进行的广泛的跨学科努力，包括生物信息学、生物学、信息论、电信、视频和数据压缩、数据存储和信息安全。\n随后于 2016 年 6 月发出了提案征集，并于 2016 年 10 月收到了来自 17 个组织的 15 份回复。已使用多种标准对已确定的技术进行了评估，包括但不限于压缩性能、选择性访问能力和灵活性。对各种测序数据进行有效编码。对不同类型的基因组数据进行单独评估：序列读取、质量值、读取标识符、比对信息和元数据。此外，通过测量编码和解码速度以及内存使用情况对计算复杂性进行了初步评估。这确保了候选技术与高效实施兼容。在对提交的提案进行评估和排名时，还考虑了对非顺序访问、扩展核苷酸字母表、附加元数据编码（可扩展性）以及测序质量值（通常称为质量分数）的量化编码的支持。\n最有价值的技术被整合其中，以提供 i) 测序技术生成的原始基因组数据的压缩，ii) 当在参考序列的背景下考虑基因组数据时，压缩与基因组数据相关的比对信息，以及 iii) 定义支持存储和传输的基因组信息传输层。此外，MPEG-G 标准支持与复杂用例相关的功能，其中大多数功能不受当前现有格式（例如 FASTQ 和 SAM&#x2F;BAM）的支持。 MPEG-G 解决的著名用例包括：\n\n对压缩数据的选择性访问（根据若干项标准）\n数据流\n压缩文件的合并和基因组研究的聚合\n隐私规则的执行\n可选的对测序数据和元数据的加密\n基因组片段的注释和链接\n测序数据和元数据的增量更新\n\n最后，与现有的基因信息处理管线的集成和互通性通过支持FASTQ、SAM&#x2F;BAM文件的互相转换来保证。\n下面我们将更详细地描述 MPEG-G 标准，重点介绍其特性和功能，并讨论该标准在未来基因组数据存储、访问、共享和处理中的作用。需要澄清的是，MPEG-G 标准仅规定了从使用 MPEG-G 编码的文件和流中提取信息所需的解码器语法和算法。这种方法允许不断开发新的和更优化的编码器，同时保持与任何现有标准兼容解码器的兼容性。\n\nFigure 1: MPEG-G 文件格式中访问单元的关键元素。每个访问单元包含仅属于一个数据类的基因组记录。\n\n结果基因信息表示MPEG-G技术提供了对于原始基因序列和与参考基因对齐后的基因序列的存储以及传输能力。并更进一步地提供了对单个参考基因（组合）以及其集合的表示。MPEG-G中这种对基因组序列数据的表示是基于Genomic Records概念的。Genomic Records是一种包含了单个序列的读或者一系列成对的序列读的数据结构。如果可行，它将会把序列和对齐信息。一组读标记以及一组质量分数组合起来。\n在不打破传统方法的情况下，Genomic Records数据结构提供了一种更紧凑、更简单且易于管理的数据结构，将与单个 DNA 模板相关的所有信息分组：从简单的原始测序数据到复杂的比对信息。然而虽然Genomic Records是用于基因组信息交互和操作的合适数据结构，但它也不是一个合适的用于压缩的原子数据结构。例如，在处理选择性数据访问时，Genomic Records是一个太小的单元，无法在实现高效、快速的信息检索的同时又具有高度可压缩性。\n为了实现这两个目标，Genomic Records被分类并分组为六个数据类，这些数据类根据其与一个或多个参考序列的比对结果来定义（例如，数据类 P 中的完美匹配、仅在数据类 M 中包含替换的匹配、数据类 I 中包含插入缺失的匹配项，数据类 U 中包含无法映射的读数或原始测序数据）。为了进一步提高压缩效率，Genomic Records簇中包含的信息被分成所谓的描述符流。每个描述符流包含特定类型的信息。这些描述符流的示例有：映射位置、替换数量和读取长度（参见方法）。\n将序列读取分类为数据类使得能够开发强大的选择性数据访问机制。为了实现这一点，MPEG-G 引入了Access Units的概念，它是压缩域中信息编码和访问的基本结构。Access Units是可以独立访问和检查的编码基因组信息的单元。事实上，Access Units仅由属于特定数据类的基因组记录组成，因此构成了一个能够提供强大过滤功能的数据结构，以有效支持许多不同的用例。图 1 显示了 MPEG-G 文件格式中访问单元的基本元素。 \nAccess Units包括标头和一组数据块。Access Units标头包含描述块中编码的基因组数据的元数据，例如数据类型、读数计数、读数映射到的基因组区域、存在多重比对、存在剪接读数、包含上面&#x2F;上替换的编码读数的数量低于给定阈值和子序列（例如，来自单细胞 RNA 测序实验的条形码）等。块包含编码（即压缩）的基因组数据。可选地，附加数据结构可以与Access Units相关联。例如，这些数据结构可以包含 SAM 辅助字段或元数据，这些字段或元数据与管理Access Units的保护机制有关。\n\nFigure 2: MPEG-G 文件格式的关键元素。多个数据集组包含测序数据的多个数据集。每个数据集由包含属于一个特定数据类的基因组记录的 Access Units 组成。每个 Access Units 由读取描述符块组成。\n\n为了促进基因组信息的存储和传输，MPEG-G 指定了基因组数据的数字容器，即 MPEG-G 文件格式（图 2）。如图所示，MPEG-G 文件由文件头和一个或多个名为数据集组的容器组织。每个数据集组同时封装一个或多个数据集、与数据集组关联的标头和可选元数据。最后，每个数据集包含一个标头、可选的元数据容器并携带一个或多个Access Units。文件格式的嵌套性质允许对压缩数据进行有效查询和选择性访问。\n例如，可以使用 MPEG-G 文件来构建三个个体（父亲、母亲、孩子）的基因组测序数据的存储，如下所示：将存在三个不同的数据集组，每个数据集组对应三个个体中的每个个体。然后，每个数据集组将包含与在不同时刻或从不同库执行的同一个体的测序运行相关的数据集。此示例展示了 MPEG-G 文件如何能够将一个或多个个体的整个基因组历史封装在一个独特的文件中，包括与研究、样本等相关的任何元数据。\n压缩能力序列数据以及和它们相关的元数据是一组异构数据，每个数据都由子集的统计行为。因此，MPEG-G提供了几个用于区分这些类型的数据及其表示的策略。在MPEG-G的帮助下，压缩性能和选择性数据访问的优化空间是非常大的，并且可以使用许多不同的解决方案，这些解决方案可以正对不同的应用甚至特定的测序技术和物种进行优化。比如，数据压缩模式可以针对高压缩率和索引（存档类应用）或者低延迟（流媒体类型应用）进行优化。甚至对齐的读数可以进行无参考或基于参考的压缩。在后一种案例中，MPEG-G支持使用FASTA或MPEG-G格式的有参考序列。有参考序列的使用可以作为数据集嵌入同一个MPEG-G文件中或者作为外部参考序列存储，这样需要使用一个无歧义的定义来引用这些外部参考序列。质量分数同样可以无损压缩或者量化。\n在MPEG-G规范的开发过程中，根据提案征集的结果，选择了性能最佳的压缩技术来集成到MPEG-G规范中（有关这些技术的列表，请参阅方法部分）。但需要注意的是，作为标准的开发方式，只有解码过程是规范和规定的。这保证了实现该标准的应用程序的互操作性，同时编码过程对算法和特定于实现的创新开放。因此，MPEG-G 可实现的压缩性能因编码器而异，具体取决于各个实现，并且很可能会随着时间的推移而提高。\n尽管如此，为了让读者了解 MPEG-G 可实现的压缩功能，接下来我们将展示该标准支持的一些技术（可在编码器中实现）的压缩性能，以及它们与当前格式的比较。应该注意的是，使这些技术与 MPEG-G 兼容可能需要进行一些语法修改才能生成 MPEG-G 兼容的描述符流，这可能会导致压缩性能略有不同。此外，由于 MPEG-G 文件提供了纯压缩之外的附加功能，因此预计会产生一些较小的开销。\n在当今的常见实践中，SAM文件通常以BAM文件的形式存储或传输，BAM文件本质上是按块二进制化和gzip压缩的SAM文件。 CRAM 格式可以有效地表示对齐的数据，也得到了广泛的接受。相反，FASTQ 文件通常使用通用无损压缩器（例如 gzip）进行压缩。\n例如，FASTQ 文件中包含的信息（即标识符、读取和质量分数）可以由 MPEG-G 编码器以类似于 FaStore 中的方式进行压缩，FaStore 是 FASTQ 文件的最佳压缩器之一文献中提出。在这种情况下，gzip 将 FASTQ 文件平均减少了 70% 以上，而 FaStore 则减少了 85% 以上（对于所有支持的模式，包括无损模式）。当涉及到对齐数据时，MPEG-G 编码器可以使用与 DeeZ 相当的压缩方法，该方法能够将 437 GB H. Sapiens SAM 文件压缩到大约 63 GB，而相比之下，DeeZ 的压缩方法为 75 GB。 CRAM（加扰）或 BAM 的 106 GB。关于质量值的量化，可以应用 QVZ 和 CALQ 等方法，获得比 BAM 高 10 倍的整体压缩增益，同时保留甚至提高变体调用性能.\n最后，熵编码所采用的技术（参见方法）已被证明可以将 MPEG-G 描述符流测试集压缩至未压缩大小的约 21%，每个描述符流的平均处理速度超过 25 MiB&#x2F;s（使用单线程编码）。\n如上所述，这些只是可实现的可能编码性能的示例，并且压缩比以及压缩速度可以根据每个数据集的具体统计特性以及根据编码器的质量和优化能力而变化。另请注意，由于将每个数据集封装到 MPEG-G 兼容文件中，预计会产生一些较小的开销。\n压缩之外的MPEG-G除了提供方法来实现最先进的压缩技术之外，该标准还提供了基因组信息处理应用之间互操作的基础。ISO&#x2F;IEC同样致力于支持该标准的维护，以保证使用MEPG-G技术的应用程序的持久性。下面列出了MPEG-G技术的基本特征：\n压缩数据的选择性访问在一个MPEG-G文件中嵌入的索引将使得对压缩数据的几种选择性访问的方式成为现实。具体来说，支持以下类型的选择性访问，这些类型可以组合在同一查询中：\n\n给定参考序列上起始到结束映射位置的基因组间隔\n数据类型（比如一个单数据类）\n替换数量低于&#x2F;高于特定阈值的序列读取\n具有多重比对的序列读取\n匹配原始或未映射读数上先前定义的模式（例如条形码）\n连续和非连续区间的标签，可能跨越多个数据集\n\n数据流化MPEG-G 还提供了对压缩数据进行有效分组的方法。这样，接收设备就能在传输完成之前开始处理数据。MPEG-G 流媒体的主要功能包括：\n\n数据包大小适应信道特性&#x2F;状态\n流数据的即时索引\n基于数据包的基因组数据过滤\n\n\nFigure 3: MPEG-G传输格式的关键组件\n\nMPEG-G 内的流式传输是通过传输格式规范实现的，除了图 2 中描述的数据结构（表示文件格式）之外，该规范还提供一组额外的数据结构（数据包和映射表，请参见图 3）。传输格式允许将文件格式结构复用到数据流中，每个数据流都由多个可以动态适应网络特性和条件的数据包组成。此外，传输格式允许在协议级别（例如 TCP&#x2F;IP）上进行错误检测、无序传送以及错误&#x2F;不完整数据的重新传输。文件和传输格式可以通过 MPEG-G 标准中定义的规范转换过程相互转换，不会丢失信息。\n基因组研究的聚合以及测序数据和元数据的增量更新多个相关的基因组研究可以封装在同一个 MPEG-G 文件中，同时仍然可以单独访问。数据集和数据集组的概念支持这一点。数据集通常包含测序运行的结果，数据集组通常包含与同一研究相关的运行。文件串联机制支持聚合存储在多个文件中的（部分）研究，该机制不需要对压缩数据进行重新编码。对于可以与附加访问单元集成的单个数据集来说也是如此，而无需解压缩和重新压缩现有的访问单元。\n对于聚合，只需要更新索引信息和部分关联元数据。一旦聚合了不同的研究，就可以对多个研究进行横向查询（例如，“选择所有压缩样本的染色体 1”）。\n隐私规则的执行MPEG-G 文件中编码的数据可以链接到多个所有者定义的隐私规则，这些规则对数据访问和使用施加限制。 MPEG-G 提供了一种语法来表达要在编码内容上强制执行的隐私规则的层次结构。例如，这使得能够在不同用户之间实现权利委托。数据所有者可以将不同级别的访问权限委托给不同的用户，以便私人医生比对大量人群进行研究的研究中心拥有更高的访问权限。\n对序列数据和元数据的可选加密MPEG-G 支持基因组信息在逻辑数据结构层次结构的不同级别上进行加密。编码文件的每个可识别部分都可以与访问控制机制（例如加密或数字签名）相关联。保护机制的粒度范围从对齐读取的一些特征（例如映射位置）的加密到整个数据集或数据集组。 MPEG-G 不强制选择任何特定的元素进行加密，但提供了支持任何类型策略的语法。然而，某些参数（例如密码）仅限于值集，以便遵守安全建议并简化实现和兼容性。这种方法允许将数据保护的潜在资源密集型应用仅限于真正需要保护的数据部分，而以明文形式留下不敏感的数据。\n压缩域中基因组片段的注释和连接MPEG-G 规范提供了将元数据与压缩基因组数据相关联的标准语法，以实现注释机制。此外，MPEG-G 还支持连接单个基因组样本内或跨多个基因组样本的片段。为此，MPEG-G 支持不同压缩基因组数据块的聚合，以便可以通过单个查询执行检索。该机制依赖于将文本标识符与表达要聚合的基因组数据的特征的语法相关联的概念。这些特征可以是参考序列上的基因组间隔、数据类型（即数据类）或数据集标识符。这使得能够连接彼此相距较远的基因组区域（例如，在不同染色体上或来自不同测序运行），从而简化了数据的注释和检索。\n与现有主要技术和格式的互操作性MPEG-G 支持与 FASTQ、SAM 或 BAM 等格式之间的转换。 MPEG-G 规范提供了有关如何将现有内容转码为 MPEG-G 并返回其原始格式的指南。这对于无法从 SAM 规范明确推断转码机制的情况尤其有用。\nMPEG-G 实现框架MPEG-G 规范包括规范性参考软件和一致性测试，它们通过工具和方法补充语法、语义和解码过程的正式规范，以实现稳健且可靠的一致性验证。此外，标准制定过程中还编制了基因组信息数据库。该数据库包含用于评估基因组信息压缩技术性能的测序数据集合。\n参考软件为了支持和指导 MPEG-G 的实施，该标准包括一个规范的参考软件。参考软件是规范的，因为解码器的任何一致实现，采用相同一致的压缩比特流，并使用相同的规范输出数据结构，将输出相同的数据。也就是说，符合 MPEG-G 标准的实现并不期望遵循算法，甚至不遵循参考软件使用的编程技术；此类软件仅用于支持开发兼容设备和应用程序生态系统的实施过程。因此，规范实现的可用性只是对文本规范的额外支持。还应该强调的是，参考软件并不是 MPEG-G 解码器的优化实现。这也意味着参考软件不应用作性能基准。\n一致性一致性对于提供测试和验证 MPEG-G 技术在不同设备和应用程序中正确实施以及确保所有系统之间的互操作性的基础至关重要。一致性测试指定了一个规范程序来评估一组详尽的压缩数据是否符合标准：每个声称符合 MPEG-G 的解码器都必须证明完整一致性测试台的正确解码。\n用于一致性测试的比特流集可在 MPEG-G 基因组信息数据库中找到（见下文）。\nMPEG-G基因组信息数据库MPEG-G基因组信息数据库是一个统计学意义上的序列数据集合，可用于评估基因信息压缩技术的性能。除了真实的测序数据，数据库中还包含了一组参考序列和变量调用实验所需的支持数据（参见 方法）。在编译数据库时，特别强调合并尽可能多样化的数据。因此，它包含由不同测序技术生成的数据，这些数据是为了进行不同实验类型（例如，WGS、RNA-seq 等）而生成的，并且源自不同物种的样本，例如智人、黑腹果蝇或大肠杆菌。\n讨论广泛使用的基因组信息表示格式（即 FASTQ 和 SAM&#x2F;BAM）是在测序数据稀缺珍贵、应用范围有限的情况下设计的。典型的缺点包括未指定的应用程序编程接口，阻碍了可互操作的应用程序和设备的创建；没有执行隐私保护的框架；未记录的延期和修改流程；压缩性能差（在某些情况下仅限于应用于纯文本的通用压缩器）；缺乏一致性测试；没有指定传输格式，也不支持分组数据流。高通量测序机引入的新范式——相对便宜的高覆盖率测序，具有几乎无限数量的衍生生物协议和下游分析工作流程——强烈鼓励采用更复杂的方式来存储、处理和共享基因组数据。只有识别并解决现有格式中存在的所有基本设计问题，才能实现能够高效处理测序数据的解决方案，类似于当今共享数字媒体内容的解决方案。MPEG-G 代表了朝这个方向迈出的重要一步。它为全新的软件解决方案铺平了道路，使世界各地的独立团体和组织能够无缝通信和共享数据，而不会失去与现有应用程序的互操作性。\n还可以进一步类比数字媒体行业。 MPEG-G 旨在使基因组数据访问、处理和共享（无论是在云中还是在本地存储中）像流式传输音频文件或观看电影一样简单。换句话说，MPEG-G 规范有望为基因组学带来与上个世纪末和本世纪初数字媒体行业所见证的相同的突破性发展。这场革命的主要驱动力之一是数据压缩器令人印象深刻的性能，它使数字媒体存储和传输的规模达到了前所未有的水平。另一个决定因素是在 ISO 和 IEC 等国际中立机构的监督下公开、公平的技术评估和规范过程。这鼓励了世界各地的小型和大型组织联合起来并在协作环境中工作，同时为该标准的长期稳定性提供了保证，该标准是由大量专家维护的公共文件。最后，系统互操作性标准接口的规范使得兼容技术和产品的激增，构成了我们今天所知的数字媒体生态系统。这些元素都存在于 MPEG-G 中；希望它们能够促进类似生态系统的创建（见图 4），最终使个性化医疗等基因组应用民主化。\n随着MPEG-G标准的发布，基因组数据共享将受益于文件大小的减小和接口的标准化；将提供分析工具以及访问和操作数据的复杂方法；由于内置访问控制，安全和隐私保护将得到无缝实施。目前可以想象但由于要传输的数据量巨大或 IT 开发成本高昂而不易实施的应用程序可能很快就会成为现实。此外，开放透明的维护和标准更新过程将鼓励机构投资于该技术的采用和进一步开发。因此，MPEG-G有望在未来很长一段时间内继续发展、改进并结出硕果。\n\nFigure 4: 由MPEG-G驱动的基因生态\n\n方法在这个部分我们会更加正式地描述MPEG-G标准及其组成部分。具体来说，MPEG-G标准分为以下五个部分:\n\n基因组信息的存储和传输。这一部分定义了基因组数据在MPEG-G结构中是如何被组织起来进行传输（比如 流式传输）和存储的。我们提供了一个参考的转换过程来将原本的文件格式转换成传输格式以及相反的过程。\n基因组信息的编码。这一部分定义了用于表示未对齐（比如 原始数据）和对齐的基因组序列读及其相关的标识符，质量值和参考序列的语法。这是标准的一部分，通过描述解析 MPEG-G 比特流的兼容解码器的规范行为来处理压缩。MPEG-G仅指定解码过程，而可以使用任何编码算法，只要它产生符合这部分标准的比特流。\n元数据和API。该标准的这一部分指定了如何将符合 MPEG-G 标准的比特流与描述基因组研究或测序运行等元数据集成。本部分涵盖的其他主题包括从外部系统访问 MPEG-G 数据的规范接口规范、实现访问控制、完整性验证以及身份验证和授权机制的机制规范。本部分还包括专门介绍 SAM 和 MPEG-G 数据结构之间映射的信息部分。\n参考软件。为了帮助和指导 MPEG-G 的实现，该标准包括一个规范性参考软件。参考软件是规范的，因为解码器的任何一致实现，采用相同一致的压缩比特流并使用相同的规范输出数据结构，将输出相同的数据。\n一致性。该标准的这一部分对于提供测试和验证 MPEG-G 技术在不同设备和应用程序中正确实施的方法至关重要，以确保所有系统之间的互操作性。一致性测试指定了一个规范程序来评估一组详尽的压缩数据是否符合标准。\n\n下面时关于1、2、3部分更详细的描述。\nPart 1：基因组信息的传输和存储MPEG-G定义了一个数字容器用于压缩后的基因组数据的传输和存储。在 MPEG 术语中，用于在电信网络上传输分组数据（比如 流式传输）的容器格式称为传输格式，而用于在物理介质（比如 文件）上存储的容器格式称为文件格式。将流转换为文件以及反之亦然的过程是规范的并在标准中指定。\n文件格式一个MPEG-G文件由文件头和一个或多个叫做数据集组的容器组成。每个数据集组包含一个数据集组头，可选的元数据容器和一个或多个封装的数据集。每个数据集有一个数据集头，可选的元数据容器并且包含一个或者多个Access Units。Access Unit实际上才是存储压缩基因组数据的容器。它包含一个Access Unit头，头部提供了对压缩内容的描述（比如数据类型、读数、压缩读数的基因区位等）。\n在MPEG-G文件没有使用描述符号流构建的情况下，Access Unit会包含一系列包含编码信息的数据块，这些数据块可以使用数据集层面乃至其它Access Unit中的全局数据进行独立解码，例如包含 MPEG-G 编码参考序列数据的Access Unit。否则，编码信息块按类型分组、连接并存储为描述符流。然后，索引机制允许将给定的访问单元与相应的块集合相关联。在任何一种情况下，每个块都使用最适合测量的统计特性的熵编码技术（参见下面的第 2 部分）进行压缩。这种嵌套数据结构如Figure 2 所示。\n传输格式除了为文件格式定义的数据容器之外，MPEG-G 还指定支持网络上分组数据传输的数据结构。此类结构被定义为既承载压缩的基因组数据，又更新描述流内容的元数据。后一种类型的数据的一个示例是接收端使用的索引信息，以使得即使对部分传输的内容也能够进行选择性访问。传输格式结构有助于规范传输格式（即通过互联网传输的 MPEG-G 流）和文件格式（即存储在磁盘上的 MPEG-G 文件）之间的转换规范过程。\n传输格式结构有助于规范传输格式（即通过互联网传输的 MPEG-G 流）和文件格式（即存储在磁盘上的 MPEG-G 文件）之间的转换规范过程。\nPart 2：基因组信息编码基因组记录根据其读数与一个或多个参考序列的主要比对结果分为六个数据类，如Table 1 所示。记录根据与所用参考序列的不匹配类型进行分类用于对齐。\n为了进一步提高压缩效率，集群基因组记录中包含的信息被分割到描述符流中。将聚类基因组记录中包含的信息拆分为描述符流的概念允许根据每个描述符流的统计属性定制编码参数。\n\n    \n        \n             类型 \n            语义\n        \n        \n            P\n            读取与参考序列完全匹配。\n        \n        \n            N\n            仅包含未知碱基的错配读数。\n        \n        \n            M\n            读数中至少包含一个替换碱基，也可能包含未知碱基，但不包含插入碱基、删除碱基和剪切碱基。\n        \n        \n            I\n            读数至少包含一个插入、缺失或剪切碱基，也可能包含未知碱基或置换。\n        \n        \n            HM\n            仅映射一个读数的半映射对。\n        \n        \n            U\n            未映射读数。\n        \n        \n            Table 1: MPEG-G中定义的数据类型\n        \n    \n\n\n原始测序数据的压缩模式原始测序数据可以根据两种不同的方法进行编码，具体取决于当前的应用：\n高压缩比和索引：通过利用基因组序列数据的高冗余度来实现高压缩比。这使得能够使用众所周知的压缩技术，例如相对于已编码数据的序列的差分编码。这种方法实现了最大压缩比，但需要整个数据集的可用性以及一些可能影响压缩延迟的预处理阶段。原始基因组序列的差异编码依赖于多个序列之间共享的共同模式（即“签名”）的识别。这些常见模式仅与每次读取的特定核苷酸（即“残差”）一起编码一次。这种签名的存在使得能够实现索引方案，利用该索引方案可以通过模式匹配算法来搜索压缩数据。例如，该模式适用于原始测序数据的长期存储。可以使用 MPEG-G 中针对此操作模式定义的解码器语法来表示数据输出的预处理技术的示例包括 ORCOM [13]、HARC [14]、FaStore [7] 中提出的技术，并且一般而言，所有（未来）基于常见模式对读取进行聚类的预处理技术。\n低延迟：当低流延迟比压缩比具有更高的优先级时，MPEG-G 还支持“高吞吐量”压缩方法，一旦基因组序列可用，就可以应用该方法。在这种情况下，在实际编码之前不需要对整个数据集进行数据预处理。这种方法支持流式传输场景，其中基因组数据一旦可用（甚至可能在测序过程完成之前）就需要从测序设施传输到远程设备。\n质量值的压缩模式由于其更高的熵和更大的字母表，质量值已被证明比读数更难压缩。此外，有证据表明质量值本质上是有噪声的，并且使用它们的下游应用程序以不同的启发式方式这样做。因此，质量值的量化不仅可以显着减轻存储需求，还可以提供与使用未压缩数据实现的性能相当（有时甚至优于）的变体调用性能。这甚至可以通过每个质量分数 0.5 位而不是无损压缩所需的 3 位来实现，大约\n因此，在MPEG-G中，质量值可以以无损方式或以量化方式编码。当对质量值进行无损编码时，可以在实际算术编码之前对质量值应用若干变换（另请参见下面的熵编码过程的步骤2）。这些变换包括差分编码、游程编码和名为“匹配编码”的变换，可以将其视为改进的 Lempel-Ziv 方案 [17]。\n不过质量值的量化可以导致熵编码后比特流大小的显着减小。然而，为了促进最小化任何量化效应，MPEG-G 标准提供了多种机制来允许编码器执行量化方案的细粒度选择。\n在未对齐读取的情况下，符合 MPEG-G 的编码器可以自由选择任何有益的量化方案。这包括最近发表的研究的量化方案，例如[18,19,20,9]。所使用的具体量化方案通过质量值码本通知给解码器。量化的质量值作为该质量值码本中的质量值索引被用信号发送给解码器。\n在对齐读取的情况下，MPEG-G 引入了一个额外的维度来微调质量值量化：可以根据基因组位置（即每个基因座）选择码本 [10]。因此，每个基因组位置一个质量值密码本标识符与质量值索引一起被发送到解码器。\n在这两种情况下，在熵编码之前，质量值索引被分成每个质量值码本的单独流。最后，MPEG-G 编码器还可以通过为每个数据类以及每个访问单元选择不同的码本来调整量化。\n读取标识符的压缩模式读取标识符被分解为一系列标记，这些标记可以是三种主要类型：字符串、数字和单个字符。读取标识符表示为相对于先前解码的读取标识符之一的一组差异和匹配。这种方法不依赖于任何测序制造商的实施，并且仅假设在同一测序运行中，读取标识符的结构大部分是恒定的。请注意，这种标识符压缩方法（或其变体）先前已在压缩器中使用，例如 SamComp [21]、Quip [22]、DeeZ [8] 和 FaStore [7] 等。\n参考序列的压缩模式MPEG-G支持使用FASTA格式和MPEG-G压缩格式的参考序列。参考序列同样可以作为数据集嵌入同一个MPEG-G文件中。也可以使用可选的外部参考序列（比如，不包含在比特流中的序列）。MPEG-G规定了如何使用URI和校验码来保证外部参考序列的确定性。\nMPEG-G 中的参考序列可以编码为独立数据集或相对于另一个参考序列的差异。在第一种情况下，参考序列被编码为属于数据类 U（未映射读取）的基因组记录序列，并使用针对未映射序列数据描述的方法进行编码。在相对于另一个参考序列进行差分编码的情况下，使用与用于对齐数据的相同方法。在这种情况下，属于数据类 P、N、M、I 和 U 的基因组记录可用于表示编码组件的片段。在差异编码的情况下，用作对一个或多个其他基因组序列进行编码的参考的参考序列不需要是真实的基因组序列，而是可以被合成以提高压缩性能。当使用公共参考（不一定是集合的序列之一）压缩基因组序列集合时，这可能会很有帮助。\n熵编码将不同类型的数据存储在单独的描述符流中可以显着提高压缩效率。可以利用每个描述符的不同统计属性来定义用于熵编码的不同源模型。通过根据每个源模型的统计特性采用适当的上下文自适应概率模型来提高压缩效率。\n为了压缩异构描述符集，MPEG-G 指定使用上下文自适应二进制算术编码 (CABAC) [23]，如流行的视频编码标准和基因组数据压缩解决方案 AFRESh 和 AQUa [24, 25] 中所使用的那样。通过选择这种高效的算术编码器，可以显着简化兼容编解码器的实现，因为目前可以使用硬件和软件中的各种实现。\n压缩过程由 5 个步骤组成（见Figure 5）：输入数据解析、值转换、值二值化、上下文选择和 CABAC。\n\nMPEG-G 中使用的上下文自适应熵编码\n\n在步骤 1（输入数据解析）中，描述符流被解析为值序列。如果有利的话，描述符流中包含的数据可以分成多个子序列。每个结果子序列在步骤 2 到 5 中单独处理。\n在步骤 2（值转换）中，将可选的转换（序列）应用于步骤 1 生成的值。某些转换会生成其他数据流。每个生成的变换子序列在步骤 3 到 5 中分别进行处理。\n在步骤 3（值二值化）中，不同变换子序列中的值被转换为二值化表示（即一组位）。为了允许步骤 5 中的有效压缩，变换和二值化的组合应该以这样的方式选择：二值化的每个比特的值尽可能可预测。二值化流用作步骤 5 的输入。\n在步骤 4（上下文选择）中，识别将在编码步骤（步骤 5）期间使用的上下文集。每个上下文集包含对一个输入值进行编码所需的上下文。上下文选择步骤的目标是选择期望尽可能类似于步骤 3 生成的二值化表示中的比特分布的上下文集。所选上下文的流充当熵编码器的支持值步骤 5.\n在步骤5（CABAC）中，使用在步骤4中或在旁路模式中选择的上下文集，使用表示等概率的非自适应上下文，对步骤3中生成的二值化表示的仓进行编码。\n解码过程MPEG-G规范不仅定义了压缩基因组测序数据的语法和语义，还定义了确定性解码过程。\nMPEG-G 解码过程的规范输入是称为数据单元的数据结构的串联。根据传送数据的类型，数据单元可以分为三种类型。类型 0 的数据单元封装一个或多个参考序列的解码表示，类型 1 的数据单元包含在称为参数集的结构中的解码过程中使用的参数，类型 2 的数据单元包含一个Access Unit。\n类型 0 和 1 的数据单元在类型 2 的数据单元的解码过程中使用，但不产生任何规范的输出。这些数据单元携带的数据由解码过程以依赖于实现的方式进行管理。访问单元的解码过程以包含原始或对齐读取的访问单元的 MPEG-G 记录的形式或以包含压缩参考序列或部分的访问单元的原始参考结构的形式产生规范输出。其中。 MPEG-G 记录可以被视为改进的 SAM 记录：在 MPEG-G 中，读取对通常编码在同一记录中，除非满足某些条件，例如配对距离高于用户定义的阈值，或者配对映射到不同的参考序列。分割读取对的决定由编码器做出，并且使用适当的描述符将配对信息传输到解码器以用于该对中的每个读取。解码过程是完全指定的，以便所有符合标准第 2 部分的解码器将产生相同的解码输出。规范解码过程包括数据结构的所有层次结构，从 MPEG-G 文件中包含的复用比特流或流场景中的数据流，到描述符块再到规范输出。解码过程的简化图如Figure 6 所示。\n\nMPEG-G 数据单元转化为规范输出的简化版解码流程\n\nPart 3：元数据和APIs隐私规则的应用MPEG-G 文件中编码的数据可以链接到多个所有者定义的隐私规则，这些规则对数据访问和使用施加限制。隐私规则在 XACML（可扩展访问控制标记语言）3.0 版（OASIS 标准 [26]）中指定。\nMPEG-G 文件格式包括在 MPEG-G 层次结构的大多数级别（包括数据集组、数据集、描述符流和访问单元级别）可用的特定容器中提供的保护信息。除了应用于它们所引用的信息的隐私规则之外，这些保护容器还提供了管理信息的机密性和完整性的机制。具体来说，有关隐私规则的信息仅在数据集组和数据集级别可用。例如，隐私规则可以指定对与识别阿尔茨海默病倾向相关的特定区域的访问控制。通过使用加密技术与隐私规则相结合，可以有效地保护基因组数据免受未经授权的访问。因此，只有获得规则授权的用户才能对受保护区域进行操作。\n序列数据和元数据的加密MPEG-G 支持在其逻辑数据结构层次结构中的不同级别上对基因组信息进行加密。保护信息指定如何对同一级别的数据结构以及紧接其下的一层的保护信息容器进行加密。此信息使用 XML 加密 v1.1 标准 (www.w3.org/TR/xmlenc-core1) 表示。另一方面，可以通过使用 XML Signature v1.1 (www.w3.org/TR/xmldsig-core1) 的电子签名来提供身份验证和完整性。\n加密不仅可以用于基因组记录中包含的“低级”详细测序数据和元数据，还可以用于数据集组和数据集层次结构级别可用的“高级”元数据。为此，MPEG-G 提供了使用 XML v1.1 (www.w3.org/TR/xml11) 指定的元数据信息结构，以及针对这些级别的一组元素。它包括元数据元素的最小核心集（例如数据集组的标题和样本，或数据集的标题和项目中心）。用户和应用程序可以通过包含额外的信息元素以标准化方式扩展该核心集。\n此外，元数据配置文件是用标准中提供的机制指定的元数据集的特定子集。指定的元数据简档可以对应于在MPEG-G中指定或使用的公共元数据集，例如来自欧洲基因组-现象档案库(EGA)和国家癌症研究所(NCI)基因组数据共享(GDC)的元数据集。元数据配置文件包括核心元素的子集和使用扩展机制指定的一组新元素。\nMPEG-G 基因组信息数据库数据库中包含的测序数据根据：i) 实验类型，ii) 测序生物体，以及 iii) 采用的测序技术进行分类。该数据库包括与全基因组测序、宏基因组测序、RNA测序和癌症测序实验相关的数据。 WGS 数据通过模拟人类 WGS 数据得到进一步扩展。此外，数据库中还包含来自多种类群（即动物界、植物界、真菌、细菌和病毒）的数据：黑腹果蝇和智人（动物界）、可可（植物界）、酿酒酵母（真菌）、不同菌株大肠杆菌和铜绿假单胞菌（细菌）和 ΦX174（病毒）。最后，使用不同的测序技术生成数据：i) 边合成边测序（Illumina&#x2F;Solexa Genome Analyzer、Illumina Genome Analyzer IIx、Illumina MiSeq、Illumina HiSeq 2000、Illumina HiSeq X Ten、Illumina NovaSeq 6000）；ii) 单分子实时测序（Pacific Biosciences SMRT (PacBio))；iii) 纳米孔测序（Oxford Nanopore MinION）； iv) 离子半导体测序（Ion Torrent PGM）。\n可以通过 https://github.com/voges/mpeg-g-gidb 访问该数据库。\nMPEG-G 文档由于 MPEG-G 标准的规模和广度，我们建议读者参考描述它的官方文档。当 ISO 和 IEC 发布最终版本时，这些文件将公开。中间公共文档可在 MPEG 网站上专门介绍 MPEG-G 的部分 (https://mpeg.chiariglione.org/standards/mpeg-g) 以及 MPEG-G 门户网站 (https://mpeg-g.org) 上找到。\n","slug":"introduction_to_MPEG-G","date":"2023-12-03T06:55:49.000Z","categories_index":"论文翻译","tags_index":"生物信息学,MPEG-G","author_index":"ClaRn"},{"id":"926471e4eff9b83304d4f06ae8b35be9","title":"SVM 的求解","content":"\n\n\n\n\n\nTIP\n给定下列3个样本点，请计算硬间隔SVM分类器\n\n\n\n\n\n\n\n\n3\n1\n\n\n1\n1\n\n\n-1\n-1\n\n\n\n\n首先，我们需要定义SVM的目标函数和约束条件。我们假设SVM的分类决策函数是 ，其中  和  是我们要求的参数， 是输入的特征值。我们的目标是让  能够正确地区分两类样本，即 ，其中  是样本的类别标签，取值为 。同时，我们还希望找到一个最优的超平面，使得它到两类样本的最近距离（也就是间隔）最大。这个距离可以用  表示，其中  是  的绝对值。因此，我们的目标函数可以写成：\n\n\n这是一个带有不等式约束的凸二次规划问题，我们可以用拉格朗日乘子法来求解。拉格朗日乘子法的基本思想是，将一个含有  个变量和  个约束条件的优化问题，转化为一个含有  个变量的无约束优化问题，然后通过求解拉格朗日函数的极值点来得到原问题的解。拉格朗日函数是由原函数和约束条件通过拉格朗日乘子（一些常数）相加而构成的。\n在我们的例子中，我们有两个变量  和 ，以及三个约束条件 。我们引入三个拉格朗日乘子 ，分别对应三个约束条件，然后构造拉格朗日函数：\n\n我们的目标是求解  的极小值，但是这个函数是关于  和  的，我们需要先固定其中的一部分变量，然后对另一部分变量求导，令其为零，得到一些方程。这里我们先固定 ，对  和  求导，得到：\n\n\n从上面两个方程，我们可以解出  和  关于  的表达式：\n\n\n将这两个表达式代入拉格朗日函数，我们可以得到一个只关于  的函数，称为对偶函数：\n\n注意，我们利用了  这个条件，将  消去了。现在，我们的目标是求解对偶函数的极大值，即：\n\n\n\n这是一个带有等式和不等式约束的凸二次规划问题，我们可以用一些数值算法来求解，比如内点法，外点法，梯度投影法等。这里我们不深入讨论这些算法的细节，而是直接给出一个可能的解：\n\n有了  的解，我们就可以回代求出  和  的解：\n\n\n因此，我们得到了一个 SVM 分类器 ，它可以正确地将三个样本分为两类。\nSMO求解代码如下：\npythonimport numpy as np\n\n\ndef smo_algorithm(X, Y, max_passes=1000, C=1.0, tol=1e-3):\n    \"\"\"\n    Simplified SMO algorithm for training a support vector machine.\n\n    Parameters:\n    X (list of list of float): Data points.\n    Y (list of int): Labels corresponding to the data points.\n    max_passes (int): Maximum number of times to iterate over alpha without changing.\n    C (float): Regularization parameter.\n    tol (float): Tolerance for stopping criterion.\n\n    Returns:\n    np.ndarray: The alpha values for each data point.\n    float: The bias term b.\n    np.ndarray: The weight vector w.\n    \"\"\"\n\n    # Convert lists to numpy arrays for easier calculations\n    X = np.array(X)\n    Y = np.array(Y)\n    m, n = X.shape\n\n    # Initialize variables\n    alphas = np.zeros(m)\n    b = 0\n    passes = 0\n\n    while passes &lt; max_passes:\n        num_changed_alphas = 0\n        for i in range(m):\n            # Calculate Ei = f(xi) - yi\n            Ei = np.dot((alphas * Y), np.dot(X, X[i, :])) + b - Y[i]\n\n            if ((Y[i] * Ei &lt; -tol and alphas[i] &lt; C) or (Y[i] * Ei &gt; tol and alphas[i] &gt; 0)):\n                # Randomly select j ≠ i\n                j = np.random.choice([x for x in range(m) if x != i])\n                # Calculate Ej = f(xj) - yj\n                Ej = np.dot((alphas * Y), np.dot(X, X[j, :])) + b - Y[j]\n\n                # Save old alphas\n                alpha_i_old = alphas[i]\n                alpha_j_old = alphas[j]\n\n                # Compute L and H\n                if Y[i] != Y[j]:\n                    L = max(0, alphas[j] - alphas[i])\n                    H = min(C, C + alphas[j] - alphas[i])\n                else:\n                    L = max(0, alphas[i] + alphas[j] - C)\n                    H = min(C, alphas[i] + alphas[j])\n\n                if L == H:\n                    continue\n\n                # Compute eta\n                eta = 2.0 * np.dot(X[i, :], X[j, :]) - np.dot(X[i, :], X[i, :]) - np.dot(X[j, :], X[j, :])\n                if eta &gt;= 0:\n                    continue\n\n                # Update alpha_j\n                alphas[j] -= Y[j] * (Ei - Ej) / eta\n\n                # Clip alpha_j\n                alphas[j] = min(H, alphas[j])\n                alphas[j] = max(L, alphas[j])\n\n                if abs(alphas[j] - alpha_j_old) &lt; tol:\n                    continue\n\n                # Update alpha_i\n                alphas[i] += Y[i] * Y[j] * (alpha_j_old - alphas[j])\n\n                # Update b\n                b1 = b - Ei - Y[i] * (alphas[i] - alpha_i_old) * np.dot(X[i, :], X[i, :]) \\\n                     - Y[j] * (alphas[j] - alpha_j_old) * np.dot(X[i, :], X[j, :])\n                b2 = b - Ej - Y[i] * (alphas[i] - alpha_i_old) * np.dot(X[i, :], X[j, :]) \\\n                     - Y[j] * (alphas[j] - alpha_j_old) * np.dot(X[j, :], X[j, :])\n\n                if 0 &lt; alphas[i] &lt; C:\n                    b = b1\n                elif 0 &lt; alphas[j] &lt; C:\n                    b = b2\n                else:\n                    b = (b1 + b2) / 2.0\n\n                num_changed_alphas += 1\n\n        if num_changed_alphas == 0:\n            passes += 1\n        else:\n            passes = 0\n\n    # Calculate the weight vector w\n    w = np.dot((alphas * Y), X)\n\n    return alphas, b, w\n\n\n# Test data\nX = [[3], [1], [1]]\nY = [1, 1, -1]\n\n# Run SMO algorithm\nalphas, b, w = smo_algorithm(X, Y)\n\nprint(alphas, b, w)","slug":"SVM 的求解","date":"2023-12-03T05:50:42.000Z","categories_index":"基础,机器学习","tags_index":"机器学习,模式识别","author_index":"ClaRn"},{"id":"b910ae60a17b1ab8f5a481a64bd4c8b5","title":"CUDA C 中的PTX编程","content":"\n\n\n\n\n\n\n\n\nCUDA编程环境提供了一个并行线程执行指令集(PTX)用于使用GPU的数据并行计算能力。本指南用于将PTX汇编语句集成进CUDA C程序中。\nASM语句使用asm()将任意PTX汇编代码插入到你的CUDA程序中。一个简单的示例如下：\ncasm(\"membar.gl;\");该语句将PTX指令membar.gl插入到了程序生成的PTX code中，插入位置就在调用asm()函数的地方。\n参数当涉及到传入和传出参数时，一个包含了PTX code的asm()语句可能变得非常复杂，但也会变得更有用。参数传递的基本语法如下：\ncasm(\"template-string\" : \"constraint\"(output) : \"constraint\"(input));通过使用逗号分隔，可以传递多个参数。示例代码中的template-string包含了操作数的引用。多条PTX指令可以通过使用分号分隔来传递。\n示例如下：\ncasm(\"add.s32 %0, %1, %2\" : \"=r\" (i) : \"r\"(j), \"r\"(k))每一个%n都是一个指向操作数的下标，比如%0指向i，%1指向j，%2指向k。PTX指令中，输出操作数永远都是第一个参数，所以它们被分配到了最小的下标。上例最终被翻译为如下PTX指令：\ncadd.s32 i, j, k;这种数字标记的顺序可以任意使用，比如说上例同样可以写为：\ncasm(\"add.s32 %0, %2, %1\" : \"=r\" (i) : \"r\"(k), \"r\"(j))也可以重复使用一个引用：\ncasm(\"add.s32 %0, %1, %1\" : \"=r\" (i) : \"r\"(k))最终被编译为：\ncadd.s32 i, k, k如果没有传入参数，最后一个冒号可以省略：\ncasm(\"mov.s32 %0, 2\" : \"=r\"(i))如果没有输入的话，两个冒号之间可以留空：\ncasm(\"mov.s32 r1, %0\" :: \"r\"(i))要在PTX指令中使用%符号，可以使用%%进行转义：\ncasm(\"mov.u32 %0, %clock;\" : \"=r(x)\");上述例子中为了说明%的作用而进行了简化。实际上，操作数是通过约束所定义的方式传递的，比如说r表示的就是一个32位的整数型寄存器，所以语句：\ncasm(\"add.s32 %0, %1, %2\" : \"=r\" (i) : \"r\"(j), \"r\"(k))实际上在编译器中产生了如下字节码序列：\ncld.s32 r1, [j]\nld.s32 r2, [k]\nadd.s32 r3, r1, r2;\nst.s32 [i], r3;这就是为什么输入和输出操作数会有区别，因为需要保证在指令执行之前，操作数被载入了对应的寄存器。=操作符说明了要写入的目标寄存器，还有一个+操作符标记可读写的寄存器。比如：\ncasm(\"add.s32 %0, %0, %1;\" : \"+r\"(i) : \"r\"(j));多条PTX指令可以合并到一个asm()语句中，基本上任何合法语句都能作为一个字符串参数传入asm()函数。多条指令也可以通过多个字符串分隔，只需要使用 C/C++ 的字符串拼接。同时在asm()函数内的PTX指令后写注释语句不受影响。为了生成更具有可读性的PTX中间文件，最好在每一个指令字符串的结尾都带上\\n\\t。\n举个例子，一个计算立方体体积的程序可以写为：\nc__device__ int cube(int x)\n{\n    int y;\n    asm(\n        \".reg .u32 t1;\\n\\t\"             //temp reg t1\n        \"mul.lo.u32 t1, %1, %1;\\n\\t\"    //t1 = x* x\n        \"mul.lo.u32 %0, t1, %1;\"        //y = t1 * x\n        : \"=r\"(y) : \"r\"(x)\n    );\n    return y;\n}如果一个输出操作数是根据汇编指令的条件来更新的，那么就应该用+修饰符。示例如下：\nc__device__ int cond(int x)\n{\n    int y = 0;\n    asm(\n        \"{\\n\\t\"\n        \"   .reg .pred %p;\\n\\t\"             \n        \"   setp.eq.s32 %p, %1, 34;\\n\\t\"    // x == 34 ?\n        \"   @%p mov.s32 %0, 1;\\n\\t\"         // 若为true将y设为1\n        \"}\"                                 // 等价于 y = (x==34)?1:y\n        : \"+r\"(y) : \"r\"(x)\n    );\n    return y;\n}约束不同的 PTX 寄存器类型有不同的字母约束，如下：\n\nh = .u16 reg\nr = .u32 reg\nl = .u64 reg\nf = .f32 reg\nd = .f64 reg\n\n示例如下：\ncasm(\"cvt.f32.s64 %0, %1;\" : \"=f\"(x) : \"l\"(y));上述代码生成的字节码如下：\ncld.s64 rd1, [y];\ncvt.f32.s4 f1, rd1;\nst.f32 [x], f1;“n”型约束可以用于已知数值的整型操作数，示例如下：\ncasm(\"add.u32 %0, %0, %1;\" : \"=r\"(x) : \"n\"(42));生成的字节码如下：\ncadd.u32 r1, r1, 42;8位宽的PTX寄存器并没有分配约束字母。PTX指令类型接受8位宽的类型是通过从更宽的指令类型转换而来的。示例如下：\nc__device__ void copy_u8(char* in, char* out)\n{\n    int d;\n    asm(\"ld.u8 %0, [%1];\" : \"=r\"(d) : \"l\"(in));\n    *out = d;\n}上述代码生成的字节码如下：\ncld.u8 r1, [rd1];\nst.u8 [rd2], r1;使用不是上面指定的约束字符串之一的约束字符串的行为是未定义的。\n陷阱尽管asm()语句可用性非常高，但你依然可能会遇到一些问题。\n命名空间冲突在之前定义的cube函数中，如果将函数内联将可能出现对临时寄存器t1重复声明的错误。要避免这个错误可以：\n\n不要将cube函数内联\n将 t1 使用嵌套在 {} 内，以便每次调用都有单独的作用域，例如：\n\nc        __device__ int cube (int x)\n        {\n            int y;\n            asm(\n                \"{\\n\\t\"\n                \"   reg .u32 t1;\\n\\t\"\n                \"   mul.lo.u32 t1, %1, %1;\\n\\t\"\n                \"mul.lo.u32 %0, t1, %1;\\n\\t\"\n                : \"=r\"(y) : \"r\"(x)\n            );\n            return y;\n        }也可以把asm()内的本地标识符直接使用大括号包裹起来。\n内存空间冲突asm()语句是无法知道寄存器是在什么样的内存空间中的，用户必须保证使用的PTX指令正确。对于sm_20以及更高的版本，任何传递给asm()语句的指针参数会被作为一个统一虚拟地址空间的地址传递。\n错误的优化编译器会默认asm()语句不会对程序产生除了改变了输出操作数以外的任何副作用。为了确保汇编代码在生成PTX的过程中不会被删除或者移动，程序员需要使用volatile关键字。例如：\ncasm volatile (\"mov.u32 %0, %%clock;\" : \"=r\"(x));通常任何需要写入的内存都会被定义为一个输出操作数，但是如果操作对于用户内存有一些隐藏的副作用的话（比如说通过一个操作数间接访问内存的某一位置），或者如果你想停用所有在asm()语句周围的内存优化，那就可以在第三个冒号后添加一个memory来解除这一约束。例如：\ncasm volatile (\"mov.u32 %0, %%clock;\" : \"=r\"(x) :: \"memory\");\nasm (\"st.u32 [%0], %1;\" :: \"l\"(p), \"r\"(x) : \"memory\");错误的PTX编译器前端并不会将asm()语句的模板字符串进行解析，并且不会知道其中的语句是什么意思以及它是否是合法的PTX语句。所以如果字符串中存在错误，在ptxas之前都将无法被感知。比如说，如果你通过r约束传递一个值但是在add.f64指令中使用了这个值，那在ptxas中你将得到一个解析错误。同样，操作数修饰符也是不支持的。例如如下语句：\ncasm(\"mov.u32 %0, %n1;\" : \"=r\"(n) : \"r\"(1));在%n1中的这个n标识符是不支持的，但也会被传入ptxas，这可能会导致未定义行为。\n错误检查下面是一些在编译器中可用的内联PTX汇编错误检查技巧。\n在一个汇编操作符中使用多个约束字母是不被允许的，比如：casm(\"add.s32 %0, %1, %2;\" : \"=r\"(i) : \"rf\"(j), \"r\"(k));\n\n\n\n\n\n\n\n\nerror: an asm operand may specify only one constraint letter in a __device__ / __ global__ function\n只有标量变量是可以用在asm的操作数中的。聚合型变量比如结构体类型是不被允许的。比如：cint4 i4;\nasm(\"add.s32 %0, %1, %2;\" : \"=r\"(i4) : \"r\"(j), \"r\"(k));\n\n\n\n\n\n\n\n\nerror: an asm operand must have scalar type\nPTX asm 约束隐含的类型和大小必须与关联操作数的类型和大小匹配。比如：对于char类型的变量ci：\ncasm(\"add.s32 %0, %1, %2;\" : \"=r\"(ci) : \"r\"(j), \"r\"(k));\n\n\n\n\n\n\n\n\nerror: asm operand type size(1) does not match type/size implied by constraint ‘r’\n要让char类型的变量ci、cj和ck在上述语句中可用，代码应该改写成如下形式：\ncint temp = ci;\nasm(\"add.s32 %0, %1, %2;\" : \"=r\"(temp) : \"r\"((int)cj), \"r\"((int)ck));另一个类型不匹配的示例是：对于float类型的变量fi，\ncasm(\"add.s32 %0, %1, %2;\" : \"=r\"(fi) : \"r\"(j), \"r\"(k));\n\n\n\n\n\n\n\n\nerror: asm operand type size(4) does not match type/size implied by constraint ‘r’\n","slug":"PTX编程","date":"2023-11-29T02:40:49.000Z","categories_index":"","tags_index":"GPU,CUDA","author_index":"ClaRn"},{"id":"e8b1d5b0c00361d7420940b31baf6a00","title":"《诸神的黄昏 1944—1945，从莱特湾战役到日本投降》读书报告","content":"太平洋上的终章——《诸神的黄昏 1944—1945，从莱特湾战役到日本投降》读书报告引言\n\n\n\n\n\n\n\n\n 关于太平洋战争大战略的基本问题仍然悬而未决。麦克阿瑟是否应当获准收复整个菲律宾群岛，包括北方主岛吕宋岛？欧内斯特·金关于攻打台湾的方案能否获得通过？美军是否应当在中国大陆沿岸登陆？若如此，这是否意味着美军将会大规模参加中国的抗日战争？更远一些看，对日本的最后一战将会是什么样子？日本能否在血腥惨烈的登陆之前接受投降条件？昭和天皇裕仁在战争的最后阶段会扮演何种角色？这都是些复杂而且无比重要的抉择，而且不可能无限期拖而不决。总统选举的时间安排是不可更改的，不论遇到什么困难，选民们都会在11月的第一个星期二走进投票站。现在，美国将不可避免地在大选季对太平洋上的重大战略问题做出决定了一人们必定会带上政治的有色眼镜去看待这些决策，无论是当时的人，还是后世的历史学者，都将如此。 —— 《诸神的黄昏：1944一1945，从莱特湾成役到日本投降》  \n1939 年德国闪击波兰，标志着第二次世界大战欧洲战场的开端。这场历史上规模最大、涉及人类最多的战争，直接奠定了战后数十年的世界格局。1941年12月7日，日本偷袭珍珠港将美军拉入了同盟国阵营，这场世界级的大战开始走向转折。\n伊恩·托尔（Ian W. Toll）是美国历史作家、海军历史学者。他先后毕业于乔治敦大学和哈佛大学，曾短暂进入政界，之后又投身金融行业，在多家银行担任分析师。但他一直对从事历史研究的梦想念念不忘，2002年开始专心从事写作。他以《六舰》一书赢得广泛赞誉，荣获塞缪尔·埃利奥特·莫里森奖和威廉·科尔比奖等多项奖项。他的“太平洋战争三部曲”，《燃烧的大洋》《征服的怒潮》《诸神的黄昏》，在学者、军迷和历史爱好者群体中均广受好评。\n《诸神的黄昏：1944—1945，从莱特湾战役到日本投降》是“太平洋战争三部曲”的最后一卷。这本书详细描述了太平洋战争的最后阶段，从1944年10月的莱特湾战役，到1945年8月的日本投降，涵盖了美军、日军、英军、澳军、中军等各方的战略、战术、外交、政治、人文等方面的内容。这本书不仅展现了战争的残酷和惨烈，也揭示了战争的复杂和多元，以及战争对人类社会的深远影响。这本书是一部里程碑式的作品，被誉为21世纪太平洋战争史的集大成之作。\n战役第二次世界大战太平洋战场的战役与亚洲和欧洲战场不同。欧亚大陆上的战争大多局限于陆地，而太平洋战场则聚焦于海战和两栖登陆。从莱特湾海战消灭日军海军主力开始，到胜利登陆硫磺岛和冲绳岛，再到轰炸日本本土，以及在广岛和长崎投下的两颗原子弹，无一不是反法西斯斗争中重要的一环。\n莱特湾海战1949年10月，美军为了收复菲律宾，对莱特岛进行了两栖登陆，日军为了阻止美军的进攻，派出了四支舰队进行反击，试图包围和摧毁美军的登陆部队和航空母舰。莱特湾战役是太平洋战争中最大规模的海战，也是历史上最后一次主力舰之间的对决。这场战役中美军凭借情报和指挥优势，以及日军的战术失误和舰载机短缺，重创了日军海军主力。这场战役日军损失了三艘航空母舰和三艘战列舰，以及大量的飞机和人员，美军则只损失了一艘轻型航空母舰和几艘驱逐舰。这场战役标志着日本海军的实力彻底崩溃，美军的制海权和制空权得到了巩固。\n从此之后，海上力量的主宰不再是战列舰，而是航空母舰。航母起降战机对敌方舰队进行轰炸打击的战术取代了传统的巨炮对轰。\n硫磺岛战役硫磺岛战役是太平洋战争中最惨烈的一场岛屿战役，也是美军在太平洋战场上付出最大代价的一场登陆战。硫磺岛是一个位于日本本土和马里亚纳群岛之间的火山岛，对美军的战略意义在于它可以作为轰炸日本本土的B-29轰炸机的中途基地。这场战役中美军为了占领该岛屿，派出了7万多名海军陆战队员，对抗日军的两万多名守军。日军利用岛上的地形和地下隧道，进行了顽强的抵抗，给美军造成了巨大的伤亡。最终美军在36天的战斗中夺下了该岛，死伤近3万人。日军则几乎全军覆没，只有一千多人被俘。美军虽最终占领了硫磺岛，但还是付出了惨痛的代价。\n这是一场充满了悲壮和悲哀的战役，它展现了战争的残酷和惨烈。由于日本军国主义的大行其道，无数年轻人在其鼓动之下走向战场付出鲜血和生命。而战争的双方都为此付出了惨痛的代价。\n冲绳岛战役 1945年4月，美军发动了冲绳岛登陆。这场战役是太平洋战争中规模最大的两栖登陆行动，这场战役中美军在太平洋战场上遭遇到的日军部队也是参战以来遇到的最强大的日军部队。冲绳岛是位于日本本土和台湾之间的岛屿，拿下该岛之后，美军可以通过该岛登陆日本本土。在登陆过程中美军派出了海陆空近50万人的部队，对抗日军的11万守军和15万民兵。日军在岛的南部设立了坚固的防御工事，并以自杀式冲击阻止美军的登陆。在经过82天的战斗之后，美军付出了死伤近5万人的代价成功攻下冲绳岛。在登陆过程中，海军陆战队的最高指挥官西蒙·巴克纳尔将军阵亡，他也是美国在二战期间唯一一位阵亡的四星上将。此次战役日军损失10万正规军和10余万平民武装，其中很多都死于自杀式冲锋袭击。此役之后，日军的抵抗决心更加速了美国对日本使用原子弹的决定。\n火烧东京为了胁迫日本投降，打击日本抵抗决心，在取得了硫磺岛登陆的战果之后，美军开始启动轰炸日本本土的计划。自1944年11月起，东京历经106次大小空袭，造成了24至90万人丧生。\n1945年3月10日的东京大轰炸，是美国对东京实施的最惨烈的一次空袭，也是人类历史上最致命的一次轰炸。美国派出了334架B-29轰炸机，投掷了约1700吨的燃烧弹，引发了一场火灾旋风，摧毁了东京的41平方公里的区域，造成了约10万人死亡，100万人无家可归，以及大量的工业和基础设施的损失。这场大轰炸的战略目的是为了摧毁日本的工业和基础设施，削弱日本的战争能力，同时也为了打击日本的士气和意志，迫使日本投降或接受和平条件。这次轰炸尽管对日本造成了巨大损失，但是并没有达到预期的目的，日本政府和军方仍然拒绝投降或谈判，甚至加强了对美国的敌意和抵抗。\n1945年5月25日，美国再一次派出轰炸机对东京进行轰炸。这是美国对东京实施的最大规模的一次空袭，也是美国对日本本土的最后一次轰炸。美国派出了470架B-29轰炸机，投掷了约3000吨的炸弹，包括燃烧弹和高爆弹，摧毁了东京的36平方公里的区域，造成了约7,000人死亡，10万人受伤，以及大量的建筑物被毁。这次轰炸进一步摧毁了日本的城市和经济，但是也没有达到预期的目的，日本政府和军方仍然坚持抵抗，甚至准备了大量的特攻部队和民兵，以对抗美军的登陆。\n原子弹下无冤魂1945年8月，美国为迫使日本投降，同时为了避免登陆日本本岛作战从而产生巨大伤亡，在广岛和长崎投下了两颗原子弹。这两次轰炸直接造成了约21万人死亡，数十万人重伤，同时无数周边平民遭受了大量核辐射和后遗症。\n两次轰炸极大打击了日本军国主义集团想要凭借日本本土优势进行拼死抵抗的决心，促进了日本政府于1945年8月15日宣布无条件投降。\n结语《诸神的黄昏：1944—1945，从莱特湾战役到日本投降》是一部精彩的军事史著作，它为我展现了太平洋战争的全貌和细节，以及这场战争对当今世界的意义。通过阅读这本书，我学到了很多关于战争的知识和感受，也对战争的复杂和多元，以及战争的残酷和惨烈，有了更深刻的理解和思考。我认为这本书是一部值得推荐的作品，它不仅是一部历史的记录，也是一部人性的探索，也是一部文化的对话。\n第二次世界大战之于今日，不仅奠定了当今世界的格局，重塑了世界秩序，也影响了科技、文化、思想等方方面面。第二次世界大战结束了欧洲的霸权，促进了美国和苏联的崛起，但也导致了冷战的出现。民族解放运动的蓬勃展开，让自由和解放的思想理念深入人心。不少战前殖民地纷纷独立，建立了属于亚非拉等地第三世界人们自己的共和国。第二次世界大战极大推进了科学和技术的发展，尤其是航空、原子能技术、计算机等领域，为今天的信息社会和数字化时代奠定了基础。第二次世界大战期间各国通力合作，对抗法西斯主义的扩张，促进了战后各国之间的文化和思想的交流和碰撞，为今天的多元化和全球化提供了动力和启示。\n这本书中获得的启发和思考，让我得以审视自二战结束以来那七十余年的风风雨雨和波澜壮阔。好战必亡，忘战必危。二战作为人类历史上规模最大的战争，无论何时重温那段历史，都能激发起人们对于和平和发展的向往。\n","slug":"《诸神的黄昏》读书报告","date":"2023-11-28T05:18:16.000Z","categories_index":"","tags_index":"读书笔记","author_index":"ClaRn"},{"id":"273e79725e1d4628435ad0a0f23019d3","title":"算法设计与分析-课后练习23","content":"课后练习23\n\n\npythonproblem1 = &#123;\n    &#39;N&#39;: 5,\n    &#39;M&#39;: 12,\n    &#39;p&#39;: (10,15,6,8,4),\n    &#39;w&#39;: (4,6,3,4,2)\n&#125;\n\nproblem2 = &#123;\n    &#39;N&#39;: 5,\n    &#39;M&#39;: 15,\n    &#39;p&#39;: (4,4,5,8,9),\n    &#39;w&#39;: (4,4,5,8,9)\n&#125;pythondef tp(x, w):\n    tp_num = 0\n    for i in range(len(x)):\n        tp_num += x[i] * w[i]\n    if len(x) &lt; len(w):\n        tp_num += w[len(x)]\n    return tp_num\n\ndef bp(x, w, p, M):\n    bp_num = 0\n    cur_w = 0\n    for i in range(len(x)):\n        bp_num += p[i] * x[i]\n        cur_w += x[i] * w[i]\n    if len(x) &lt; len(p):\n        bp_num += (M-cur_w+1) * p[len(x)]/w[len(x)]\n        \n    return bp_num\n\ndef deep_traverse(M, p, w, x, answers):\n    global L\n    \n    if len(x) == len(p):\n        bp_tmp = bp(x, w, p, M)\n        if bp_tmp &gt; L:\n            L = bp_tmp\n        # print(&#39;L=%.2f&#39; % L)\n        answers.append(x)\n        return\n    left_child_x = x+[1]\n    right_child_x = x+[0]\n    if tp(x, w) &lt;= M:\n        deep_traverse(M,p,w,left_child_x, answers)\n    \n    bp_num = bp(x,w,p,M)\n    if bp_num &gt;= L:\n        deep_traverse(M,p,w,right_child_x, answers)\n    \nL = 0\ndef pack_problem(problem):\n    global L\n    N = problem[&#39;N&#39;]\n    M = problem[&#39;M&#39;]\n    p = problem[&#39;p&#39;]\n    w = problem[&#39;w&#39;]\n    L = 0\n    \n    answers = []\n    deep_traverse(M, p, w, [], answers)\n    answers.sort(key=lambda item:bp(item, w, p, M), reverse=True)\n    max_bp = bp(answers[0], w, p, M)\n    for item in answers:\n        bp_val = bp(item, w, p, M)\n        if bp_val == max_bp:\n            print(&#39;解向量=%s 最大效益值=%d&#39; % (str(item), bp_val))\n    pythonpack_problem(problem1)txt解向量=[1, 1, 0, 0, 1] 最大效益值=29pythonpack_problem(problem2)txt解向量=[0, 0, 1, 0, 1] 最大效益值=14","slug":"算法设计与分析-课后练习23","date":"2023-11-26T00:49:12.000Z","categories_index":"基础,作业,算法","tags_index":"作业,算法","author_index":"ClaRn"},{"id":"35bd5c162e51440561c9d41f746e68d2","title":"算法设计与分析-课后练习22","content":"课后练习22\n\n\npythonW = (5,7,10,12,15,18,20)\nsum_w = sum(W)\nprint(&#39;sum(W) = %d&#39; % sum_w)txtsum(W) = 87pythonM = 35\nleast_sum = sum_w - M\nprint(&#39;bottom edge = %d&#39; % least_sum)txtbottom edge = 52pythondef condition1(X):\n    sum_part1 = 0\n    for i in range(len(X)):\n        sum_part1 += W[i] * X[i]\n    \n    sum_part2 = 0\n    for i in range(len(X), len(W)):\n        sum_part2 += W[i]\n    return sum_part1 + sum_part2 &gt;= M\n\ndef condition2(X):\n    sum_part1 = 0\n    for i in range(len(X)):\n        sum_part1 += W[i] * X[i]\n    if len(X) &gt;= len(W):\n        return sum_part1 &lt;= M\n    return sum_part1 + W[len(X)] &lt;= Mpythonstart = (0, 1, sum_w, [])\nline = [start]\ngraph = &#39;&#39;&#39;graph TD;\\n&#39;&#39;&#39;\nanswers = []\n\nwhile len(line) != 0:\n    head = line.pop(0)\n    if head[0] == M:\n        answers.append(head)\n        continue\n    if head[1]-1 &gt;= len(W):\n        continue\n    head_str = &#39;%d,%d,%d&#39; % (head[0],head[1],head[2])\n    son_selected = (head[0]+W[head[1]-1], head[1]+1, head[2] - W[head[1]-1], head[3]+[1])\n    son_unselected = (head[0], head[1]+1, head[2] - W[head[1]-1], head[3]+[0])\n    if condition2(son_selected[3]) or son_selected[0] == M:\n        line.append(son_selected)\n        son_selected_str = &#39;%d,%d,%d&#39; % (son_selected[0], son_selected[1], son_selected[2])\n        graph += &#39;    %s -- %s --&gt; %s\\n&#39; % (head_str, &#39;x(%d)=%d&#39;%(head[1],1), son_selected_str)\n        print(&#39;x(%d):(%d,%d,%d) X:%s&#39;%(head[1], son_selected[0], son_selected[1], son_selected[2], str(son_selected[3])))\n    if (condition1(son_unselected[3]) and condition2(son_unselected[3])) or son_unselected[0] == M:\n        line.append(son_unselected)\n        son_unselected_str = &#39;%d,%d,%d&#39; % (son_unselected[0], son_unselected[1], son_unselected[2])\n        graph += &#39;    %s -- %s --&gt; %s\\n&#39; % (head_str, &#39;x(%d)=%d&#39;%(head[1],0), son_unselected_str)\n        print(&#39;x(%d):(%d,%d,%d) X:%s&#39;%(head[1], son_unselected[0], son_unselected[1], son_unselected[2], str(son_unselected[3])))\n    txtx(1):(5,2,82) X:[1]\nx(1):(0,2,82) X:[0]\nx(2):(12,3,75) X:[1, 1]\nx(2):(5,3,75) X:[1, 0]\nx(2):(7,3,75) X:[0, 1]\nx(2):(0,3,75) X:[0, 0]\nx(3):(22,4,65) X:[1, 1, 1]\nx(3):(12,4,65) X:[1, 1, 0]\nx(3):(15,4,65) X:[1, 0, 1]\nx(3):(5,4,65) X:[1, 0, 0]\nx(3):(17,4,65) X:[0, 1, 1]\nx(3):(7,4,65) X:[0, 1, 0]\nx(3):(10,4,65) X:[0, 0, 1]\nx(3):(0,4,65) X:[0, 0, 0]\nx(4):(12,5,53) X:[1, 1, 0, 0]\nx(4):(15,5,53) X:[1, 0, 1, 0]\nx(4):(17,5,53) X:[1, 0, 0, 1]\nx(4):(5,5,53) X:[1, 0, 0, 0]\nx(4):(17,5,53) X:[0, 1, 1, 0]\nx(4):(19,5,53) X:[0, 1, 0, 1]\nx(4):(7,5,53) X:[0, 1, 0, 0]\nx(4):(10,5,53) X:[0, 0, 1, 0]\nx(4):(12,5,53) X:[0, 0, 0, 1]\nx(4):(0,5,53) X:[0, 0, 0, 0]\nx(5):(12,6,38) X:[1, 1, 0, 0, 0]\nx(5):(15,6,38) X:[1, 0, 1, 0, 0]\nx(5):(17,6,38) X:[1, 0, 0, 1, 0]\nx(5):(5,6,38) X:[1, 0, 0, 0, 0]\nx(5):(17,6,38) X:[0, 1, 1, 0, 0]\nx(5):(7,6,38) X:[0, 1, 0, 0, 0]\nx(5):(10,6,38) X:[0, 0, 1, 0, 0]\nx(5):(12,6,38) X:[0, 0, 0, 1, 0]\nx(5):(15,6,38) X:[0, 0, 0, 0, 1]\nx(5):(0,6,38) X:[0, 0, 0, 0, 0]\nx(6):(15,7,20) X:[1, 0, 1, 0, 0, 0]\nx(6):(35,7,20) X:[1, 0, 0, 1, 0, 1]\nx(6):(35,7,20) X:[0, 1, 1, 0, 0, 1]\nx(6):(15,7,20) X:[0, 0, 0, 0, 1, 0]\nx(7):(35,8,0) X:[1, 0, 1, 0, 0, 0, 1]\nx(7):(35,8,0) X:[0, 0, 0, 0, 1, 0, 1]pythonprint(graph)txtgraph TD;\n    0,1,87 -- x(1)=1 --&gt; 5,2,82\n    0,1,87 -- x(1)=0 --&gt; 0,2,82\n    5,2,82 -- x(2)=1 --&gt; 12,3,75\n    5,2,82 -- x(2)=0 --&gt; 5,3,75\n    0,2,82 -- x(2)=1 --&gt; 7,3,75\n    0,2,82 -- x(2)=0 --&gt; 0,3,75\n    12,3,75 -- x(3)=1 --&gt; 22,4,65\n    12,3,75 -- x(3)=0 --&gt; 12,4,65\n    5,3,75 -- x(3)=1 --&gt; 15,4,65\n    5,3,75 -- x(3)=0 --&gt; 5,4,65\n    7,3,75 -- x(3)=1 --&gt; 17,4,65\n    7,3,75 -- x(3)=0 --&gt; 7,4,65\n    0,3,75 -- x(3)=1 --&gt; 10,4,65\n    0,3,75 -- x(3)=0 --&gt; 0,4,65\n    12,4,65 -- x(4)=0 --&gt; 12,5,53\n    15,4,65 -- x(4)=0 --&gt; 15,5,53\n    5,4,65 -- x(4)=1 --&gt; 17,5,53\n    5,4,65 -- x(4)=0 --&gt; 5,5,53\n    17,4,65 -- x(4)=0 --&gt; 17,5,53\n    7,4,65 -- x(4)=1 --&gt; 19,5,53\n    7,4,65 -- x(4)=0 --&gt; 7,5,53\n    10,4,65 -- x(4)=0 --&gt; 10,5,53\n    0,4,65 -- x(4)=1 --&gt; 12,5,53\n    0,4,65 -- x(4)=0 --&gt; 0,5,53\n    12,5,53 -- x(5)=0 --&gt; 12,6,38\n    15,5,53 -- x(5)=0 --&gt; 15,6,38\n    17,5,53 -- x(5)=0 --&gt; 17,6,38\n    5,5,53 -- x(5)=0 --&gt; 5,6,38\n    17,5,53 -- x(5)=0 --&gt; 17,6,38\n    7,5,53 -- x(5)=0 --&gt; 7,6,38\n    10,5,53 -- x(5)=0 --&gt; 10,6,38\n    12,5,53 -- x(5)=0 --&gt; 12,6,38\n    0,5,53 -- x(5)=1 --&gt; 15,6,38\n    0,5,53 -- x(5)=0 --&gt; 0,6,38\n    15,6,38 -- x(6)=0 --&gt; 15,7,20\n    17,6,38 -- x(6)=1 --&gt; 35,7,20\n    17,6,38 -- x(6)=1 --&gt; 35,7,20\n    15,6,38 -- x(6)=0 --&gt; 15,7,20\n    15,7,20 -- x(7)=1 --&gt; 35,8,0\n    15,7,20 -- x(7)=1 --&gt; 35,8,0绘制状态空间树如下：\n\n所有M子集为：\npythonfor item in answers:\n    print(item[3])txt[1, 0, 0, 1, 0, 1]\n[0, 1, 1, 0, 0, 1]\n[1, 0, 1, 0, 0, 0, 1]\n[0, 0, 0, 0, 1, 0, 1]","slug":"算法设计与分析-课后练习22","date":"2023-11-26T00:48:46.000Z","categories_index":"基础,作业,算法","tags_index":"作业,算法","author_index":"ClaRn"},{"id":"ae6525a3e493be521850258ed1ec57e9","title":"对数几率回归(Logistic Regression)","content":"对数几率回归模型分类任务中，在给定输入的情况下，概率密度函数为：\n线性模型中，期望表示给定的情况下，的概率，取值为区间\n使用sigmoid函数将的范围转换到，sigmoid函数也被称为对数几率函数或者logit函数。\n对数几率回归实质上是一种分类模型。\nsigmoid函数\n函数图像如下：\n对数几率一个事件的几率(odds)为该事件发生的概率与不发生的概率的比值：\n两边同取log：\n\n得到对数几率\n\n当时， 的类别取\n当时， 的类别取\n当时， 的概率和 的概率相等，此时𝒙位于决策面上。可将 分类到任意一类，或拒绝作出判断\n\n分类任务的损失函数0-1损失0-1损失在预测正确时损失记为0，错误时损失记为1 。\n0-1损失不连续，优化计算不方便。\n交叉熵损失交叉熵损失亦被称为负log似然损失。\n\n对数几率回归采用交叉熵损失函数，且必须加正则项，正则项可以用L1正则、L2正则和L1+L2正则。\n对数几率回归的优化求解对数几率回归模型没有解析解，只有迭代解\n\n一阶：梯度下降、随机梯度下降（SGD）、随机平均梯度法（SAG）、随机平均梯度法改进版（SAGA）、共轭梯度、坐标轴下降\n二阶：牛顿法及拟牛顿法（BFGS、L-BFGS）\n\n正则项处理与线性回归相同。\n梯度训练集上的损失函数和部分有：\n则梯度：\n海森矩阵损失函数和的梯度为\n则海森矩阵为：\n是正定矩阵，梯度下降可以找到最小值\n牛顿法求解目标函数极值海森矩阵如下：\n牛顿法迭代公式为：\n牛顿法求解步骤：\n\n从开始，初始化为随机值\n计算目标函数在的梯度和海森矩阵\n计算移动方向：\n根据迭代公式更新的值：\n判断是否满足迭代终止条件。满足则返回最佳参数\n\n牛顿法需要计算二阶偏导，这使得计算过程过于复杂英雌通常使用拟牛顿法构造出近似海森矩阵的正定对称矩阵，进而逐步优化目标函数。\n令损失函数和的梯度为海森矩阵为则迭代公式可化简为：\n分类模型的评价指标正确率其中为示性函数，当括号中的条件满足时函数值为，否则为\n负log似然损失（交叉熵损失）\n合页损失（SVM中的损失函数）\n混淆矩阵对类分类问题，混淆矩阵为的矩阵\n矩阵的第行第列的元素值表示真实类别标签为类的样本预测为第类的样本数目，因此矩阵对角线上的元素越大说明模型分类效果越好。\n\nPrecision 精准率/查准率：在所有被预测为正的样本中实际为正的样本的比例正样本结果中的预测准确程度\nRecall 召回率/查全率: 在实际为正的样本中被预测为正样本的比例\nFPR(False Positive Rate) 假阳率: 在实际为负的样本中被预测为正样本的比例\nF1分数：Precision 和Recall调和平均值\nMCC Matthews相关性系数：用一个值综合混淆矩阵，度量真实值和预测值之间的相关性,若分母中任意一对括号相加之和为0，则整个MCC矩阵的值为0 。MCC值在之间，其中：\n1：完美分类器\n0：随机分类器\n-1：所有预测结果和实际相反\n\n\n\n$$Precision = \\frac{TP}{\\hat{N}+} \\Recall = \\frac{TP}{N+} \\FPR = \\frac{FP}{N_-} \\F1 = \\frac{2(Precision \\times Recall)}{Precision + Recall} \\MCC = \\frac{TP \\times TN - FP \\times FN}{\\sqrt{(TP+FP)(TP+FN)(TN+FP)(TN+FN)}}$$\nPR曲线使用精准率和召回率绘制出的曲线。用于稀有事件检测，如目标检测、信息检索、推荐系统。横轴为Recall，纵轴为Precision。\n\nPR曲线下的面积又叫AP，是对不同召回率点上的精确率进行平均后的值。\nROC曲线使用召回率和假阳率绘制出的曲线。在一些列阈值上运行检测器，并画出TPR和FPR为阈值τ的隐式函数，其中横轴为FPR，纵轴为TPR。\n\nROC曲线越片左上角表示分类器性能越好。ROC曲线下的面积取值范围，表示随机猜测分类器，表示完美分类。\n","slug":"对数几率回归","date":"2023-11-23T05:17:24.000Z","categories_index":"基础,机器学习","tags_index":"机器学习,模式识别","author_index":"ClaRn"},{"id":"5a4ab85065f9d4565d494efb3b62b3fd","title":"回归任务","content":"回归任务在监督学习中，给定数据，其中为训练样本数目，为样本索引，为第个样本的输入特征，为对应的输出/响应。\n当时，该监督学习任务为一个回归任务。根据训练样本，学习一个从输入到输出的映射。\n机器学习三要素：\n\n函数集合\n目标函数:函数的好坏\n优化算法：找到最佳函数\n\n线性回归线性回归是指函数集合为输入特征的线性组合，即假设输出与输入之间的关系为线性关系。\n\n 为特征维度，为特征索引，为截距项\n回归任务目标函数\n为损失函数，为正则项\nL2损失L2损失即预测残差的平方，预测残差\n\n训练集上所有训练数据的预测残差的平方和记为:\n最小L2损失函数等价于高斯白噪声下的极大似然。在回归任务中，令模型预测值与真实值之间的差异为噪声。假设噪声相互独立且与输入无关，且的分布为0均值的正态分布，即，则 ,且 ，所以有\n\nL2损失处处连续，优化求解方便\n但是L2损失对噪声点敏感\n\n负log似然损失极大似然估计等价于负log似然最小，因此负log似然也被称为一种损失函数：负log似然损失。\nL2损失是高斯白噪声假设下的负log似然损失。\n胡伯损失L1损失就是，但是L1损失在处不连续，优化求解麻烦。\nHuber损失综合了L1损失和L2损失，Huber损失函数如下：\n\n线性回归模型的正则项正则项加入的目的是为了防止模型过拟合。正则项通常与模型的复杂度有关。\n线性回归模型结构简单，因此可以无需正则项，此时目标函数退化为最小二乘法。\n令模型拟合的函数，正则项为，为模型参数，为参数的维度\n\nL2正则函数:\n\nL1正则函数:\n\n\n正则项不对截距项惩罚，因为截距项不影响模型的复杂度。\n岭回归岭回归就是使用L2损失函数和L2正则函数的线性回归模型。\n岭回归的目标函数\nLassoLasso是使用L2损失函数和L1正则函数的线性回归模型。\nLasso的目标函数\n弹性网络正则项将L1正则和L2正则合并，使用L2损失函数。弹性网络的目标函数\n","slug":"回归任务","date":"2023-11-21T23:50:02.000Z","categories_index":"基础,机器学习","tags_index":"机器学习,模式识别","author_index":"ClaRn"},{"id":"12c939ce01f114334baac440d0498eaf","title":"Logistic回归&SVM作业","content":"\n\n\n\n\n\nTIP\n给定如下4个输入特征的4个样本，采用Logistic回归，\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n初始化权重，，采用梯度下降，计算每个样本上的梯度；\n\n对于，有：\n则梯度：\n对于，有：\n则梯度：\n对于，有：\n则梯度：\n对于，有：\n则梯度：\n\n轮梯度下降后，得到参数估计为，。给定测试样本，给出样本的预测结果。\n\n故样本的预测结果为\n\n\n\n\n\n\n\nTIP\n根据下表，绘制ROC曲线（阈值分别取0、0.2、0.4、0.6、0.8和1），并解释你是选择使用分类器1还是分类器2。\n\n\n\nclass\n分类器1:\n分类器2:\n\n\n\nP\n0.83\n0.92\n\n\nN\n0.78\n0.62\n\n\nP\n0.62\n0.53\n\n\nN\n0.48\n0.49\n\n\nN\n0.32\n0.38\n\n\nN\n0.22\n0.28\n\n\n\n\n\n对于分类器1：\n当阈值取时：得到ROC曲线上的点\n当阈值取时：得到ROC曲线上的点\n当阈值取时：得到ROC曲线上的点\n当阈值取时：得到ROC曲线上的点\n当阈值取时：得到ROC曲线上的点\n当阈值取时：得到ROC曲线上的点\n根据求得的顶点：绘制得到分类器1的ROC曲线：\n对于分类器2：\n当阈值取时：得到ROC曲线上的点\n当阈值取时：得到ROC曲线上的点\n当阈值取时：得到ROC曲线上的点\n当阈值取时：得到ROC曲线上的点\n当阈值取时：得到ROC曲线上的点\n当阈值取时：得到ROC曲线上的点\n根据求得的顶点：绘制得到分类器2的ROC曲线：\n经过对比可知，分类器1的AUC大于分类器2的AUC，可以看出分类器1的性能更好。故应该选择分类器1完成分类任务。\n\n\n\n\n\n\n\nTIP\n给定下列3个样本点，请计算硬间隔SVM分类器\n\n\n\n\n\n\n\n\n3\n1\n\n\n1\n1\n\n\n-1\n-1\n\n\n\n\n\n可求得 ，故将样本代入可求得：硬间隔SVM分类器\n\n\n\n\n\n\n\nTIP\n软间隔SVM分类器通过引入松弛变量来放松优化约束，允许在分类中出现错误。原始形式的软间隔SVM分类器如下：。。以下说法是否正确？并给出理由。\n\n\n增加超参数C倾向于减少训练误差。\n正确。增加超参数C意味着更强调对误分类的惩罚，从而促使模型更好地拟合训练数据。较大的值将导致更复杂的模型，可能会在训练数据上表现得更好，但也可能增加过拟合的风险\n\n\n增加超参数C往往会降低间隔\n正确，增加超参数C会增大对错误分类的惩罚，使间隔降低。\n\n\n硬间隔SVM是超参数C设置为0的软间隔的特殊情况。\n错误，硬间隔SVM是超参数C设置为无穷大时的特殊情况，此时间隔无穷小。\n\n\n增加超参数C往往会降低对异常值的敏感性。\n正确，增加超参数C会增大对模型误分类的惩罚，使模型更关注减小误分类从而降低对异常值的敏感性。\n\n\n\n\n\n\n\n\n\n\nTIP\n考虑以下4个由不同核函数和/或松弛惩罚的导致的SVM决策边界。标签的两类训练数据分别用三角形和正方形表示。支持向量被描述为实心三角形和正方形。请将每个决策边界与下面中最可能的优化设置相匹配，并简要说明配对的理由。\n\n\n\n\n（A） 的软间隔线性SVM。（B） 的软间隔线性SVM。（C） 核函数为的硬间隔SVM。（D） 核函数为的硬间隔SVM。\n\n\n图像(a) 与 优化设置(B) 配对。图像(a) 的分类间隔更小，因此C的值应该更大。\n图像(b) 与 优化设置(D) 配对。图像(b) 的边缘更加平滑，因此核函数也应该更平滑。\n图像(c) 与 优化设置(A) 配对。图像(c) 的分类间隔更大，因此C的值应该更小。\n图像(d) 与 优化设置(C) 配对。图像(d) 的边缘更锐利，因此核函数也应该更锐利。\n\n","slug":"Logistic回归&SVM作业","date":"2023-11-21T07:09:37.000Z","categories_index":"基础,机器学习,作业","tags_index":"机器学习,作业,模式识别","author_index":"ClaRn"},{"id":"54494e1e251f042b5032d44b74312b75","title":"算法设计与分析-课后练习10","content":"课后练习10 利用贪心策略求解背包问题\n\n\npythonn = 4\nM = 54\np = (20, 16, 10, 18)\nw = (16, 12, 15, 24)python# 对p和w根据p/w进行排序\np_w = []\nfor i in range(n):\n    p_w.append((p[i], w[i], i+1))\np_w.sort(key=lambda item: item[0]/item[1], reverse=True)python# 选择物品\nanswer_vec = []\npack_left_room = M\nsum_px = 0\nfor j in range(n):\n    if pack_left_room &gt; 0:\n        item = p_w[j]\n        item_name = &#39;物品&#39;+str(item[2])\n        if pack_left_room &gt;= item[1]:\n            answer_vec.append((item_name, &#39;1&#39;))\n            sum_px += item[0] * 1\n            pack_left_room -= item[1]\n        else:\n            r = str(pack_left_room) + &#39;/&#39; + str(item[1])\n            answer_vec.append((item_name, r))\n            sum_px += item[0] * pack_left_room / item[1]\n            pack_left_room -= pack_left_room\n    else:\n        break    pythons = &#39;解向量 = [&#39;\nfor item in answer_vec:\n    s += &#39; %s个%s,&#39; % (item[1], item[0])\ns = s[:-1] + &#39; ]&#39;\nprint(s)\ns = &#39;Σpx = %.3f&#39; % sum_px\nprint(s)txt解向量 = [ 1个物品2, 1个物品1, 1个物品4, 2/15个物品3 ]\nΣpx = 55.333","slug":"算法设计与分析-课后练习10","date":"2023-11-21T02:05:27.000Z","categories_index":"基础,作业,算法","tags_index":"作业,算法","author_index":"ClaRn"},{"id":"90d9fa88c77b8abbe860172a727a4e03","title":"算法设计与分析-课后练习11","content":"课后练习11 求背包问题的最优解\n\n\npythonn = 7\nM = 15\np = [10, 5, 15, 7, 6, 18, 3]\nw = [2, 3, 5, 7, 1, 4, 1]python# 对p和w根据p/w进行排序\np_w = []\nfor i in range(n):\n    p_w.append((p[i], w[i], i+1))\np_w.sort(key=lambda item: item[0]/item[1], reverse=True)python# 选择物品\nanswer_vec = []\npack_left_room = M\nsum_px = 0\nfor j in range(n):\n    if pack_left_room &gt; 0:\n        item = p_w[j]\n        item_name = '物品'+str(item[2])\n        if pack_left_room &gt;= item[1]:\n            answer_vec.append((item_name, '1'))\n            sum_px += item[0] * 1\n            pack_left_room -= item[1]\n        else:\n            r = str(pack_left_room) + '/' + str(item[1])\n            answer_vec.append((item_name, r))\n            sum_px += item[0] * pack_left_room / item[1]\n            pack_left_room -= pack_left_room\n    else:\n        break    pythons = '解向量 = ['\nfor item in answer_vec:\n    s += ' %s个%s,' % (item[1], item[0])\ns = s[:-1] + ' ]'\nprint(s)\ns = 'Σpx = %.3f' % sum_px\nprint(s)txt解向量 = [ 1个物品5, 1个物品1, 1个物品6, 1个物品3, 1个物品7, 2/3个物品2 ]\nΣpx = 55.333下面计算其它解向量的Σpx\npython# 我们将每一种物品计算其被排除后的解向量以及Σpx\n\nfor i in range(n):\n    ans_vec = []\n    left_room = M\n    sum_px_j = 0\n    for j in range(n):\n        if i == j:\n            continue\n        if left_room &lt;= 0:\n            break\n        item_name = '物品'+str(j + 1)\n        if left_room &gt; 0:\n            ans_vec.append((item_name, '1'))\n            left_room -= w[j]\n            sum_px_j += p[j] * 1\n        else:\n            r = str(left_room) + '/' + str(w[j])\n            ans_vec.append((item_name, r))\n            sum_px_j += p[j] * left_room / w[j]\n            left_room -= left_room\n        \n    s = '解向量 = ['\n    for item in ans_vec:\n        s += ' %s个%s,' % (item[1], item[0])\n    s = s[:-1] + ' ]'\n    print(s)\n    s = 'Σpx = %.3f' % sum_px_j\n    print(s)txt解向量 = [ 1个物品2, 1个物品3, 1个物品4 ]\nΣpx = 27.000\n解向量 = [ 1个物品1, 1个物品3, 1个物品4, 1个物品5 ]\nΣpx = 38.000\n解向量 = [ 1个物品1, 1个物品2, 1个物品4, 1个物品5, 1个物品6 ]\nΣpx = 46.000\n解向量 = [ 1个物品1, 1个物品2, 1个物品3, 1个物品5, 1个物品6 ]\nΣpx = 54.000\n解向量 = [ 1个物品1, 1个物品2, 1个物品3, 1个物品4 ]\nΣpx = 37.000\n解向量 = [ 1个物品1, 1个物品2, 1个物品3, 1个物品4 ]\nΣpx = 37.000\n解向量 = [ 1个物品1, 1个物品2, 1个物品3, 1个物品4 ]\nΣpx = 37.000通过求解其它解向量，我们可以发现 贪心策略求解得到的解向量FG(I)=最优解FO(I)。因此可以得到：\n当物品按照Wi的降序排列时，由于贪心策略的目标函数是Σpx最大化，因此并不会对解向量产生影响。\n","slug":"算法设计与分析-课后练习11","date":"2023-11-21T02:04:50.000Z","categories_index":"基础,作业,算法","tags_index":"作业,算法","author_index":"ClaRn"},{"id":"ac8a4dc9a4a094a930f27a99be0c9864","title":"算法设计与分析-课后练习12","content":"课后练习12 对作业排序问题的证明\n\n根据定理4.3：\n可知：\n\n当是一个可行解时，必有一个作业执行序列使得所有作业按期执行\n该作业执行序列中的作业依据降序排列\n对于任意作业，如果它的执行期限是，且时间片是空的，则分配该时间片。\n如果时间片非空，则向前寻找非空时间片，故时间片一定是非空的。\n\n问题得证\n","slug":"算法设计与分析-课后练习12","date":"2023-11-21T02:03:57.000Z","categories_index":"基础,作业,算法","tags_index":"作业,算法","author_index":"ClaRn"},{"id":"936c542a29ffbd776c8edaf03bb7198c","title":"算法设计与分析-课后练习13-1","content":"课后练习13-1\n\n首先计算斐波那契数列\npython def fibonacci(n):\n    if n == 0 or n == 1:\n        return 1\n    return fibonacci(n-1) + fibonacci(n-2)\n\nfibonacci_nums = []\nfor i in range(8):\n    fibonacci_nums.append(fibonacci(i))pythonfibonacci_numstxt[1, 1, 2, 3, 5, 8, 13, 21]下面生成这组字符的哈夫曼树\npythonfib_num_chars = []\nbase_char = &#39;a&#39;\nfor i in range(len(fibonacci_nums)):\n    fib_num_chars.append((chr(ord(base_char) + i), fibonacci_nums[i], None))python# 哈夫曼树节点\nclass TreeNode:\n    def __init__(self, data, value):\n        self.data = data\n        self.value = value\n        self.left = None\n        self.right = None\n        \ndef insert_tree(tree_node:TreeNode):\n    tree_val = tree_node.value\n    for index in range(len(fib_num_chars)):\n        if fib_num_chars[index][1] &gt; tree_val:\n            fib_num_chars.insert(index, (&#39;&#39;, tree_val, root))\n            break\n\n# 斐波那契数列按照升序排列，故可以直接取其首端两个值构建哈夫曼树节点\nwhile len(fib_num_chars) &gt; 1:\n    minst1 = fib_num_chars.pop(0)\n    minst2 = fib_num_chars.pop(0)\n    if minst1[2] is None and minst2[2] is None:\n        m1_t_node = TreeNode(minst1[0], minst1[1])\n        m2_t_node = TreeNode(minst2[0], minst2[1])\n        root_val = minst1[1] + minst2[1]\n        root = TreeNode(None, root_val)\n        root.left = m1_t_node\n        root.right = m2_t_node\n        insert_tree(root)\n    elif minst1[2] is not None and minst2[2] is not None:\n        root_val = minst1[1] + minst2[1]\n        root = TreeNode(None, root_val)\n        root.left = minst1[2]\n        root.right = minst2[2]\n        insert_tree(root)\n    elif (minst1[2] is None and minst2[2] is not None) or (minst1[2] is not None and minst2[2] is None):\n        tree_minst = None\n        char_minst = None\n        if minst1[2] is not None:\n            tree_minst = minst1\n            char_minst = minst2\n        if minst2[2] is not None:\n            tree_minst = minst2\n            char_minst = minst1\n        char_node = TreeNode(char_minst[0], char_minst[1])\n        root_val = char_minst[1] + tree_minst[1]\n        root = TreeNode(None, root_val)\n        root.left = tree_minst[2]\n        root.right = char_node\n        insert_tree(root)\n        \nhuffman_tree = fib_num_chars[0][2]哈夫曼树生成后遍历哈夫曼树生成哈夫曼编码\npythonhuffman_codes = &#123;&#125;\ndef traverse(tree_node:TreeNode, code=None):\n    if code is None:\n        code = []\n    if tree_node.data is None:\n        traverse(tree_node.left, code + [&#39;0&#39;])\n        traverse(tree_node.right, code + [&#39;1&#39;])\n    else:\n        huffman_codes[tree_node.data] = &#39;&#39;.join(code)\n        \ntraverse(huffman_tree)pythonhuffman_codestxt&#123;&#39;a&#39;: &#39;0000000&#39;,\n &#39;b&#39;: &#39;0000001&#39;,\n &#39;c&#39;: &#39;000001&#39;,\n &#39;d&#39;: &#39;00001&#39;,\n &#39;e&#39;: &#39;0001&#39;,\n &#39;f&#39;: &#39;001&#39;,\n &#39;g&#39;: &#39;01&#39;,\n &#39;h&#39;: &#39;1&#39;&#125;当推广到n个字符频率恰好是前n个斐波那契数时，第1个字符的哈夫曼编码为n-1个‘0’，第1个字符的哈夫曼编码为n-2个‘0’+1个‘1’，第i个字符的哈夫曼编码为n-i-1个‘0’+1个‘1’。\n","slug":"算法设计与分析-课后练习13-1","date":"2023-11-21T02:02:40.000Z","categories_index":"基础,作业,算法","tags_index":"作业,算法","author_index":"ClaRn"},{"id":"9a15442a59869df6863553b2b6be7e68","title":"算法设计与分析-课后练习13-2","content":"课后练习13-2\n\n构建无向图：\npythonimport networkx as nx\nimport matplotlib.pyplot as plt\n\ngraph = nx.Graph()\ngraph.add_nodes_from([&#39;A&#39;, &#39;B&#39;, &#39;C&#39;, &#39;D&#39;, &#39;E&#39;, &#39;F&#39;])\ngraph.add_edge(&#39;A&#39;, &#39;B&#39;, w=6, prim=0, kruskal=0)\ngraph.add_edge(&#39;A&#39;, &#39;C&#39;, w=1, prim=0, kruskal=0)\ngraph.add_edge(&#39;A&#39;, &#39;D&#39;, w=5, prim=0, kruskal=0)\ngraph.add_edge(&#39;B&#39;, &#39;C&#39;, w=5, prim=0, kruskal=0)\ngraph.add_edge(&#39;B&#39;, &#39;E&#39;, w=3, prim=0, kruskal=0)\ngraph.add_edge(&#39;C&#39;, &#39;D&#39;, w=5, prim=0, kruskal=0)\ngraph.add_edge(&#39;C&#39;, &#39;E&#39;, w=6, prim=0, kruskal=0)\ngraph.add_edge(&#39;C&#39;, &#39;F&#39;, w=4, prim=0, kruskal=0)\ngraph.add_edge(&#39;E&#39;, &#39;F&#39;, w=6, prim=0, kruskal=0)\ngraph.add_edge(&#39;F&#39;, &#39;D&#39;, w=2, prim=0, kruskal=0)\n\npos = nx.spring_layout(graph)\nnx.draw_networkx(graph, pos)\nnx.draw_networkx_edge_labels(graph, pos, nx.get_edge_attributes(graph, &#39;w&#39;))\nplt.show()\nPrim算法求最小生成树python# 设置点集A, 选取&#39;A&#39;作为初始点开始构建最小生成树\nA = set()\nA.add(&#39;A&#39;)\nmin_cost = 0\n\nwhile True:\n    if len(A) == len(graph):\n        break\n    \n    min_w = 100000000\n    min_adj = (&#39;A&#39;, &#39;A&#39;)\n    for n in A:\n        adjs = graph[n]\n        for adj in adjs:\n            if adj in A:\n                continue\n            if adjs[adj][&#39;w&#39;] &lt; min_w:\n                min_w = adjs[adj][&#39;w&#39;]\n                min_adj = (n, adj)\n    \n    graph[min_adj[0]][min_adj[1]][&#39;prim&#39;] = 1\n    A.add(min_adj[1])\n    min_cost += min_wpythonmin_costtxt15pythonnx.draw_networkx_edges(graph, pos, style=&#39;dashed&#39;)\nnx.draw_networkx_edges(graph, pos, [edge for edge in graph.edges if graph[edge[0]][edge[1]][&#39;prim&#39;] == 1], style=&#39;solid&#39;, edge_color=&#39;r&#39;)\nnx.draw_networkx_nodes(graph, pos)\nnx.draw_networkx_labels(graph, pos)\nnx.draw_networkx_edge_labels(graph, pos, nx.get_edge_attributes(graph, &#39;w&#39;))\nplt.show()\nKruskal算法求最小生成树python# 首先对边进行排序\nedges = []\nfor u,v in graph.edges:\n    edges.append((u,v,graph[u][v][&#39;w&#39;]))\nedges.sort(key=lambda item: item[2])pythonEdge_Set = set() # 边集\nNode_Set = set() # 点集\nsub_graph = nx.Graph()\nmin_cost = 0\n\ndef find_connection(n0, n1) -&gt; bool:\n    if (n0 not in Node_Set) or (n1 not in Node_Set):\n        return False\n    else:\n        connected_connection = nx.node_connected_component(sub_graph, n0)\n        return n1 in connected_connection\n    \nfor e in edges:\n    if len(Edge_Set) &lt; len(graph) - 1:\n        # 如果两个节点之间已经是联通的，则跳过\n        if find_connection(e[0], e[1]):\n            continue\n        Node_Set.add(e[0])\n        Node_Set.add(e[1])\n        Edge_Set.add(e)\n        sub_graph.add_edge(e[0], e[1])\n        graph[e[0]][e[1]][&#39;kruskal&#39;] = 1\n        min_cost += e[2]\n    else:\n        breakpythonmin_costtxt15pythonnx.draw_networkx_edges(graph, pos, style=&#39;dashed&#39;)\nnx.draw_networkx_edges(graph, pos, [edge for edge in graph.edges if graph[edge[0]][edge[1]][&#39;kruskal&#39;] == 1], style=&#39;solid&#39;, edge_color=&#39;r&#39;)\nnx.draw_networkx_nodes(graph, pos)\nnx.draw_networkx_labels(graph, pos)\nnx.draw_networkx_edge_labels(graph, pos, nx.get_edge_attributes(graph, &#39;w&#39;))\nplt.show()\n破圈法生成最小生成数pythongraph_backup = graph.copy()\n\n# 遍历所有节点并计算所有圈\nfor n in graph_backup.nodes:\n    while True:\n        cycles = nx.cycle_basis(graph_backup, n)\n        if len(cycles) == 0:\n            break\n        cycle = cycles[0]\n        max_w = 0\n        max_p = ()\n        # 得到圈中权重最大的边\n        for i in range(len(cycle)):\n            nn0 = cycle[i]\n            nn1 = cycle[(i+1)%len(cycle)]\n            if max_w &lt; graph_backup[nn0][nn1][&#39;w&#39;]:\n                max_w = graph_backup[nn0][nn1][&#39;w&#39;]\n                max_p = (nn0, nn1)\n        # 去掉圈中权重最大的边\n        graph_backup.remove_edge(max_p[0], max_p[1])pythonnx.draw(graph_backup, pos)\nnx.draw_networkx_labels(graph, pos)\nnx.draw_networkx_edge_labels(graph_backup, pos, nx.get_edge_attributes(graph_backup, &#39;w&#39;))\nplt.show()\n","slug":"算法设计与分析-课后练习13-2","date":"2023-11-21T02:00:42.000Z","categories_index":"基础,作业,算法","tags_index":"作业,算法","author_index":"ClaRn"},{"id":"3761b2378aa31c8a0afb776a92a9ec59","title":"算法设计与分析-课后练习14","content":"课后练习14\n\n\npythonimport networkx as nx\nimport matplotlib.pyplot as plt\n\ngraph = nx.DiGraph()\n\ngraph.add_edge(&#39;s&#39;, &#39;t&#39;, w=3)\ngraph.add_edge(&#39;s&#39;, &#39;y&#39;, w=5)\ngraph.add_edge(&#39;t&#39;, &#39;x&#39;, w=6)\ngraph.add_edge(&#39;t&#39;, &#39;y&#39;, w=2)\ngraph.add_edge(&#39;y&#39;, &#39;t&#39;, w=1)\ngraph.add_edge(&#39;y&#39;, &#39;x&#39;, w=4)\ngraph.add_edge(&#39;y&#39;, &#39;z&#39;, w=6)\ngraph.add_edge(&#39;x&#39;, &#39;z&#39;, w=2)\ngraph.add_edge(&#39;z&#39;, &#39;x&#39;, w=7)\ngraph.add_edge(&#39;z&#39;, &#39;s&#39;, w=3)SHORTEST-PATHS算法pythondef shortest_path(source_node):\n    s = [source_node]\n    next_n = [source_node] # 队列存储下一个待遍历的顶点\n    dict_i = [9999999 for _ in range(len(graph))]\n    dict_i[s.index(source_node)] = 0\n    while True:\n        tmp_current_node = next_n.pop(0)\n        adjs = graph[tmp_current_node]\n        for adj in adjs:\n            # 如果未遍历过该邻接点，将顶点加入待遍历队列\n            if adj not in s:\n                s.append(adj)\n                next_n.append(adj)\n            i_tmp_c = s.index(tmp_current_node)\n            i_adj = s.index(adj)\n            dict_i[i_adj] = min(adjs[adj][&#39;w&#39;] + dict_i[i_tmp_c], dict_i[i_adj]) # 比较dict中到达点adj的路径长度和通过点tmp_current_node到达点adj的长度\n        \n        if len(s) == len(graph): # 当所有顶点进入s时，停止遍历\n            return dict_i, spythondef print_nodes(source_node, dicts, nodes): # 输出函数\n    for i in range(len(dicts)):\n        if i == 0:\n            continue\n        print(&#39;%s --&gt; %s 长度:%2d &#39; % (source_node, nodes[i], dicts[i]))当源点为节点’s’时，’s’点到达各节点的最短路径长度为：pythonsource = &#39;s&#39;\ns_dict, s_nodes = shortest_path(source)\nprint_nodes(source, s_dict, s_nodes)txts --&gt; t 长度: 3 \ns --&gt; y 长度: 5 \ns --&gt; x 长度: 9 \ns --&gt; z 长度:11 当源点为节点’z’时，’z’点到达各节点的最短路径长度为：pythonsource = &#39;z&#39;\nz_dict, z_node = shortest_path(source)\nprint_nodes(source, z_dict, z_node)txtz --&gt; x 长度: 7 \nz --&gt; s 长度: 3 \nz --&gt; t 长度: 6 \nz --&gt; y 长度: 8 ","slug":"算法设计与分析-课后练习14","date":"2023-11-21T01:58:58.000Z","categories_index":"基础,作业,算法","tags_index":"作业,算法","author_index":"ClaRn"},{"id":"959ad7ee51ad9ca09e82dc0ada6a5ccd","title":"算法设计与分析-课后练习15","content":"课后练习15\n\n\npythonimport networkx as nx\nimport matplotlib.pyplot as plt构建图\npythongraph = nx.DiGraph()\n\ngraph.add_edge(1, 2, w=9, c=0)\ngraph.add_edge(1, 3, w=7, c=0)\ngraph.add_edge(1, 4, w=3, c=0)\ngraph.add_edge(1, 5, w=2, c=0)\ngraph.add_edge(2, 6, w=4, c=0)\ngraph.add_edge(2, 7, w=2, c=0)\ngraph.add_edge(2, 8, w=1, c=0)\ngraph.add_edge(3, 6, w=3, c=0)\ngraph.add_edge(3, 7, w=7, c=0)\ngraph.add_edge(4, 8, w=11, c=0)\ngraph.add_edge(5, 7, w=11, c=0)\ngraph.add_edge(5, 8, w=8, c=0)\ngraph.add_edge(6, 9, w=5, c=0)\ngraph.add_edge(7, 9, w=3, c=0)\ngraph.add_edge(8, 9, w=5, c=0)有向图如下所示：\npythonpos = nx.nx_agraph.graphviz_layout(graph)\nnx.draw_networkx(graph, pos)\nnx.draw_networkx_labels(graph, pos)\nnx.draw_networkx_edge_labels(graph, pos, nx.get_edge_attributes(graph, &#39;w&#39;))\nplt.show()\n下面使用前向法，从v4段的节点9开始，向前递推到v1段的节点1\npythonv4_node = 9\nv1_node = 1\n\nmin_cost = 0\ncur_node = v4_node\nwhile cur_node != v1_node:\n    in_edges = graph.in_edges(cur_node)\n    min_w = 100000\n    min_edge = ()\n    for in_edge in in_edges:\n        if graph[in_edge[0]][in_edge[1]][&#39;w&#39;] &lt; min_w:\n            min_w = graph[in_edge[0]][in_edge[1]][&#39;w&#39;]\n            min_edge = in_edge\n        \n    graph[min_edge[0]][min_edge[1]][&#39;c&#39;] = 1\n    cur_node = min_edge[0]\n    min_cost += min_w从节点1到节点9的路径最小值为：\npythonmin_costtxt14绘制路径\npythonnx.draw_networkx_edges(graph, pos, style=&#39;dashed&#39;)\nnx.draw_networkx_edges(graph, pos, [edge for edge in graph.edges if graph[edge[0]][edge[1]][&#39;c&#39;] == 1], style=&#39;solid&#39;, edge_color=&#39;r&#39;)\nnx.draw_networkx_nodes(graph, pos)\nnx.draw_networkx_labels(graph, pos)\nnx.draw_networkx_edge_labels(graph, pos, nx.get_edge_attributes(graph, &#39;w&#39;))\nplt.show()\npython","slug":"算法设计与分析-课后练习15","date":"2023-11-21T01:57:21.000Z","categories_index":"基础,作业,算法","tags_index":"作业,算法","author_index":"ClaRn"},{"id":"8feb5684fd02f6eab97366f1f1224414","title":"算法设计与分析-课后练习16","content":"课后练习16\n\n\npythontree = [\n    [9],\n    [12, 15],\n    [10, 6, 8],\n    [2, 18, 9, 5],\n    [19, 7, 10, 4, 16]\n]\nLEVEL = 5我们使用向后推导的方式来计算，每个节点都有两种选择：向左和向右，要选择最大的路径，比如说l1层到l2层的路径应该是(9, max(12, 15)), l_table变量存储起始点到第i层第j个节点之间的最大代价\npythonl_table = []\n\n# 初始化 l_table\nfor i in range(LEVEL):\n    l_table.append([0 for _ in range(i+1)])\n\nl_table[0][0] = tree[0][0]\nfor level in range(1, len(tree)):\n    data_in_level = tree[level]\n    data_in_upper_level = l_table[level-1]\n    for index in range(len(data_in_level)):\n        f_l = index-1\n        f_r = index\n        v_f_l = 0\n        v_f_r = 0\n        if len(data_in_upper_level) &gt; f_l &gt;= 0:\n            v_f_l = data_in_upper_level[f_l]\n        if len(data_in_upper_level) &gt; f_r &gt;= 0:\n            v_f_r = data_in_upper_level[f_r]\n        l_table[level][index] = max(v_f_r, v_f_l) + data_in_level[index]\n        \nfor l in l_table:\n    print(l)txt[9]\n[21, 24]\n[31, 30, 32]\n[33, 49, 41, 37]\n[52, 56, 59, 45, 53]故可以得出，最大数值和为：\npythonmax_path_sum = max(l_table[-1])\nmax_path_sumtxt59同时我们根据这个值在l_table中进行查找，可以得到路径为 [9 , 12, 10, 18, 10]\n","slug":"算法设计与分析-课后练习16","date":"2023-11-21T01:56:26.000Z","categories_index":"基础,作业,算法","tags_index":"作业,算法","author_index":"ClaRn"},{"id":"154af37c30e69f5d90663e52d5441592","title":"算法设计与分析-删数问题","content":"删数问题算法思想：将输入数字n按位存入数组，将数组从大到小排序并去除前s个元素，最小数必为剩下的len(n) - s个数的排列组合之一。从剩下的数中选取最小的数字作最高位，第i小的数作第i位，最后组合得到的数字即为最小数。\n示例如下：\n\n输入s = 178643\n输入n = 4\n将s转化为数组num，并按从大到小排序 \nnum = [8, 7, 6, 4, 3, 1]\n去掉前s个数后的 num_left = [3, 1]\n最后得到 min_num_left = \n\npythonn = input()\ns = int(input())\n\n# 初始化数据，将n转化为按位存储的数组\nnums = []\nfor i in range(len(n)):\n    nums.append(int(n[i]))python# 对数组进行从大到小排序，去掉前s个元素，剩下的元素个数为最小的len(n) - s个，它们组合成的数字最小\nnums.sort(reverse=True)\nnums_left = nums[s:]\nmin_num_left = 0pythonfor i in range(len(nums_left)):\n    min_num_left += nums_left[i] * 10**i\n    \nprint('n = %s, s = %d; \\n最后剩下的最小数 = %d' % (n, s, min_num_left))txtn = 178643, s = 4; \n最后剩下的最小数 = 26python","slug":"算法设计与分析-删数问题","date":"2023-11-21T01:54:50.000Z","categories_index":"基础,作业,算法","tags_index":"作业,算法","author_index":"ClaRn"},{"id":"33d59b8f449d0f5a6ebd66551c65bd8e","title":"算法设计与分析-课后练习17","content":"课后练习17\n\n首先定义Floyd算法函数计算最短路径矩阵\npythondef floyd_algo(graph):\n    matrix = []\n    m_size = len(graph[0])\n    \n    # 初始化 最短路径 矩阵\n    for i in range(m_size):\n        matrix.append([])\n        for j in range(m_size):\n            matrix[-1].append(graph[i][j])\n    \n    for n in range(m_size):\n        print('第 %d 次迭代的最短路径矩阵：' % n)\n        print_matrix(matrix)\n        for i in range(m_size):\n            for j in range(m_size):\n                for k in range(m_size):\n                    matrix[i][j] = min(matrix[i][j], matrix[i][k]+matrix[k][j])\n                    \n    return matrix\n\ndef print_matrix(matrix):\n    for i in range(len(matrix)):\n        s = ''\n        for j in range(len(matrix[0])):\n            if matrix[i][j] &gt; 100:\n                s += 'inf '\n            else:\n                s += '%3d ' % matrix[i][j]\n        print(s)将有向图使用邻接表表示\npythoninf = 10000 # 使用一个较大值表示两个节点之间没有路径\n\ngraph1 = [\n    #1    2    3    4    5    6\n    [0  , inf, inf, inf, 1,   inf], # 1\n    [1  , 0  , inf, 2,   inf, inf], # 2\n    [inf, 2,   0  , inf, inf, 8  ], # 3\n    [4  , inf, inf, 0  , 3,   inf], # 4\n    [inf, 7,   inf, inf, 0  , inf], # 5\n    [inf, 5,   10,  inf, inf, 0  ], # 6\n]\n\ngraph2 = [\n    #1    2    3    4    5    6\n    [0  , inf, inf, inf, -1,  inf], # 1\n    [1  , 0  , inf, 2,   inf, inf], # 2\n    [inf, 2,   0  , inf, inf, -8 ], # 3\n    [-4 , inf, inf, 0  , 3,   inf], # 4\n    [inf, 7,   inf, inf, 0  , inf], # 5\n    [inf, 5,   10,  inf, inf, 0  ], # 6\n]第一个图的计算结果如下:\npythonresult1 = floyd_algo(graph1)txt第 0 次迭代的最短路径矩阵：\n  0 inf inf inf   1 inf \n  1   0 inf   2 inf inf \ninf   2   0 inf inf   8 \n  4 inf inf   0   3 inf \ninf   7 inf inf   0 inf \ninf   5  10 inf inf   0 \n第 1 次迭代的最短路径矩阵：\n  0   8 inf  10   1 inf \n  1   0 inf   2   2 inf \n  3   2   0   4   4   8 \n  4  10 inf   0   3 inf \n  8   7 inf   9   0 inf \n  6   5  10   7   7   0 \n第 2 次迭代的最短路径矩阵：\n  0   8 inf  10   1 inf \n  1   0 inf   2   2 inf \n  3   2   0   4   4   8 \n  4  10 inf   0   3 inf \n  8   7 inf   9   0 inf \n  6   5  10   7   7   0 \n第 3 次迭代的最短路径矩阵：\n  0   8 inf  10   1 inf \n  1   0 inf   2   2 inf \n  3   2   0   4   4   8 \n  4  10 inf   0   3 inf \n  8   7 inf   9   0 inf \n  6   5  10   7   7   0 \n第 4 次迭代的最短路径矩阵：\n  0   8 inf  10   1 inf \n  1   0 inf   2   2 inf \n  3   2   0   4   4   8 \n  4  10 inf   0   3 inf \n  8   7 inf   9   0 inf \n  6   5  10   7   7   0 \n第 5 次迭代的最短路径矩阵：\n  0   8 inf  10   1 inf \n  1   0 inf   2   2 inf \n  3   2   0   4   4   8 \n  4  10 inf   0   3 inf \n  8   7 inf   9   0 inf \n  6   5  10   7   7   0 pythonprint_matrix(result1)txt  0   8 inf  10   1 inf \n  1   0 inf   2   2 inf \n  3   2   0   4   4   8 \n  4  10 inf   0   3 inf \n  8   7 inf   9   0 inf \n  6   5  10   7   7   0 第二个图的计算结果如下:\npythonresult2 = floyd_algo(graph2)txt第 0 次迭代的最短路径矩阵：\n  0 inf inf inf  -1 inf \n  1   0 inf   2 inf inf \ninf   2   0 inf inf  -8 \n -4 inf inf   0   3 inf \ninf   7 inf inf   0 inf \ninf   5  10 inf inf   0 \n第 1 次迭代的最短路径矩阵：\n  0   6 inf   8  -1 inf \n -2   0 inf   2  -3 inf \n  0  -3   0  -1  -6  -8 \n -4   2 inf   0  -5 inf \n  5   7 inf   9   0 inf \n  3   5  10   7   2   0 \n第 2 次迭代的最短路径矩阵：\n  0   6 inf   8  -1 inf \n -2   0 inf   2  -3 inf \n -5  -3   0  -1  -6  -8 \n -4   2 inf   0  -5 inf \n  5   7 inf   9   0 inf \n  3   5  10   7   2   0 \n第 3 次迭代的最短路径矩阵：\n  0   6 inf   8  -1 inf \n -2   0 inf   2  -3 inf \n -5  -3   0  -1  -6  -8 \n -4   2 inf   0  -5 inf \n  5   7 inf   9   0 inf \n  3   5  10   7   2   0 \n第 4 次迭代的最短路径矩阵：\n  0   6 inf   8  -1 inf \n -2   0 inf   2  -3 inf \n -5  -3   0  -1  -6  -8 \n -4   2 inf   0  -5 inf \n  5   7 inf   9   0 inf \n  3   5  10   7   2   0 \n第 5 次迭代的最短路径矩阵：\n  0   6 inf   8  -1 inf \n -2   0 inf   2  -3 inf \n -5  -3   0  -1  -6  -8 \n -4   2 inf   0  -5 inf \n  5   7 inf   9   0 inf \n  3   5  10   7   2   0 pythonprint_matrix(result2)txt  0   6 inf   8  -1 inf \n -2   0 inf   2  -3 inf \n -5  -3   0  -1  -6  -8 \n -4   2 inf   0  -5 inf \n  5   7 inf   9   0 inf \n  3   5  10   7   2   0 ","slug":"算法设计与分析-课后练习17","date":"2023-11-21T01:09:57.000Z","categories_index":"基础,作业,算法","tags_index":"作业,算法","author_index":"ClaRn"},{"id":"d7775844653cc819fd417c7a3b8d62f4","title":"算法设计与分析-课后练习19","content":"课后练习19\n\n\npythonn = 4\nw = [5, 3, 4, 7]\np = [3, 2, 5, 9]\nM = 15pythons_1 = []\ns = [(0, 0)]\n\nfor i in range(n):\n    s_i = []\n    cur_couple = (p[i], w[i])\n    s_i.append(cur_couple)\n    for j in range(len(s_1)-1, -1, -1):\n        for item in s_1[j]:\n            if (p[i] + item[0], w[i] + item[1]) in s_i:\n                continue\n            s_i.append((p[i] + item[0], w[i] + item[1]))\n        \n    s_1.append(s_i)\n    s += s_i\n    for j in range(len(s_i)):\n        is_modified = False\n        for item_s in s:\n            item_s_i = s_i[j]\n            if item_s[0] &lt; item_s_i[0] and item_s[1] &gt; item_s_i[1]:\n                s.remove(item_s)\ns.sort(key=lambda s_item: s_item[1])pythonprint('s = ' + str(s))\n\n\nfor i in range(len(s_1)):\n    print('s_' + str(i+1) + ' = ' + str(s_1[i]))txts = [(0, 0), (2, 3), (5, 4), (7, 7), (9, 7), (11, 10), (14, 11), (16, 14), (17, 16), (19, 19)]\ns_1 = [(3, 5)]\ns_2 = [(2, 3), (5, 8)]\ns_3 = [(5, 4), (7, 7), (10, 12), (8, 9)]\ns_4 = [(9, 7), (14, 11), (16, 14), (19, 19), (17, 16), (11, 10), (14, 15), (12, 12)]pythontarget_couple = ()\nfor i in range(len(s)):\n    if s[i][1] == M:\n        target_couple = s[i]\n        break\n    elif s[i][1] &gt; M and i &gt; 0:\n        target_couple = s[i-1]\n        break\n        \nprint('f('+str(M)+') 由序偶' +str(target_couple)+ '给出')txtf(15) 由序偶(16, 14)给出故有：且且故决策序列为：第二件、第三件、第四件物品\n","slug":"算法设计与分析-课后练习19","date":"2023-11-21T01:07:11.000Z","categories_index":"基础,作业,算法","tags_index":"作业,算法","author_index":"ClaRn"},{"id":"a643a8f22b50cab70dbe12575c51a852","title":"算法设计与分析-课后练习18","content":"课后练习18\n\n初始状态为：且有：  \n\n\n\n\n0\n1\n2\n3\n4\n\n\n\n0\n1,0,0\n3,0,0\n2,0,0\n1,0,0\n1,0,0\n\n\n1\n7,1,1\n8,8,2\n4,4,3\n3,3,4\n\n\n\n2\n12,19,2\n10,14,2\n6,9,3\n\n\n\n\n3\n14,25,2\n12,21,2\n\n\n\n\n\n4\n16,32,2\n\n\n\n\n\n\n最优二分检索树如下：\n\n\n","slug":"算法设计与分析-课后练习18","date":"2023-11-21T01:04:38.000Z","categories_index":"基础,作业,算法","tags_index":"作业,算法","author_index":"ClaRn"},{"id":"a8af3cf75b04482263ec5e275a72a958","title":"算法设计与分析-课后练习20","content":"课后练习20\n\n\npythonn = 5\nw = [2, 2, 6, 5, 4]\np = [6, 3, 5, 4, 6]\nM = 10pythonplefts = []\n\nfor i in range(n + 1):\n    pleft = 0\n    for j in range(i, n):\n        pleft += p[j]\n    print('PLEFT(%d) = %d' % (i, pleft))\n    plefts.append(pleft)txtPLEFT(0) = 24\nPLEFT(1) = 18\nPLEFT(2) = 15\nPLEFT(3) = 10\nPLEFT(4) = 6\nPLEFT(5) = 0最优解估计值 \npythons_1 = []\ns = [(0, 0)]\nL = 15\n\nfor i in range(n):\n    s_i = []\n    cur_couple = (p[i], w[i])\n    if cur_couple[0] + plefts[i+1] &gt;= L:\n        s_i.append(cur_couple)\n        \n    for j in range(len(s_1)-1, -1, -1):\n        for item in s_1[j]:\n            new_item = (p[i] + item[0], w[i] + item[1])\n            if new_item in s_i:\n                continue\n            if new_item[0] + plefts[i+1] &lt; L:\n                continue\n            if new_item[1] &gt; M:\n                continue\n            s_i.append(new_item)\n        \n    s_1.append(s_i)\n    s += s_i\n    for j in range(len(s_i)):\n        is_modified = False\n        for item_s in s:\n            item_s_i = s_i[j]\n            if item_s[0] &lt; item_s_i[0] and item_s[1] &gt; item_s_i[1]:\n                s.remove(item_s)\n    \ns.sort(key=lambda s_item: s_item[1])pythonprint('s = ' + str(s))\n\n\nfor i in range(len(s_1)):\n    print('s_' + str(i+1) + ' = ' + str(s_1[i]))txts = [(0, 0), (6, 2), (3, 2), (9, 4), (5, 6), (10, 7), (11, 8), (15, 8)]\ns_1 = [(6, 2)]\ns_2 = [(3, 2), (9, 4)]\ns_3 = [(5, 6), (8, 8), (14, 10), (11, 8)]\ns_4 = [(13, 9), (10, 7)]\ns_5 = [(15, 8)]pythonprint('f_%d(%d) = %d' % (i+1 ,M, s[-1][0]))txtf_5(10) = 15python","slug":"算法设计与分析-课后练习20","date":"2023-11-21T01:02:45.000Z","categories_index":"基础,作业,算法","tags_index":"作业,算法","author_index":"ClaRn"},{"id":"90df7255f6fefdff85aaf838864da52c","title":"算法设计与分析-课后练习21","content":"课后练习21\n\n\npythonTable = [\n    [0, 3, 7, 9, 12, 13],\n    [0, 5, 8, 10, 11, 12],\n    [0, 4, 6, 11, 12, 12]\n]\n\nA = 0\nB = 1\nC = 2\n\nMachines = 5pythonmax_val = 0\nmax_seq = ()\nfor x in range(Machines+1):\n    for y in range(Machines+1):\n        z = Machines - x - y\n        if z &lt; 0 or z &gt; Machines:\n            continue\n        value = Table[A][x] + Table[B][y] + Table[C][z]\n        if max_val &lt; value:\n            max_val = value\n            max_seq = (x, y, z)pythonprint(&#39;最大盈利为: %d&#39; % max_val)\nprint(&#39;最大盈利的分配方式为：A:%d, B:%d, C:%d&#39; % max_seq)txt最大盈利为: 19\n最大盈利的分配方式为：A:0, B:2, C:3","slug":"算法设计与分析-课后练习21","date":"2023-11-21T01:00:00.000Z","categories_index":"基础,作业,算法","tags_index":"作业,算法","author_index":"ClaRn"},{"id":"a1b53e1281173f553545a82d3e9f99c2","title":"PCA&LR作业","content":"\n\n\n\n\n\nTIP\n给定两类样本的特征，其中类别：类别：\n\n\n用PCA降维，分别将特征降至1维和2维，并给出降维后每个样本的位置。\n\n计算两类样本均值：\n\n\n\n将每个样本的特征减去样本均值：\n类别1：\n类别2：\n\n\n计算协方差矩阵 \n计算协方差矩阵的特征值和特征向量：\n特征值：\n特征向量：\n\n\n将特征降至1维：\n选择最大特征值所对应的特征向量\n类别1：\n类别2：\n\n\n将特征降至2维：\n选择前2大个特征值所对应的特征向量\n类别1：\n类别2：\n\n\n\n\n给出每个样本点降至2维后，再重构回3维空间的坐标。\n\n降至2维所使用的特征向量组成的矩阵为\n则样本点重构回三维空间的坐标为\n类别1：\n类别2：\n\n\n\n\n\n\n\n\n\n\nTIP\n假设我们采用带如下正则的线性回归，目标函数为：当从增加到时，描述以下各项如何变化：\n\n\n模型的过拟合行为；\n目标函数中的正则项为L2正则，当从增加到时，中的分量总和会受到限制，在时，目标函数中没有对的约束，容易产生过拟合的结果。当逐渐增大时，将会对有一定的约束作用，减轻过拟合行为的发生。当趋近于时，将会被限制为无限趋向，此时模型将无法正常工作。\n\n\nw的值和模的大小；\n当时，的值和模的大小是不受约束的，随着的增加，由于的值和模的大小越大，目标函数的值也会越大，所以的模也会随着参数更新而减小。当时，由于的模无限趋近，的值也会越来越小。\n\n\n模型的偏差和方差。（注意：这里的偏差不是指b）\n当时，模型的偏差会比较小，此时模型可以有灵活的拟合能力，当时，模型的偏差会逐渐增大。\n当时，模型的方差会非常大，因为此时噪声对模型的影响很大，当时，模型的方差会逐渐减小。\n\n\n\n\n\n\n\n\n\n\nTIP\n假设我们想要训练线性模型。我们将使用梯度下降来最小化个训练样本  上的误差平方和：计算目标函数损失相对于和  的偏导数。\n\n目标函数相对于的偏导数\n目标函数相对于的偏导数\n\n\n\n\n\n\n\nTIP\n假设我们采用不同的验证集划分方式： 2折交叉验证、10折交叉验证、留一交叉验证、单次70%/30%的训练集/验证集划分。\n\n\n不同的验证集划分方式会对模型性能产生什么影响？（如训练误差、泛化误差）\n2折交叉验证：使用两个互斥的子集进行验证，交替选择训练集和验证集。这种方式可能导致估计的方差较大，因为验证集的大小相对较小，所以对模型性能的估计可能不够稳定。\n10折交叉验证：将数据集分为10个互斥的子集，依次使用其中9个作为训练集，1个作为验证集，重复10次。这种方式通常能够提供相对稳定的性能估计，对于泛化误差的估计较为准确。\n留一交叉验证：每个样本都作为一个验证集，其余样本作为训练集，进行多次训练和验证。这种方式的估计通常具有较低的方差，但计算成本较高，特别是对于大型数据集。\n单次70%/30%的训练集/验证集划分：将数据集划分为70%的训练集和30%的验证集。这种方式的估计可能对初始随机划分的敏感性较大，估计的方差可能会较高\n\n\n哪种方式得到的验证误差会提供 在“未见过的测试集”上误差的最佳近似？\n10折交叉验证通常被认为是提供在未见过的测试集上误差的最佳近似的一种方式，因为它将数据集划分成多个子集，多次训练和验证，可以更好地捕捉模型的泛化性能。然而，最终的性能估计仍然可能会受到数据划分的随机性影响，因此需要考虑多次重复的交叉验证以获得更稳定的估计。\n\n\n原始数据集有多大有影响吗？对于一个非常大或非常小的数据集，你会得到不同的结论吗？\n原始数据集的大小对于交叉验证的效果有一定影响。对于一个非常小的数据集，可能会导致每个子集的样本量很小，这可能会导致性能估计不够稳定，特别是在2折交叉验证和单次70%/30%划分中。对于一个非常大的数据集，计算成本可能成为一个问题，尤其是在留一交叉验证中，因为需要训练和验证大量模型。\n\n\n就计算而言，哪种方式最快？\n单次70%/30%的训练集/验证集划分通常是最快的，因为它只涉及一次划分和一次模型训练和验证。其他交叉验证方式需要多次重复训练和验证，因此计算成本较高。留一交叉验证可能是最慢的，因为它需要与样本数相同的模型训练和验证步骤。\n\n\n\n","slug":"PCA&LR作业","date":"2023-11-18T19:45:25.000Z","categories_index":"基础,机器学习,作业","tags_index":"机器学习,作业,模式识别","author_index":"ClaRn"},{"id":"31d8cdd5baa8bcd02cb907b9fac066d4","title":"特征工程","content":"数据预处理数据预处理包括噪声的清晰和数据变换。\n特征类型包括：\n\n连续数值型特征\n多项式扩展\nlog变换（）\n区间量化\n二值化\n缩放\n规范化\n\n\n离散特征/类别型特征\n0/1编码\n标签编码\n独热码\n计数编码\n\n\n地点型特征\n时间型特征\n\n特征构造特征构造是从原始数据中构造新的特征的过程，通常需要手工创建。\n特征抽取特征抽取的目的是从原始数据抽取新特征，使算法自动执行。\n数据降维数据降维/嵌入是指将原始的高维数据映射到低维空间。高维度复杂数据的内在维度可能比较小，或者和任务相关的维度较小，所以荣誉的数据通常是可以被压缩的。\n降维方法降低维度的方法通常有两种：\n\n特征选择：选取已有特征的一个子集\n特征抽取：组合现有的特征来构建新特征\n\nPCA降维主成分分析主成分分析是将高位空间线性投影到一个低维空间，同时我们希望这个低维空间能够表征高维度空间的绝大部分信息，即信息损失最小。\n线性降维的一般形式数据点： 新空间的数据点: 选择个方向向量: 将投影到新空间: \nPCA的求解求解过程：输入：低维空间的维度算法过程：\n\n (将特征的数据值减去均值，得到偏移)\n计算 (协方差矩阵)\n对S做矩阵分解 (求特征值和特征向量)\n最大特征值对应的特征向量: \n\n输出：\n奇异值分解法(SVD)当数据原始维度过大时，求解协方差矩阵将变得困难。此时通过奇异值分解法可以快速地求出最大的D个特征值对应的特征向量。\n此时引入另一种PCA的求解方式。\nPCA的求解求解过程：输入：低维空间的维度算法过程：\n\n (将特征的数据值减去均值，得到偏移)\n奇异值分解 \n个奇异值对应的左奇异向量：\n\n输出：\n特征选择特征选择的方式如下：\n\n手工特征选择\n随机特征选择：随机采样，从维中随机选择维\n过滤式选择：设计一个相关统计量来度量特征的重要性\n相关系数（回归问题）\n互信息（单个特征和分类标签的互信息）\n统计量（单个特征和分类标签之间的独立性）\n信息增益（当特征出现或者不出现时，预测的熵减少）\n方差、information value、…\n\n\n包裹式特征选择：用最终要用的学习器的性能评价特征的重要性\n嵌入式特征选择：与模型训练一起完成，比如基于L1正则（比如Lasso回归或Logistic回归，SVM）的特征选择和基于树（比如决策树）的特征选择\n\nAddition协方差矩阵的计算协方差协方差用于衡量随机变量之间的相关程度。\n设、是定义在上的两个实数随机变量，则有：$$协方差 cov(X,Y)=E[(X-\\mu)(Y-v)]= \\frac{1}{n-1} \\sum^{n}{i=1}(x_i - \\mu)(y_i - v)=E(XY) - \\mu v ，\\E(X)=\\mu, E(Y)=v$$在实际应用中，样本数量通常会非常巨大，所以实际计算时会用来近似，此时原式变为：$ cov(X,Y)= \\frac{1}{n} \\sum^{n}{i=1}(x_i - \\mu)(y_i - v)$\n协方差矩阵协方差矩阵是一组随机变量之间任意两个随机变量之间的协方差所组成的方阵。\n若有则和之间的协方差矩阵为:\n另一种更快速的计算方式是，将样本与其转置相乘并记为(是一个矩阵)，并将与所有样本的累加后乘以，记为。\n","slug":"特征工程","date":"2023-11-18T01:17:02.000Z","categories_index":"基础,机器学习","tags_index":"机器学习,模式识别","author_index":"ClaRn"},{"id":"2de89c6bdcc1a7d65b885893c5d238e0","title":"LZ77编码和类LZW压缩算法","content":"LZ77编码","slug":"LZ77编码和类LZW压缩算法","date":"2023-11-17T08:26:11.000Z","categories_index":"","tags_index":"压缩算法","author_index":"ClaRn"},{"id":"80dc6c398842f9a2e7cabf21fa1c2234","title":"马尔可夫链和隐马尔可夫模型","content":"马尔可夫性质马尔可夫链是由一个条件分布来表示的 ，这被称为随机过程中的转移概率。马尔可夫链即符合马尔可夫性质的随机变量序列，最简化的马尔可夫链即只有一个X1的状态的转移链。在这些随机变量中，它们的当前状态，将来状态和过去状态是相互独立的。\n马尔可夫链马尔可夫链是基于状态而言的，其性质有些类似有限状态自动机，但是与DFA之类的n有限状态自动机不同的是，在不同状态的转移之间并非是一个特定条件在进行约束，而是一个概率。状态机上所有的概率可以构成一个分布，名叫转移概率分布。\n\n隐马尔可夫模型隐马尔可夫模型引入了“生成概率”的概念，每一个状态都有自己的生成概率分布，可以按照不同的概率产生一组可以被观测到的符号。在隐马尔可夫模型中，状态路径是无法直接看到的。\n在简单的马尔可夫模型（如马尔可夫链），所述状态是直接可见的观察者，因此状态转移概率是唯一的参数。在隐马尔可夫模型中，状态是不直接可见的，但输出依赖于该状态下，是可见的。每个状态通过可能的输出记号有了可能的概率分布。因此，通过一个HMM产生标记序列提供了有关状态的一些序列的信息。注意，“隐藏”指的是，该模型经其传递的状态序列，而不是模型的参数；即使这些参数是精确已知的，我们仍把该模型称为一个“隐藏”的马尔可夫模型。隐马尔可夫模型以它在时间上的模式识别所知，如语音，手写，手势识别，词类的标记，乐谱，局部放电和生物信息学应用。\nhttps://www.coursera.org/learn/sheng-wu-xin-xi-xue/lecture/uekgI/yin-ma-er-ke-fu-mo-xing\n","slug":"马尔可夫链和n隐马尔可夫模型","date":"2023-04-26T04:16:47.000Z","categories_index":"生物信息学,人工智能,基础","tags_index":"人工智能,生物信息学,算法","author_index":"ClaRn"},{"id":"250cf64c9de21149319ed296b52cadd2","title":"Smith-Waterman算法和Needleman-Wunsch算法","content":"简介Smith-Waterman算法和Needleman-Wunsch算法都是生物信息学领域非常经典的算法，主要用于基因或者蛋白质序列的比对。\nNeeleman-Wunsch算法是基于生物信息学知识来匹配蛋白序列或者基因序列的算法，是将动态规划算法应用于生物序列的比较的早期实践之一。\nSmith-Waterman算法是Needleman-Wunsch算法的延伸，相比于Needleman算法主要聚焦于一整条序列的全局比对，Smith算法更多的用于找寻两个序列中具有高度相似度的片段。\nNeedleman-Wunsch算法原理NW算法主要用于对比两个序列并得到这两个序列的全部序列匹配。\n假设两个待比对序列为：AAG 和 AGC ，且不同的碱基对应的分值如下表所示，空值的罚分为线性距离，值为-5 。\n\n\n\n\nA\nC\nG\nT\n\n\n\nA\n2\n-7\n-5\n-7\n\n\nC\n-7\n2\n-7\n-5\n\n\nG\n-5\n-7\n2\n-7\n\n\nT\n-7\n-5\n-7\n2\n\n\n即DP矩阵中计算分数的公式为：\n，\n计算所得结果如下图：\n然后回溯得到对比结果： \n关于回溯：在北大的生物信息学导论课程中并没有提及回溯的具体方式，不过可以参考下面这篇博客：https://blog.csdn.net/yohjob/article/details/89144032 \nSmith-Waterman算法Smith-Waterman算法与Needleman-Wunsch算法差别并不大，主要存在的差异是DP矩阵的计算公式，Smith-Waterman算法给公式的值规定了最小值从而突出局部特征。公式如下所示：，\n","slug":"Smith-Waterman算法和Needleman-Wunsch算法","date":"2023-04-25T21:41:09.000Z","categories_index":"生物信息学,基础","tags_index":"生物信息学,算法,动态规划","author_index":"ClaRn"},{"id":"ffa3c8772fdf3309434ff546ef79c450","title":"图像特征","content":"SIFT、HOG特征SIFT特征Scale Invariant Feature Transform ，又称尺度不变特征变换。SIFT特征对旋转、尺度缩放、亮度变化等保持不变性，是一种非常稳定的局部特征。\nHOG特征Histogram of Oriented Gradient ，又称方向梯度直方图特征，是一种在计算机视觉和图像处理中用来进行物体检测的特征描述子。HOG特征通过计算和统计图像局部区域的梯度方向直方图来构成特征。\nSIFT、HOG特征的计算过程SIFT特征的计算过程\n生成高斯差分金字塔(DOG金字塔)，尺度空间构建\n空间极值点检测(关键点的初步查探)\n稳定关键点的精确定位\n稳定关键点方向信息分配\n关键点描述\n特征点匹配\n\nHOG特征的计算过程\n灰度图Gamma校正(不必须)\n梯度计算\n8x8Cell梯度直方图划分\n16x16Block归一化，统计Cell梯度直方图\n计算HOG特征描述\n\n","slug":"图像特征","date":"2023-04-02T13:09:32.000Z","categories_index":"图形图像","tags_index":"图像处理,OpenCV","author_index":"ClaRn"},{"id":"e14beeee054107e61818821b5c2d1c74","title":"进程同步经典问题","content":"信号量信号量机制是一种用于解决互斥和同步问题的机制，包括两个原语wait(S)和signal(S)，也可以记为P操作和V操作。\n管程使用一个数据结构S来描述共享资源数，并包含对该数据结构的一组操作。\n生产者-消费者问题cppsemaphore mutex = 1;\nsemaphore empty = n;\nsemaphore full = 0;\nproducer () &#123;\n    while(1) &#123;\n        // ...produce data\n        P(empty);\n        P(mutex);\n        // ...add data to buffer\n        V(mutex);\n        V(full);\n    &#125;\n&#125;\n\nconsumer() &#123;\n    while(1) &#123;\n        P(full);\n        P(mutex);\n        // ...get data from buffer\n        V(mutex);\n        V(empty);\n        // ...consume data\n    &#125;\n&#125;读者-写者问题cppint count = 0; // 读者数量\nsemaphore mutex=1;\nsemaphore rw=1;\nsemaphore w=1; \n// w是用来保证写优先的\n// 如果没有将会导师读优先，写进程会存在“饿死”现象 \n\nwriter() &#123;\n    while(1) &#123;\n        P(w);\n        P(rw);\n        // ...writing\n        V(rw);\n        V(w);\n    &#125;\n&#125;\n\nreader() &#123;\n    while(1) &#123;\n        P(w);\n        P(mutex);\n        if (count == 0)\n            P(rw);\n        count ++;\n        V(mutex);\n        V(w);\n        // ...reading\n        P(mutex);\n        count --;\n        if (count == 0)\n            V(rw);\n        V(mutex);\n    &#125;\n&#125;","slug":"进程同步经典问题","date":"2023-03-25T13:53:16.000Z","categories_index":"","tags_index":"Review,操作系统","author_index":"ClaRn"},{"id":"cfd4ec52764f9243a80a5ef9b48d3349","title":"软件工程中的开发模型","content":"软件开发生命周期（software development lifecycle (SDLC) ）软件的产生直到报废的生命周期，包括：问题定义、可行性分析、需求分析、总体设计、详细设计、编码、测试、运行维护等阶段。\n软件开发模型1、瀑布模型瀑布模型也称为生命周期发，是结构化方法中最常用的开发模型，可以分为软件计划、需求分析、软件设计、程序编码、软件测试和运行维护几个阶段。适合需求明确或变更少的项目\n2、增量模型增量模型融合了瀑布模型的基本成分和原型实现的迭代特征，是第三种原型化开发方法，但它不是“抛弃式”的，也不是“渐进式”的。增量模型把软件产品划分为一系列的增量构件，第一个增量往往是核心的产品，即第一个增量实现了基本的需求。 客户对每一个增量的使用和评估都作为下一个增量发布的新特征和功能，这个过程在每一个增量发布后不断重复，直到产生了最终的完善产品。增量模型与原型实现模型和其他演化方法一样，本质上是迭代的，但与原型实现不一样的是其强调每一个增量均发布一个可操作产品。增量模型将功能细化、分别开发的方法适应于需求经常改变的软件开发过程\n3、螺旋模型螺旋模型以原型为基础，每一次螺旋都要经过制订计划、风险分析、实施工程及客户评价等活动，并开发原型的一个新版本，经过若干次螺旋上升的过程得到最终的系统。\n4、喷泉模型喷泉模型是一种以用户需求为动力，以对象为驱动地模型，主要用于描述面向对象的软件开发过程，该模型认为软件开发过程自下而上的，各阶段是相互迭代和无间隙的。无间隙是指在开发活动中，分析、设计和编码之间不存在明显的边界。\n5、V模型V 形模型也称为 V 模型或验证与验证模型，是瀑布方法的扩展。使用 V 模型时，进度并不会直线移动，而是在实施和开发后逐渐上升。  \n对于 V 型 SDLC 项目，早期测试介入是与瀑布模型相比的主要区别。每个开发阶段都有一个并行测试阶段，这有助于在继续下一步之前验证和验证每个步骤。\n快速原型模型快速原型是利用原型辅助软件开发的一种新思想。  \n经过简单快速分析，快速建造一个可以运行的软件原型，以便理解和澄清问题，使开发人员与用户达成共识，最终在确定的用户需求基础上开发客户满意的软件产品。  \n原型可以为三类：\n\n探索型原型：主要用于需求分析阶段，目的是要弄清用户的需求，并探索各种方案的可行性。它主要针对开发目标模糊，用户与开发人员对项目都缺乏经验的情况，通过对原型的开发来明确用户的需求\n实验型原型：主要用于设计阶段，考核实现方案是否合适，能否实现。对于大型系统，若对设计方案心中没有把握时，可通过这种原型来证实设计方案的正确性\n演化型原型：主要用于及早向用户提交一个原型系统，该原型系统或者包含系统的框架，或者包含系统的主要功能，在得到用户的认可后，将原型系统不断扩充演变为最终的软件系统\n\n敏捷模型敏捷（Agile） SDLC 模型是迭代和增量方法的组合，致力于通过早期交付工作软件来适应灵活的需求并满足用户和客户的需求。敏捷项目中的需求和解决方案可能会在开发过程中发展。  \n通过敏捷开发，该产品被分为小的增量构建，并以迭代方式交付。将所有任务划分为较小的时间范围，以便为每个版本准备工作功能。最终产品版本包含所有必需的功能。敏捷仍然是技术行业中使用最广泛的SDLC。\n常见的敏捷开发方法：\n\n极限编程(XP)\n自适应软件开发\n水晶方法\n特性驱动开发\nscrum\n\n","slug":"软件工程","date":"2023-03-23T16:41:13.000Z","categories_index":"基础","tags_index":"Review,软件工程","author_index":"ClaRn"},{"id":"fba5abef53d9d5ea6aea61fb0369866c","title":"编译原理考点","content":"编译原理作业：\n正则表达式生成NFA&#x2F;DFA\nLL1 词法分析\nLR 词法分析\n\n编译程序的功能组织结构图\n‘词法分析器→语法分析器→语义分析器→中间代码生成器→代码优化器→目标代码’\n语法分析树和抽象语法树不是一个玩意儿(问题不大)\n词法分析\n调度场算法\n\n使用栈针对不同运算符的优先级进行处理\n\n\n\n\nChomsky四型文法\n0型文法\n无限制文法&#x2F;短语结构文法\n设G&#x3D;（VN，VT，P，S），如果它的每个产生式α→β是这样一种结构：α∈(VN∪VT)*且至少含有一个非终结符，而 β∈(VN∪VT)*，则G是一个0型文法。0型文法也称短语文法。一个非常重要的理论结果是：0型文法的能力相当于图灵机(Turing)。或者说，任 何0型文语言都是递归可枚举的，反之，递归可枚举集必定是一个0型语言。0型文法是这几类文法中，限制最少的一个。0型文法是其它类型文法的母集。\n\n\n\n\n1型文法\n上下文有关文法\n1型文法也叫上下文有关文法，此文法对应于线性有界自动机。它是在0型文法的基础上每一个α→β,都有|β|&gt;&#x3D;|α|。这里的|β|表示的是β的长度。\n注意：虽然要求|β|&gt;&#x3D;|α|，但有一特例：α→ε也满足1型文法。\n如有A-&gt;Ba则|β|&#x3D;2,|α|&#x3D;1符合1型文法要求。反之,如aA-&gt;a，则不符合1型文法。\n\n\n\n\n2型文法\n上下文无关文法\n在1型文法的基础上，每一个α→β都有α是非终结符。\n如A-&gt;Ba,符合2型文法要求。\n如Ab-&gt;Bab虽然符合1型文法要求,但不符合2型文法要求，因为其α&#x3D;Ab，而Ab不是一个非终结符。\n\n\n\n\n3型文法\n正则文法\n对应有限状态自动机。\n在2型文法的基础上满足:A→α|αB（右线性）或A→α|Bα（左线性）。\n如有：A-&gt;a,A-&gt;aB,B-&gt;a,B-&gt;cB，则符合3型文法的要求。\n但如果推导 为:A-&gt;ab,A-&gt;aB,B-&gt;a,B-&gt;cB或推导 为:A-&gt;a,A-&gt;Ba,B-&gt;a,B-&gt;cB则不符合3型方法的要求了。\n具体的说，例子 A-&gt;ab,A-&gt;aB,B-&gt;a,B-&gt;cB中的A-&gt;ab不符合3型文法的定义,如果把后面的ab,改成“一个非终结符＋一个终结符”的形式（即为aB）就对了。例子A-&gt;a,A-&gt;Ba,B-&gt;a,B-&gt;cB中如果把B-&gt;cB改为 B-&gt;Bc的形式就对了,因为A→α|αB（右线性）和A→α|Bα（左线性）两套规则不能同时出现在一个语法中,只能完全满足其中的一个,才能算 3型文法。\n\n\n\n\n\n\n正则表达式\n| ：或\n* ：匹配0或无限个\n· ：连接\n优先级：*、·、|\n例如：\n令 ∑ &#x3D; {a, b}，则\nL(a|b) &#x3D; L(a)∪L(b) &#x3D;{a}∪{b} &#x3D; {a, b}\nL((a|b)(a|b)) &#x3D; L(a|b) L(a|b)&#x3D;{a, b}{a, b}&#x3D; { aa, ab, ba, bb }\nL(a*) &#x3D; (L(a))*&#x3D; {a}*&#x3D; { ε, a, aa, aaa, . . . }\nL((a|b)*) &#x3D; (L(a|b))* &#x3D; {a, b}*&#x3D; { ε, a, b, aa, ab, ba, bb, aaa, . . .}\nL(a|a*b) &#x3D; { a, b, ab, aab, aaab, . . .}\n\n\n\n\n\n有穷自动机(FA)\n具有有穷个状态数\n最长子串匹配原则：输入串的多个前缀与一个或多个模式匹配时，总是选择最长的前缀进行匹配。\n\n\nNFA(非确定的FA)\nNFA是不唯一的，但其对应的DFA是唯一的\nε对应的NFA \nr &#x3D; r1r2对应的NFA \nr &#x3D; r1|r2 对应的NFA \nr &#x3D; (r1)*对应的NFA \n\n\nDFA(确定的FA)\nDFA每个状态都是一个由NFA状态构成的集合，也就是NFA状态集合的一个子集。例如NFA中状态A可以经由a边到达状态A、B，则DFA中状态A可经由a边到达状态 {A,B} ，这里 {A,B}集合是一个状态。\nNFA→DFA：初始状态ε闭包T，求出后遍历终结符，对每个move(T,a)求ε闭包，求出的闭包为新的状态U，a即当前终结符，意思是T通过a到达U，将U换为T继续执行，直到没有新的U出现。\n如图所示 r=aa*bb*cc* 的无ε边的NFA到DFA的转换：\n无ε边的NFA到DFA的转换 \nNFA状态转换表 \n转换后的DFA \n\n\n如图所示为带ε边的NFA到DFA的转换 \n\n\nDFA最小化：\n状态合并：将所有状态划分为终结状态和非终结状态，并将终结状态和非终结状态进行合并，合并规则为:二者同为终结状态或非终结状态，且通过指定输入符号可以到达的状态相同。\nε-闭包(ε-closure)\nε-closure(s)：能够从NFA状态s开始只通过ε转换到达的NFA状态集合\nε-closure(T)：能够从T中的某个NFA状态s开始，只通过ε转换到达的NFA状态集合\nmove(T, a)：能够从T中的某个状态s出发通过标号为a的转换到达的NFA状态的集合\n\n\n\n\n\n上下文无关文法\n二义性文法判断\n能通过不同分析顺序生成两个分析树的文法称为二义性文法\n消除二义性：不修改文法，指定正确的分析树；或修改文法(指定优先级、结合性)\n\n\n短语、简单短句和句柄判断\n短语：每颗子树的叶子\n简单短语：每颗简单子树(仅有叶子结点没有根节点)的叶子\n句柄：最左简单子树的叶子(最左边的那个简单子树)\n\n\n\n自顶向下语法分析 （最左推导：既总是选择每个句型的最左非终结符进行替换）\n判定：产生式A → α | β 满足下面的条件：\n如果α 和β均不能推导出ε ，则FIRST (α)∩FIRST (β) &#x3D;Φ(空集)\nα 和β至多有一个能推导出ε\n如果 β →* ε，则FIRST (α)∩FOLLOW(A) &#x3D;Φ; 如果 α →* ε，则FIRST (β)∩FOLLOW(A) &#x3D;Φ;\n\n\n消除左递归：(A → A α1 | A α2 | β1 | β2)→(A → β1 A′ | β2 A′;A′ → α1 A′ | α2 A′ | ε)\n间接左递归：将间接左递归文法的定义代入得到直接左递归，再消除\n提取左因子：(S → aAd | aBe)→(S → a S’;S’ → Ad | Be)\nFirst、Follow\nFirst：可以从X推导出的所有串首终结符构成的集合;可以存在ε\nFollow：可能在某个句型中紧跟在A后边的终结符a的集合；如果A是某个句型的的最右符号，则将结束符“$”添加到FOLLOW(A)中；如果是起始的第一句，则添加“$”\n\n\nLL(1)分析表\nSelect：将每条文法拆分为拓广文法，若该条文法A的First为ε，则Select(A)&#x3D;Follow(A)，否则Select(A)&#x3D;First(A)\n通过Select集合可以看到不同拓广文法产生式对应的终结符，使用其构建终结符与非终结符相对应的文法分析表即可。(考试记得写编号)\n\n\nLL(1)分析过程\n分析栈：第一次为E，之后根据输入队列进行获取输入符号，通过输入符号和栈顶非终结符查找分析表进行文法推导，若为终结符则进行出栈匹配操作。\n\n\n\n自底向上语法分析 （归约）\n拓广文法\n就是全写出来，然后在最前面加个S’→S，有手就行\n\n\nLR(0)项目：\n加上小圆点的状态示意句柄\n\n\nLR(0)识别活前缀状态机\n从第一条增广文法开始往下，列出所有可以推导出的项目，然后写出每个项目移进之后的状态，直到小圆点到了最后再也推导不出来新的状态，就是规约状态。\n\n\nLR方法判断过程\nLR(0)分析表、SLR(1)分析表\nLR(0)分析表：\n分为两部分：Action和GOTO\nACTION：移进项目\nGOTO：跳转到文法\n\n\n\n\nSLR(1)分析表：\n如果下一个输入符号a属于移进项目，则移进；若a属于某个规约项目的Follow，则使用该规约项目进行规约\n\n\n\n\nLR分析过程\nLR(1)识别活前缀状态机\nLALR(1)判断\nLALR(1)识别活前缀状态机\nLR(1)分析表、LALR(1)分析表\n如果除了展望符外，两个LR(1)项目集是相同的，则称这两个LR(1)项目集是同心的\nLALR(1)状态机即合并同心项后的LR(1)状态机\n\n\nLR分析过程\n\n语义分析\n依赖图(拓扑排序)语义分析\nS属性文法语义分析\nL属性文法语义分析\n\n中间代码三地址码的四元式、三元式表示\n四元式：(op,arg1,arg2,return)\n三元式：x&#x3D;(t+r)*y → t1&#x3D;t+r;t2&#x3D;t1*r;x&#x3D;t2;\n\n基于基本块的DAG的中间代码优化\n基本块：程序中一段顺序执行的语句序列\n通过每一条三地址码或四元式构建节点，将相关的节点相连，若节点内容一样，在右边加上名字，节点下方为常量值或运算符。\n\n","slug":"编译原理考点","date":"2023-03-15T12:38:09.000Z","categories_index":"基础","tags_index":"Review,编译原理","author_index":"ClaRn"},{"id":"d655af595b90ac0e0949f931f50e7fe8","title":"进程管理","content":"进程进程的概念和特征进程的概念从不同的角度看，进程可以有不同的定义，比较典型的是：\n\n进程是程序的一次执行过程\n进程是一个程序及其数据在处理机上顺序执行时所发生的活动\n进程是具有独立功能的程序在一个数据集合上运行的过程，它是系统进行资源分配和调度的一个独立单位。\n\n进程的特征\n动态性：进程是程序的一次执行，它有创建、活动、暂停、终止的过程，具有一定的生命周期。\n并发性：指多个进程实体同时存在于内存中，能在同一段时间内运行。\n独立性：进程实体是一个能独立运行、独立获取资源和独立接受调度的基本单位。\n异步性：由于进程的制约，使得进程的执行具有间断性，即进程按照各自独立、不可预知的速度往前推进。\n结构性：每个进程都配置一个PCB对其进行描述。从结构上看，进程实体是由程序段、数据段和进程控制块构成的。\n\n进程的状态\n运行态：进程正在处理机上运行\n就绪态：进程获得了除了处理机之外的一切资源，一旦得到处理机就可以立即执行。\n阻塞态：进程因为某一事件而暂停，比如等待输入输出或者某外设资源。\n创建态：进程正在被创建，尚未转到就绪态。\n结束态：进程执行完毕正在从系统中消失。\n\n进程切换过程\n保存处理机上下文\n更新PCB信息\n把进程的PCB移入相应的队列，如就绪、阻塞队列\n选择另一个进程执行\n更新内存管理的数据结构\n恢复处理机上下文\n\n进程控制块进程控制块用于描述一个进程，其中主要包括描述信息、进程控制和管理信息、资源分配清单和处理机相关信息等。处理机对进程的调度是基于进程控制块实现的。\n进程间通信共享存储这是最简单的一种进程间通信的方式，它为两个进程提供了一片公共的内存区域，在这个内存区域中的读写对于进程双方都是可见的。低级的共享存储是对数据结构的共享，而高级的共享存储是对存储区的共享。\n消息传递进程间的数据交换以格式化的消息为单位。包括直接通信方式和间接通信方式。\n直接通信方式发送进程直接将消息发送给接收进程，并且将它挂在接收进程的消息缓冲队列上。接收进程从消息缓冲队列中取得消息。\n间接通信方式发送进程把消息发送给某个中间实体，接收进程从中间实体去的消息，一般又称为信箱通信方式。Android的Binder通信机制类似这种。\n管道通信管道通信实际上是消息传递的一种特殊方式。管道实际上是指的用于连接读进程和写进程之间的一个共享文件，又叫做pipe文件。由于管道通信是基于文件的，该文件实际充当了一个缓冲区的作用，所以管道通信只能实现半双工通信。  \n从管道中读取数据也是一次性操作，数据在读取之后就会被抛弃。在Linux中一个管道文件被限制在4KB，一旦管道文件已满，IO操作将被阻塞。\n多线程线程是进程内部的一部分，可以理解为更轻量化的进程。在一个进程内可以拥有多个进程，这些进程拥有自己的专有寄存器和栈空间，但是共享进程内的堆空间。  \n进程是机器分配资源的基本单位，线程是机器分配CPU的基本单位。协程是线程内部的更轻量化的线程，除了拥有专有寄存器外，协程之间还共享栈空间。  \n线程又分为用户级线程和内核级线程；用户级线程依赖应用程序完成线程的调度和管理，内核级线程中的调度和管理都通过操作系统完成。\n处理机调度调度层次\n作业调度：又称高级调度，主要任务是按照一定的规则从外存中处于后备状态的作业中挑选一个或多个作业，给它们分配内存、输入输出设备等必要的资源，并简历相应的进程。\n内存调度：又称中级调度，主要任务是提高内存利用率和吞吐率。中级调度将决定将那些陷入阻塞状态的进程暂时调入外存，并在处理机以及资源空闲之后将进程调入内存。\n进程调度：又称低级调度，主要任务是按照某种方法和策略将进程从就绪队列中取出，并分配处理机。\n\n进程调度通常有两种进程调度方式：\n\n非剥夺调度方式：如果有更重要的任务进入就绪队列，将会持续执行当前任务直到结束或者发生阻塞。\n剥夺调度方式：如果有更重要的任务进入就绪队列，处理机将会被强制剥夺。\n\n不同的调度算法对于不同方面的特性不同。其中的性能指标是评价调度算法是否适合当前场景的重要参数，常用性能指标有如下几种：\n\nCPU利用率：好的调度算法应该尽可能让CPU利用率高。\n系统吞吐量：表示单位时间内CPU完成作业的数量。长作业需要消耗较长的处理机时间，因此会降低系统的吞吐量。而对于短作业，它们所需要的处理机时间较短，因此能提高系统的吞吐量。\n周转时间：周转时间是指从作业提交到作业完成所经历的时间，是作业等待、在就绪队列中排队、在处理机上运行以及进行输入输出所花费时间的总和。作业的周转时间可以用如下公式表示： 周转时间作业完成时间作业提交时间 平均周转时间是指多个作业周转时间的平均值： 平均周转时间作业的周转时间作业的中转时间 带权周转时间是指作业周转时间与作业实际运行时间的比值 带权周转时间作业周转时间作业实际运行时间 平均带权周转时间是指多个作业带权周转时间的平均值： 平均带权周转时间作业的带权周转时间作业的带权周转时间\n等待时间：指进程处于等处理机状态的时间之和，等待时间越长，用户满意度越低。\n响应时间：指从用户提交请求到系统首次响应所用的时间。\n\n调度算法先来先服务(FCFS)每次从就绪队列中选择最先进入的进程，直到完成或者阻塞。这种算法属于不可剥夺算法，从表面上看对所有进程都是公平的，但是会导致来的晚的短作业等待时间长。\n短作业优先(SJF)短作业优先算法从就绪队列中选择一个或若干个估计运行时间最短的作业。该算法会产生饥饿现象，使得长作业长期得不到执行。同时该算法也不考虑作业的优先级，因此不会保证重要任务被优先执行。  \n该算法对作业的选择严重依赖于估计出的运行时间，但估计运行时间并不准确，因此实际运行过程中该算法可能并不能够做到短作业优先。\n优先级调度优先级调度算法从就绪队列中选择优先级最高的一个或几个作业。该算法可分为非剥夺优先级调度算法和剥夺式优先级调度算法。  \n根据进程创建后优先级是否可变又可以分为静态优先级和动态优先级。\n高响应比优先算法高响应比优先算法主要用于作业调度，是对FCFS和SJF的一种综合平衡。响应比可以描述为 响应比等待时间要求服务时间要求服务时间 。对于短作业而言，其要求服务时间短，响应比就越高，可以优先调度；对于长作业而言，等待时间越长，响应比就越高，最终也可以获得处理机资源从而避免了饥饿现象。\n时间片轮转算法时间片轮转算法将进程按FCFS顺序分配时间片，进程在执行完一个时间片后将重新回到队列末尾。  \n时间片大小需要由系统的响应时间、就绪队列中的进程数目以及系统的处理能力确定。\n多级反馈队列算法多级反馈队列算法设置了多个就绪队列，每个就绪队列的优先级不同。根据不同优先级队列划分不同长度的时间片，优先级越低，时间片越大。当优先级高的队列中为空时，CPU将被分配给下一级队列中的进程。  \n进程在进入内存后，首先进入最高一级的就绪队列中等待执行，若一个时间片后还没有执行完成，将会被放置进入次优先级的就绪队列中。  \n若执行过程中有更高优先级的进程加入，CPU将被高优先级的进程抢占。\n进程同步由于进程的异步性导致的进程之间推进速度不可预测，当多个进程需要协同或竞争使用某一资源时，不可避免地需要等待或通知其它进程。这种在同一时刻仅允许一个进程使用的资源又被称为临界资源，在进程中访问临界资源的代码块被称为临界区。\n同步和互斥是进程之间的制约关系。同步是直接制约关系，是指进程之间需要依靠某种顺序执行而必须建立的制约关系，比如生产者消费者；互斥是间接制约关系，是指多个进程之间对于某类资源的争用，比如打印机的使用。\n临界区互斥方法软件实现的方法单标志法cpp// P0进程\nwhile(turn != 0);\ncritical section; // 临界区\nturn = 1;\nremainder section; // 剩余区\n\n// P1进程\nwhile(turn != 1);\ncritical section;\nturn = 0;\nremainder section该算法的两个进程必须交替进入临界区，否则若一个进程停止执行，另一个进程会陷入死等。\n双标志法先检查cpp// Pi进程\nwhile(flag[j]);\nflag[i] = true;\ncritical section;\nflag[i] = false;\nremainder section;\n\n// Pj进程\nwhile(flag[i]);\nflag[j] = true;\ncritical section;\nflag[j] = false;\nremainder section当进程并发执行时，若遇到同时先后执行while语句时，将会导致互斥失效。\n双标志法后检查cpp// Pi进程\nflag[i] = true;\nwhile(flag[j]);\ncritical section;\nflag[i] = false;\nremainder section;\n\n// Pj进程\nflag[j] = true;\nwhile(flag[i]);\ncritical section;\nflag[j] = false;\nremainder section当进程并发执行时，若遇到同时先后执行while语句时，将会导致饥饿现象。\nPeterson’s Algorithmcpp// Pi进程\nflag[i] = true;\nturn = j;\nwhile(flag[j]&amp;&amp;turn==j);\ncritical section;\nflag[i] = false;\nremainder section;\n\n// Pj进程\nflag[j] = true;\nturn = i;\nwhile(flag[i]&amp;&amp;turn==i);\ncritical section;\nflag[j] = false;\nremainder section","slug":"进程管理","date":"2022-04-24T12:42:46.000Z","categories_index":"","tags_index":"Review,操作系统","author_index":"ClaRn"},{"id":"ab80b4e122bbda900a1a6ace41232d32","title":"数据库系统","content":"数据库（数据仓库）数据库是长期储存在计算机内、有组织的、可共享的大量数据的集合\n数据库中的数据按照一定的数据模型组织、描述、存储。具有较小冗余度、较高数据独立性和易扩展性，并且可以为各种用户共享。\n数据库的基本特点：  \n\n永久存储\n有组织\n可共享\n\n数据库管理系统用户通过数据库管理系统操作数据库，数据库管理系统将操作系统的接口封装，为用户提供数据的定义、组织、存储、管理、操纵、数据库的事务管理和运行、数据库的建立和维护等工作。\n数据库系统数据库系统内包含数据库、数据库管理系统、应用程序和数据库管理员。\n数据库系统是用于存储、管理、处理和维护数据的系统\n数据库系统与文件系统的区别：数据的结构化\n数据模型概念模型：对数据和信息的建模逻辑模型：数据之间的逻辑结构组成的模型物理模型：物理机上存储的模型  \nDefinitions\n实体(Entity)：客观存在并可以互相区别的事务\n属性(Attribute)：实体的某一特性\n码(Key)：唯一标识实体的属性集\n实体型(Entity Set)：同一类型实体的集合\n联系(Relationship)：实体之间的联系，通常指不同实体集之间的联系\n\nE-R图\n范式\n第一范式(确保每列保持原子性)\n第一范式是最基本的范式。如果数据库表中的所有字段值都是不可分解的原子值，就说明该数据库表满足了第一范式。\n第一范式的合理遵循需要根据系统的实际需求来定。\n比如某些数据库系统中需要用到“地址”这个属性，本来直接将“地址”属性设计成一个数据库表的字段就行。但是如果系统经常会访问“地址”属性中的“城市”部分，那么就非要将“地址”这个属性重新拆分为省份、城市、详细地址等多个部分进行存储，这样在对地址中某一部分操作的时候将非常方便。\n\n\n第二范式(确保表中的每列都和主键相关)\n第二范式在第一范式的基础之上更进一层。第二范式需要确保数据库表中的每一列都和主键相关，而不能只与主键的某一部分相关（主要针对联合主键而言）。也就是说在一个数据库表中，一个表中只能保存一种数据，不可以把多种数据保存在同一张数据库表中。\n比如要设计一个订单信息表，因为订单中可能会有多种商品，所以要将订单编号和商品编号作为数据库表的联合主键。\n\n\n第三范式(确保每列都和主键列直接相关,而不是间接相关)\n第三范式需要确保数据表中的每一列数据都和主键直接相关，而不能间接相关。\n比如在设计一个订单数据表的时候，可以将客户编号作为一个外键和订单表建立相应的关系。而不可以在订单表中添加关于客户其它信息（比如姓名、所属公司等）的字段。\n\n\n\nSQL语句索引\nhash索引：O(1)操作，适合单值查询，如 &#x3D;、in\nbtree索引：适合单值查询和范围查询，如 &lt;、&gt;、between\n\nUNION操作符sqlSELECT column_name FROM table1\nUNION\nSELECT column_name FROM table2;UNION操作符的作用是合并两个或者多个SELECT语句的查询结果。UNION操作默认选取不同的值。如果需要允许重复的值，需要使用UNION ALL。\nsqlSELECT column_name FROM table1\nUNION ALL\nSELECT column_name FROM table2;SELECT INTO语句MySQL不支持该语句，但可以用INSERT INTO ... SELECT ...代替。下面语句将table1所有的列复制进newtable\nsqlSELECT * INTO newtable FROM table1;或者也可以将table1中的指定列复制进newtable\nsqlSELECT comun_name INTO newtable FROM table1;IN操作符IN操作符可以让WHERE在多个值中选择。\nsqlSELECT column_name1,column_name2,... \nFROM table1 \nWHERE column IN (value1, value2, ...);BETWEEN操作符BETWEEN操作符可以选取介于两个值之间的数据范围内的值。\nsqlSELECT column_name1, column_name2, ... \nFROM table1 \nWHERE column BETWEEN value1 AND value2;value的值可以是数字、字符或者日期。在MySQL中，BETWEEN操作符的选择会包括value1和value2。\nORDER BY关键字ORDER BY关键字用于对结果集合进行排序，排序结果可以是升序或者降序。\nsqlSELECT column_name1, column_name2, ...\nFROM table1\nORDER BY column_name1, column_name2, ... ASC;升序操作为ASC，是默认的；降序操作为DESC。当有多个关键字需要排序时，将会按照语句中给出的顺序作为优先级进行排序。\nJOIN连接符JOIN连接符用于将两个或是多个表的行结合起来。包括LEFT JOIN, RIGHT JOIN, INNER JOIN, OUTER JOIN。\n\nINNER JOIN：如果表中有至少一个匹配，则返回行\nLEFT JOIN：即使右表中没有匹配，也从左表返回所有的行\nRIGHT JOIN：即使左表中没有匹配，也从右表返回所有的行\nFULL JOIN：只要其中一个表中存在匹配，则返回行\n\nCHECK约束CHECK约束用于限制列中的值得范围。\nsqlCREATE TABLE Persons\n(\n   P_Id int NOT NULL,\n   LastName varchar(255) NOT NULL,\n   FirstName varchar(255),\n   Address varchar(255),\n   City varchar(255),\n   CHECK (P_Id&gt;0)\n);或者在ALTER TABLE语句中\nsqlALTER TABLE Persons\nADD CHECK (P_Id&gt;0);CREATE INDEX语句该语句可用于在表中创建索引。在不读取整个表的情况下，索引可以加快数据库查找数据的速度。\n可以使用下列语句创建一个索引\nsqlCREATE INDEX index_name\nON table_name (column_name, ...);一个索引可以不只联系一个列，可以将多个列共同索引。  \n可以使用下列语句创建一个唯一索引\nsqlCREATE UNIQUE INDEX index_name\nON table_name (column_name, ...);唯一索引不允许有两个相同值的行存在。\nLIKE操作符LIKE操作符用于在WHERE子句中搜索列中的指定模式，使用%作为字符通配符，例如%Y将会匹配所有以Y结尾的字符串。\nsqlSELECT column_name, column_name1, ... \nFROM table_name\nWHERE column_name LIKE pattern;通常情况下，pattern中的通配符有两种：\n\n%：替代0个或多个字符\n_：替代一个字符\n\n但是若要匹配正则表达式，则可以使用如下语句\nsqlSELECT * FROM Websites\nWHERE name REGEXP &#39;^[GFs]&#39;;上述语句将匹配所有以G、F、s开头的列。\nAUTO_INCREMENT在MySQL中，创建表时添加AUTO_INCREMENT字段可以让属性自增。\nsqlCREATE TABLE Persons\n(\n   ID int NOT NULL AUTO_INCREMENT,\n   LastName varchar(255) NOT NULL,\n   FirstName varchar(255),\n   Address varchar(255),\n   City varchar(255),\n   PRIMARY KEY (ID)\n);默认地，AUTO_INCREMENT 的开始值是 1，每条新记录递增 1。\n要让 AUTO_INCREMENT 序列以其他的值起始，可以使用下面的 SQL 语法：\nsqlALTER TABLE Persons AUTO_INCREMENT=100ALTER TABLE该语句可以用于修改已有的表的列。\n\n在表中添加列 sqlALTER TABLE table_name\nADD column_name datatype\n在表中删除列sqlALTER TABLE table_name\nDROP COLUMN column_name\n在表中修改列sqlALTER TABLE Persons\nALTER COLUMN column_name datatype\n\n","slug":"数据库系统","date":"2022-04-08T14:18:27.000Z","categories_index":"基础","tags_index":"数据库,Review","author_index":"ClaRn"},{"id":"90140ac06394d08c40bf165531addc6d","title":"操作系统概述","content":"操作系统的特征\n并发：指两个或多个事件在同一时间间隔内发生。\n共享：资源共享，指系统中的资源可供内存中多个并发执行的进程共同使用。\n互斥型共享：资源在同一时刻只允许一个进程使用\n同时访问共享：资源可以在同一时刻由多个进程访问\n\n\n虚拟：指吧一个物理上的实体编程若干个逻辑上的对应物\n异步：进程的执行以不可预知的速度推进，在不同的时刻仅有一个进程占有处理机。\n\n操作系统的目标和功能操作系统的主要功能有：\n\n处理机管理\n存储器管理\n设备管理\n文件管理操作系统对用户提供命令接口，让用户可以方便、快捷地操作计算机。接口有：\n命令接口：可分为联机命令接口和脱机命令接口\n联机命令接口：交互式命令接口，即Shell\n脱机命令接口：批处理命令接口，即批处理脚本\n\n\n程序接口：由一组系统调用组成\n\n操作系统地发展和分类手工处理阶段此时没有真正意义上的操作系统，所有硬件都由用户自行管理。\n批处理阶段批处理系统可分为单道批处理系统和多道批处理系统。\n单道批处理系统系统对作业的处理是成批进行的，但内存中始终只保存一道作业。每当程序在进行IO操作时，CPU将会进行等待。\n多道批处理系统内存中不再只保存一道作业，而是可以允许多个程序同时进入内存，并在当前程序因为IO操作等原因陷入阻塞时，CPU将会转而执行其它程序。\n分时操作系统分时技术指将处理器的运行时间分为很短的时间片，按照时间片将处理器分配给各个作业使用。分时操作系统则是使用了分时技术，让多个用户可以通过终端共享同一台主机，由于计算机切换进程的时间极短，每个用户都能获得接近独占机器的体验。\n实时操作系统适合需要快速响应作业的场景，可以分为硬实时系统和软实时系统。硬实时系统将会绝对地在规定时间内执行任务，软实时系统可以偶尔违反时间规定。\n操作系统的运行环境操作系统的运行机制时钟管理操作系统通过时钟管理向用户提供标准的系统时间，同时通过时钟中断完成进程的切换。\n中断机制系统内核中用于管理设备、事件、调度等操作的机制。\n原语\n是操作系统中完成一个规定操作的小程序\n处于操作系统的最底层，是最接近硬件的部分\n程序的运行具有原子性，也就是说其执行不能被打断\n程序的运行时间短，且调用频繁\n\n系统控制的数据结构及处理\n进程管理，使用进程控制块(PCB)\n存储器管理\n设备管理\n\n中断和异常中断中断又称外中断，指来自CPU之外的事件的发生，如设备发出的IO中断或时钟发出的时钟中断。\n异常异常也称内中断、例外或者陷入(trap)，指CPU内部发生的如程序非法操作、地址越界、算术溢出、虚存系统缺页以及陷入指令所引发的事件。异常无法被屏蔽，且处理异常依赖于当前运行程序。GBD的Debug就是依赖trap指令实现的调试功能。\n中断处理的过程\n关中断\n保存断点\n中断服务程序寻址\n保护现场和屏蔽字\n开中断\n执行中断服务程序\n关中断\n恢复现场和屏蔽字\n开中断、中断返回\n\n系统调用系统调用的发生需要操作系统完成从用户态到内核态的转换，同时系统调用的函数使用的堆栈也将从用户堆栈切换到系统堆栈。用户可以通过trap指令来发起系统调用，trap指令又称为陷入指令或访管指令。访管指令是在用户态执行的，所以并非是特权指令。\n","slug":"操作系统概述","date":"2022-04-08T14:11:31.000Z","categories_index":"基础","tags_index":"Review,操作系统","author_index":"ClaRn"},{"id":"81579b6c641dedc829a2b0058112fc0c","title":"数据结构","content":"一、 数据结构与算法分析的基本概念（一）数据结构的基本概念\n数据数据是信息的载体，是描述客观事物属性的数字、字符以及所有能输入到计算机中被程序识别和处理的符号的集合\n数据元素 数据元素是数据的基本单位，一个数据元素由若干个 数据项 组成，数据项是数据元素中不可分割的最小单位。\n数据对象 数据对象是具有相同性质的数据元素的集合，是数据的一个子集。\n数据类型 数据类型是一个值的集合和定义在此集合上的一组操作的统称\n原子类型：值不可再分的数据类型\n结构类型：值可以再分解为若干分量的数据类型\n抽象数据类型(ADT) ：抽象数据组织以及相关操作，可以用抽象数据类型定义一个完整的数据结构\n\n\n数据结构 数据结构是相互之间存在一种或多种特定关系的数据元素的集合。数据元素之间的关系被称为结构。数据结构包括：逻辑结构、存储结构、数据运算。 数据的逻辑结构和存储结构是密不可分的两个方面，一个算法的设计取决于所选定的逻辑结构，而算法的实现依赖于所采用的存储结构。\n数据结构的三要素\n数据的逻辑结构逻辑结构是指数据元素之间的逻辑关系，即从逻辑关系上描述数据。它与数据的存储无关，是独立于计算机的。数据的逻辑结构分为线性结构和非线性结构，线性表就是典型的线性结构；集合、树、图就是典型的非线性结构。\n集合：结构中的数据之间除了“同属于一个集合”之外，没有别的关系\n线性结构：结构中的数据元素之间只存在一对一的关系\n树形结构：结构中的数据元素之间存在一对多的关系\n图或网状结构：结构中的数据元素之间存在多对多的关系\n\n\n数据的存储结构 存储结构是指数据结构再计算机中的表示，也称物理结构。它包括数据安苏的表示和关系的表示。数据的存储结构是用计算机语言实现的逻辑结构，它依赖于计算机语言。数据的存储结构主要有顺寻存储、链式存储、索引存储和散列存储\n顺序存储：把逻辑上相邻的元素存储在物理位置上也相邻的存储单元中，元素之间的关系由存储单元的邻接关系来体现。其优点是可以实现随机存取，每个元素占用最小的存储空间，缺点是只能使用相邻的一整块存储单元，因此可能产生较多外部碎片\n链式存储：不要求逻辑上相邻的元素在物理位置上也相邻，借助指示元素存储地址的指针来表示元素之间的逻辑关系。其优点是不会出现碎片现象，能充分利用所有存储单元；缺点是每个元素因存储指针而占用额外的存储空间，且只能实现顺序存取。\n索引存储：在存储元素信息的同时还建立附加的索引表。索引表中的每项称为索引项，索引项的一般形式是(关键字：地址)。其优点是检索速度快，缺点是附加的索引表额外占用存储空间。另外，增加和删除数据时也要修改索引表，因此比较耗时。\n散列存储(哈希存储)：根据元素的关键字直接计算出该元素的存储地址。其优点是减速、增加和删除节点的操作都很快；缺点是如果散列函数不好，则可能出现元素存储单元冲突，解决冲突则需要许多额外的时间和空间开销。\n\n\n数据的运算 施加在数据上的运算包括运算的定义和实现。运算的定义是针对逻辑机构，支出运算的功能；运算的实现是针对存储结构的，指出运算的具体操作步骤。\n\n\n\n（二）渐近算法分析方法\n算法的基本概念算法是对特定问题求解的一种描述，它是指令的有限序列，其中的每条指令代表一个或多个操作。此外，一个算法还具有下列五个重要特性：\n\n有穷性：一个算法必须总在执行完有穷步之后结束，且每一步都可再有穷时间内完成。\n确定性：算法中的每条指令必须有确切的含义，对于相同的输入只能得到相同的输出\n可行性：算法中描述的操作的可以通过已有实现的基本运算执行有限次来实现\n输入：输入取自某个特定的对象的集合\n输出：一个算法有一个或多个输出，这些输出是与输入有着某种特定关系的量通常一个好的算法应该达到：\n正确性：答案得是对的\n可读性：助于人们理解\n健壮性： 输入非法数据时能作出恰当的反应，没啥bug\n效率与低存储量需求：又快又好地执行\n\n\n算法效率的度量算法效率的度量是通过时间复杂度和空间复杂度来描述的\n\n\n（三）时间复杂度\n时间复杂度 一个语句的频度是指该语句在算法中被重复执行的次数，算法中所有语句频度之和记为，它是该算法问题规模的函数，时间复杂度主要分析的数量级。算法中基本运算(最深层循环内的语句)的频度与同数量级，因此通常采用算法中基本运算的频度(取中增长最快的项，比如,则取)来分析算法的时间复杂度。故算法的时间复杂度记为：。  \n 算法的时间复杂度不仅取决于问题规模，也取决于待输入数据的性质。  \n 分析程序的时间复杂性的两条规则：\n\n加法规则 :\n乘法规则 : 常见的渐进时间复杂度有 \n\n\n\n（四）空间复杂度\n空间复杂度 算法的空间复杂度定义为该算法所耗费的存储空间，它是问题规模的函数。记为 。  \n 一个程序在执行时除了需要存储空间来存放本身所用的指令、常数、变量和输入数据之外，还需要一些对数据进行操作的工作单元和存储一些为实现计算所需信息的辅助空间。若输入数据所占空间只取决于问题本身，和算法无关，则只需分析除输入和程序之外的额外空间。 \n 算法原地工作指算法所需的辅助空间为常量，即\n\n\n\n二、 线性表、栈和队列（一）线性表的定义和基本操作的设计线性表是具有相同数据类型的n个数据元素的有限序列，其中n为表长，当时线性表是一个空表。若用命名线性表，则其表示为：，式中，称为表头元素，a_n$称为表为元素，除第一个元素外，所有元素都只有一个直接前驱，除最后一个元素外，所有元素都只有一个直接后驱。\n故线性表的特点如下：\n\n表中元素个数有限\n表中元素具有逻辑上的顺序，元素之间有其先后顺序\n表中元素都是数据元素，每个元素都是单个元素\n表中元素的数据类型都相同，即每个元素占有相同大小的存储空间\n表中元素具有抽象性，即仅讨论元素之间的逻辑关系，而不考虑元素究竟表示什么内容\n\n线性表的基本操作:\n\nInitList(&amp;L):初始化\nLength(&amp;L):求表长\nLocateElem(L,e)：按值查找操作。在表L中查找具有给定关键字值的元素\nGetElem(L,i)：按位查找操作。返回表中第i个位置的元素\nListInsert(&amp;L,i,e)：插入操作。在表L中的第i个位置上插入指定元素e\nListDelete(&amp;L,i,&amp;e)：删除操作。删除表L中第i个位置的怨怒是，并用e返回删除元素的值\nPrintList(L)：输出操作。按前后顺序输出线性表L的所有元素值\nEmpty(L)：判空操作。若L为空表，返回true，否则返回false\nDestroyList(&amp;L)：销毁操作。释放内存空间\n\n（二）线性表的顺序存储结构和链式存储结构实现顺序表的定义:  线性表的顺序存储又称顺序表。它是用一组地址连续的存储单元一次存储线性表中的数据元素，从而使得逻辑上相邻的两个元素在物理位置上也相邻。第一个元素存储在线性表的起始位置，第i个元素存储在线性表的第i个位置，紧接着便是第i+1个元素，称i为元素在线性表中的位序。因此，顺序表的特点式表中元素的逻辑顺序与其物理顺序相同。\n  每个数据元素的存储位置都和线性表的起始位置相差一个和该数据元素的位序成正比的查那个书，因此线性表中的任意数据元素都可以随机存取。通常用高级程序设计语言中的数组来描述线性表的顺序存储结构。\ntxt线性表中的位序是从1开始的，而数组下标式从0开始的静态分配的线性表的顺序存储类型可以被表述为：\nc#define MaxSize 50         //线性表的最大长度\ntypedef struct {\n    ElemType data[MaxSize];//顺序表的元素\n    int length;            //顺序表当前的长度\n}SqList                    //顺序表的类型定义动态分配的线性表的顺序存储类型可以被表述为：\nc#define InitSize 50        //线性表的初始长度\ntypedef struct {\n    ElemType *data         //顺序表的元素\n    int length;            //顺序表当前的长度\n}SqList                    //顺序表的类型定义动态分配的线性表初始化时需要对data进行内存空间分配，分配空间大小可以动态变化，若空间不足，可以额外申请一块更大的连续内存将数据复制过去后，再释放原内存，但前提是系统内存空间足够。\n顺序表最主要的特点是随机访问，访问指定序号的元素的时间复杂度为\n顺序表的存储密度高，每个节点只存储数据元素，没有额外的指针域。\n单链表的定义:\n线性表的链式表示:\ntxt顺序表可以随时存取表彰的任意一个元素，它的存储位置可以用一个简单直观的公式表示，但插入和删除操作需要移动大量元素。链式存储线性表时，不需要使用地址连续的存储单元，即不要求逻辑上相邻的元素在物理位置上也相邻，它通过“链”建立起数据元素之间的逻辑关系，因此插入和删除操作不需要移动怨怒是，而只需要修改指针，但也会失去顺序表可以随机存取的优势。\n\n线性表的链式存储又称为单链表，它是指通过一组任意的存储单元来存储线性表中的数据元素。为了建立数据元素之间的线性关系，对每个链表节点，除存放元素自身的信息外，还需要存放一个指向其后继的指针。单链表节点描述为：\nctypedef struct LNode{\n    ElemType data;\n    struct LNode *next;\n)LNode,*LinkList;利用单链表可以解决顺序表需要大量连续存储单元的缺点，但单链表附加指针域，也存在浪费空间的缺点。由于节点的离散存储，所以单链表不支持随机存取。\n通常用头指针来标识一个单链表，如单链表L，头指针为NULL时表示一个空表。此外为了操作方便，在第一个存储数据的节点之前附加一个节点，称为头节点，头节点可以存储单链表长度，也可以不存储任何信息。\n（三）线性表的应用（四）栈和队列的基本概念和基本操作的设计栈\n栈的定义：栈是只允许在一端进行插入或删除操作的线性表\n栈顶：线性表允许进行删除的那一端\n栈底：固定的，不允许进行插入和删除的一端\n空栈：不含任何元素的空表\n栈的数学性质：个不同元素进栈，出栈不同排列组合的个数为 。上述公式称为卡特兰数。\n栈的基本操作\nInitStack(&amp;S):初始化\nStackEmpty(S):判断是否为空，若是则返回true，若不是则返回false\nPush(&amp;S,x):进栈，若栈S未满则将x加入使之成为新的栈顶\nPop(&amp;S,&amp;x):出栈，若栈非空，则弹出栈顶元素，并用x返回\nGetTop(S,&amp;x):读取栈顶元素\nDestroyStack(&amp;S):销毁栈若题干未限制，则可以直接使用这些基本操作函数\n\n\n\n队列\n队列的定义：队列简称队，是一种操作受限制的线性表，只允许在表的一端插入，另一端进行删除。\n入队(进队)：向表中进行数据插入\n出队(离队)：向表中进行数据删除\n队列的基本操作\nInitQueue(&amp;Q):初始化队列\nQueueEmpty(Q):判断是否为空\nEnQueue(&amp;Q,x):入队，若队列Q未满，则将x加入使之成为新的队尾\nDeQueue(&amp;Q,&amp;x):出队，若队列Q非空，删除队头元素，并用x返回。\nGetHead(!,&amp;x):读取队头元素，若队列非空则将队头元素赋值给x\n\n\n\n（五）栈和队列的顺序存储结构和链式存储结构实现栈的存储结构\n顺序存储结构\n\n实现cpp#define Maxsize 50 //栈中元素的最大个数\ntypedef struct {\n   ElemenType data[MaxSize]; //存放栈中元素\n   int top; //栈顶指针\n} SqStack;\n栈空条件：top = -1(若栈顶指针指向下一个空闲空间，则top = 0)；栈满条件：top = Maxsize -1; 栈长：top + 1;\n由于顺序栈的入栈操作受到数组上界的约束，当对栈的最大使用空间估计不足时，有可能发生栈上溢。\n\n\n链式存储结构\n\n实现cpptypedef struct LinkNode {\n   ElemType data;\n   struct LinkNode *next;\n} *LiStack; //相当于LinkNode*\n\n\n\n队列的存储结构\n顺序存储\n实现cpp#define Maxsize 50\ntypedef struct {\n   ElemType data[Maxsize];\n   int front,rear;\n} SqQueue;\n初始状态(队空条件)：front == rear == 0;进队操作：队不满时，先将值送到队尾元素，再将队尾指针加1；出队操作:先将值取出，再将队头指针加1\n普通队列不能用rear == Maxsize 判空，会出现假溢出\n循环队列的队列长度：(rear+Maxsize-front)%Maxsize (rear指向的是下一个空余空间，所以在没有超出Maxsize的情况下实际长度是(rear-front)-1)；循环队列的队首指针：front = (front+1)%Maxsize ；循环队列的队尾指针：rear = (rear+1)%Maxsize\n循环队列判断队满\n牺牲一个单元，规定rear+1 = front ，即尾指针的下一个单元是头指针时为满；此时队满条件为：(rear+1)%Maxsize = front;队空条件仍为：front == rear;队长为：(rear-front+Maxsize)%Maxsize\n类型中新增表示元素个数的数据成员size，表示队满的条件则为size == Maxsize\n类型中新增tag数据成员，以区分是队满还是队空。tag == 0时，若因删除导致front == rear则为队空；tag == 1时，若因插入导致front == rear，则为队满。\n\n\n\n\n\n（六）栈和队列的应用\n三、 二叉树和树（一）二叉树\n二叉树的定义及其主要特征\n\n二叉树是另一种树形结构，其特点是每个结点至多只有两颗子树（即二叉树中不存在度大于2的结点），并且二叉树的子树有左右之分，其次序不能随意颠倒。与树相似，二叉树也以递归的形式定义。二叉树是个结点的有限集合：  \n或者为空二叉树，即\n或者由一个根节点和两个互不相等的被称为根的左子树和右子树组成。左子树和右子树又分别是一棵二叉树\n\n\n\n二叉树是有序树，若其左、右子树颠倒，则成为另一颗不同的二叉树，即使树中结点只有一棵子树，也要区分它是左子树还是右子树。\n\n满二叉树：\n高度为且结点数为的二叉树。即树中每层的结点都是满的。\n满二叉树的叶子结点均在最下一层，且除叶子结点外每个节点的度均为2 。\n满二叉树的编号：\n从根节点开始（根节点为1），自上到下，从左到右依次排号。\n若编号为的子节点有双亲，则双亲编号为向上取整，左孩子结点编号为，右孩子的结点编号为\n\n\n\n\n完全二叉树：\n高度为、有个结点的二叉树，当且仅当其每个结点都与高度的满二叉树中编号为的结点一一对应时称为完全二叉树（人话版：所有节点的序号排列都和满二叉树里的排列一样）\n若舍去小数取整，则有结点为分支节点，否则必为叶子结点。因为要一一对应的话，就会和满二叉树类似叶子结点几乎分布于最底层。\n叶子结点只可能在层次最大的两层上出现，最大层次中的叶子结点都依次排列在最左侧的位置上。意即从最底层的最左侧开始分布，一直排列到最右侧，排满了就是满二叉树了嗷。\n若有度为1的结点，则只可能有1个，且该结点只有左孩子。\n按层序编号后，一旦出现某节点为叶子结点或只有左孩子，则编号大于该节点的均为叶子结点（上一条性质为原理）\n若为奇数，则每个分支结点都有左孩子和右孩子，若为偶数，则编号最大的分支结点（编号为）只有左孩子，没有右孩子，其余分支结点左右孩子都有。\n\n\n二叉排序树：\n左子树上所有结点的关键字均小于根节点的关键字；右子树上所有结点的关键字均大于根节点的关键字；左子树和右子树又各是一颗二叉排序树。\n\n\n平衡二叉树：\n树上任意结点的左子树和右子树的深度之差不超过1 。\n\n\n\n\n二叉树的顺序存储结构和链式存储结构实现\n\n顺序结构存储二叉树的顺序存储结构是指用一组地址连续的存储单元依次自上而下、自左向右地存储完全二叉树上地结点，即将完全二叉树上编号为$i$地结点存储在一维数组下标为$i-1$中\n依据二叉树的性质，完全二叉树和满二叉树采用顺序存储更加合适，树中结点的序号可以唯一反应结点的逻辑关系，这样既能节省存储空间，又能利用数组元素的下标值迅速地确定结点在二叉树中的位置。\n但一般的二叉树中的空结点则需要在数组中相应位置进行补0，由此可能造成较大存储空间浪费\n\n链式结构存储使用结构体或类构建结点：\ncpptypedef struct BiTNode{\n   ElemType data;\n   struct BiTNode *lchild,*rchild;\n}BiTNode,*BiTree在含有个结点的二叉链表中，含有个空链域。\n\n\n使用不同存储结构时，实现二叉树的操作算法也会不同，因此要根据实际应用场景选择合适的存储结构\n\n二叉树的遍历及应用二叉树的遍历指按照某条搜索路径访问树中的每个节点，使得每个节点均被访问一次，而且仅被访问一次。由于二叉树是一种非线性结构，每个节点都可能有两颗子树，因此还需要寻找一种规律，以便使二叉树上的结点能排列在一个线性队列上，进而进行遍历。\n常见的遍历次序有：先序(NLR)、中序(LNR)、后续(LRN)三种遍历算法，其中的序指的是根节点何时被访问，需要注意的是，左节点永远先于右节点被访问。\n1、 先序遍历\n若二叉树为空，则直接返回\n先访问根节点\n先序遍历左子树\n先序遍历右子树\n\n代码如下：\ncppvoid PerOrder(BiTree T) {\n   if(T != NULL) {\n      visit(T);\n      PerOrder(T-&gt;lchild);\n      PerOrder(T-&gt;rchild);\n   }\n}2、 中序遍历\n若二叉树为空，直接返回\n中序遍历左子树\n访问根节点\n中序遍历右子树\n\n代码如下：\ncppvoid InOrder(BiTree T) {\n   if(T != NULL) {\n      InOrder(T-&gt;lchild);\n      visit(T);\n      InOrder(T-&gt;rchild)\n   }\n}3、 后序遍历\n后序遍历左子树\n后序遍历右子树\n访问根节点\n\n代码如下：\ncppvoid PostOrder(BiTree T) {\n   if(T != BULL) {\n      PostOrder(T-&gt;lchild);\n      PostOrder(T-&gt;rchild);\n      visit(T);\n   }\n}\n三种遍历算法中，不管采用哪种遍历算法，每个节点都访问一次且仅访问一次，故时间复杂度都是，在递归遍历中，递归工作栈的深度恰好为树的深度，故最坏情况下遍历算法的空间复杂度为。\n递归算法和非递归算法的转换中序遍历：cppvoid InOrder2(BiTree T) {\n   InitStack(S);\n   BiTree p = T;\n\n   while(p != NULL||!isEmpty(S)) {\n      if(p != NULL) {\n         //将根节点入栈并在下一个循环访问左节点\n         Push(S,p);\n         p=p-&gt;lchild;\n      } else {\n         //出栈根节点的同时访问根节点\n         Pop(S,p);\n         visit(p);\n         //下一个循环访问右节点\n         p=p-&gt;rchild;\n      }\n   }\n}先序遍历：先序遍历的实现与中序遍历相似，只需要在入栈时先访问根节点即可\ncppvoid PreOrder2(BiTree T) {\n   InitStack(S);\n   BiTree p = T;\n\n   while(p != NULL||!isEmpty(S)) {\n      if(p != NULL) {\n         //访问根节点\n         visit(p);\n         //将根节点入栈并在下一个循环访问左节点\n         Push(S,p);\n         p=p-&gt;lchild;\n      } else {\n         //出栈根节点\n         Pop(S,p);\n         //下一个循环访问右节点\n         p=p-&gt;rchild;\n      }\n   }\n}后序遍历后序遍历算法思想与之前两种不同，需要保证在根节点出栈时右节点已被访问完。\ncppvoid PostOrder(BiTree T) {\n   InitStack(S);\n   p=T;\n   r=NULL;  //用于记录最近访问过的结点\n   while(p != NULL||!IsEmpty(S)) {\n      if (p) {\n         Push(S,p);\n         //走到最左边\n         p=p-&gt;lchild;\n      } else {\n         //获取根节点\n         Peek(S,p);\n         if(p-&gt;rchild != NULL&amp;&amp;p-&gt;rchild != r) {\n         //走到右边\n         p=p-&gt;rchild;\n         } else {\n         Pop(S,p);\n         visit(p);\n         r=p;\n         p=NULL;\n         }\n      }\n   }\n}层次遍历需要借助队列实现，每访问一个节点就将该节点的孩子节点输入队列，并将该节点出队\ncppvoid LevelOrder(BiTree T) {\n   InitQueue(Q);\n   BiTree p;\n   EnQueue(Q,T);\n   while(!IsEmpty(Q)) {\n      DeQueue(Q,p);\n      visit(p);\n      if(p-&gt;lchild != NULL) {\n         EnQueue(Q,p-&gt;lchild);\n      }\n      if(p-&gt;rchild != NULL) {\n         EnQueue(Q,p-&gt;rchild);\n      }\n   }\n}由遍历序列构建二叉树\n二叉树的先序序列和中序序列可以唯一确定一颗二叉树\n先序遍历中第一个结点一定是二叉树的根节点；中序遍历中，根节点必然将中序序列分割为两个子序列，前一个子序列是根节点的左子树的中序序列，后一个子序列是根节点的右子树的中序序列。\n\n\n二叉树的后序序列和中序序列也可以唯一确定一颗二叉树\n二叉树的层序序列和中序序列也可以唯一确定一颗二叉树\n\n 除了先序序列和后序序列其余两种任意序列的组合都可以构建出二叉树。构建二叉树需要明确知道根节点和左右子树，而先序序列和后序序列无法确定左右子树。\n\n二叉排序（查找. 检索）树  \n\n平衡的二叉检索树- AVL树  \n\n堆  \ncpp#define DEFAULT_DATA_SIZE 10\n/***\n* 大顶堆\n*/\ntemplate&lt;class T&gt;\nclass Heap\n{\nprivate:\n   /* data */\n   T* _data;\n   size_t _max_size = 0;\n   size_t size = 0;\n\n   size_t _get_left_child_index(size_t index) {\n      return 2*index+1;\n   }\n\n   size_t _get_right_child_index(size_t index) {\n      return 2*index+2;\n   }\n\n   size_t _get_root_index(size_t index) {\n      return (index-1)/2;\n   }\n\n   bool _is_empty() {\n      return size == 0;\n   }\n\n   bool _is_full() {\n      return size == _max_size;\n   }\n\n   void _alloc() {\n      T* tmp = _data;\n      _data = new T[_max_size*2];\n      for (size_t i = 0; i &lt; _max_size; i++)\n      {\n            _data[i] = tmp[i];\n      }\n      _max_size *= 2;\n      delete[] tmp;\n   }\n\n   void _shiftUp(size_t index) {\n      if (index == 0) return;\n      size_t root = _get_root_index(index);\n      if (_data[root] &lt; _data[index])\n      {\n            T tmp = _data[root];\n            _data[root] = _data[index];\n            _data[index] = tmp;\n      }\n\n      _shiftUp(root);\n   }\n\n   void _shiftDown(size_t index) {\n      if (index == size) return;\n      size_t lc = _get_left_child_index(index);\n      size_t rc = _get_right_child_index(index);\n      size_t max = lc &gt; rc ? lc : rc;\n      if (_data[max] &gt; _data[index])\n      {\n            T tmp = _data[max];\n            _data[max] = _data[index];\n            _data[index] = tmp;\n            _shiftDown(lc);\n      }\n   }\n\npublic:\n   explicit Heap(size_t max_size = DEFAULT_DATA_SIZE) {\n      _max_size = max_size;\n      _data = new T[_max_size];\n   }\n\n   ~Heap() {\n      delete[] _data;\n   }\n\n   void insert(T data) {\n      if (_is_full())\n      {\n            _alloc();\n      }\n\n      _data[size] = data;\n      _shiftUp(size);\n      size++;\n   }\n\n   T removeAt(size_t index) {\n      T data = _data[index];\n      _data[index] = _data[--size];\n      _shiftDown(index);\n      return data;\n   }\n\n   T remove() {\n      return removeAt(0);\n   }\n\n   size_t length() {\n      return size;\n   }\n\n   size_t getMaxSize() {\n      return _max_size;\n   }\n\n   std::string toString() {\n      std::string s = \"[\";\n      for (size_t i = 0; i &lt; size; i++)\n      {\n            s += to_string(*(_data+i));\n            if (i != size-1)\n            {\n               s += \" ,\";\n            } else {\n               s += \"] size = \"+to_string(size) + \" max_size = \"+to_string(_max_size);\n            }\n      }\n\n      return s;\n   }\n\n};\n哈夫曼（Huffman）树和哈夫曼编码\n\n\n（二）树\n树的定义与术语  \n树的定义树是个节点的有限集。当时，称为空树。在任意一颗空树中应满足：\n\n有且只有一个特定称为根的节点\n当时，其余节点可分为个互不相交的有限集，其中每个集合本身又是一棵树，并且称为根的子树。\n\n显然，树的定义是递归的，即在书的定义中又用到了自身，树是一种递归的数据结构。树作为一种逻辑结构，同时也是一种分层结构，具有以下两个特点：\n\n树的根节点没有前驱，除根节点外的所有节点有且只有一个前驱。\n树的所有节点可以有零个或多个后继。\n\n树适合于表示具有层次的数据。树中的某个节点（除根节点外）最多只和上一层的一个节点（即其父节点）有直接关系，根节点没有直接上层节点，因此在个节点的树中有条边。而树中每个节点与其下一层的零个或多个节点（即其子女节点）有直接关系。\n基本术语\n树中一个节点的孩子个数称为该节点的度，树中节点的最大度数称为树的度。\n度大于0的节点称为分支节点，度为0的节点称为叶子节点。在分支结点中，每个结点的分支数就是该结点的度。\n结点的深度、高度和层次\n结点的深度是从根节点开始自顶向下逐层累加的\n结点的高度是从叶节点开始自底向上逐层累加的\n树的高度是树中节点的最大层数\n有序树和无序树\n有序树：树中的结点的各子树从左到右是有次序的，不能互换（次序人为规定）\n无序树：否则成为无序树\n路径和路径长度\n路径：由树中这两个结点之间所经过的结点序列构成的\n路径长度：路径所经过的边的数量\n森林是棵互不相交的树的集合。森林的概念与树的概念十分相近，因为只要把树的根节点删去就成了森林。反之，只要给棵独立的树加上一个结点，并把这棵树作为该节点的子树，则森林就变成了树\n\n树具有如下基本性质：\n\n树中的节点数等于所有结点度数之和加1\n度为的树中第层上至多有\n高度为的叉树最多有个节点\n具有个结点的叉树的最小高度为\n\n\n树的遍历  \n\n树的顺序存储结构和链式存储结构实现\n\n\n\n四、 图（一）图的基本概念图G由顶点集V和边集E组成，记为，其中表示图G中顶点的有限非空集；表示图中顶点之间的关系（边）集合。\n线性表可以是空表、树可以有空树，但图不能是空图，图中至少有一个节点，但可以没有边\n\n有向图若E是有向边(弧)的有限集合时，图G为有向图，。弧是顶点的有序对，记为&lt;v,w&gt;，其中v,w是顶点，v称为弧尾，w称为弧头。也称v邻接到w。\n\n无向图若E是无向边(边)的有限集合时，图G为无向图。边是顶点的无序对，记为(v,w)或(w,v)。可以说w和v互为邻接点。\n\n简单图、多重图 一个图若满足：\n\n不存在重复边\n不存在顶点到自身的边\n\n则称该图为简单图。若图中某两个顶点之间的边数大于1，又允许顶点通过一条边和自身关联，则称该图为多重图。\n\n完全图（简单完全图）对于无向图，|E|的取值范围在0之间，有条边的无向图称为完全图，在完全图中任意两个顶点之间都存在边；对于有向图，|E|的取值范围在0之间，有条边的有向图称为完全有向图，有向完全图中任意两个顶点之间都存在方向相反的两条弧。\n\n子图若存在一个使得是的子集，是的子集，则将称为的子图。若，则将称为的生成子图。\n\n连通、连通图和连通分量(特指无向图)\n\n\n\n连通：在无向图中，若从顶点v到顶点w有路径存在，则称v和w是连通的。\n连通图：若图中任意两个顶点都是连通的，则称该图为连通图，否则便是非连通图。\n连通分量：无向图中的极大连通子图称为该图的连通分量。(极大连通子图即该图的连通子图且该子图拥有的顶点数无法再增加，若增加就不在连通，且包含所有边)\n\n\n强连通图、强连通分量(特指有向图)\n\n\n强连通：有向图中若v到w和w到v之间都存在路径，则称这两个顶点是强连通的。\n强连通图：有向图中的任意两个结点都是强连通的，则该图称为强连通图。\n强连通分量：有向图中的极大强连通子图。\n\n\n生成树、生成森林\n\n\n生成树：包含图中所有结点的一个极小连通图。若图中有n个顶点，则生成树有n-1条边(极小连通图需要保证的是图的连通且边数最少)(若砍去生成树中的一条边，则该极小连通图退化为非连通图，若加上一条边则会产生一个回路)\n生成森林：非连通图中的连通子图的生成树构成了一片生成森林。\n\n\n顶点的度、出度、入度\n\n\n度：依附于顶点的边的条数，记为。对于具有n个顶点、e条边的无向图，所有顶点的度之和为2e(一条边代表两个度嘛)。有向图的顶点的度为该顶点出度和入度之和。\n入度：在有向图中以顶点v为终点的边的数目，记为\n出度：在有向图中以顶点v为起点的边的数目，记为\n在有向图中所有顶点的出度和等于所有顶点的入度和\n\n\n边的权和网\n\n\n权值：每条边都可以标注具有某种意义的数值，该值称为权值\n网： 边上带有权值的图称为带权图，或网\n\n\n稠密图、稀疏图\n\n\n稀疏图：边数很少的图\n稠密图：边数很多的图\n判断条件：，则为稀疏图\n\n\n路径、路径长度、回路\n\n\n路径:顶点到之间的一条路径指顶点序列\n路径长度：路径上边的数量\n回路：第个顶点和最后一个顶点相同的路径称为回路。若一个图有n个顶点，但有大于n-1条边，则此图一定存在回路。\n\n\n距离从顶点u出发到v的最短路径长度，若该路径不存在，则距离为无穷∞\n\n有向树一个顶点的入度为0、其余顶点的入度均为1 的图称为有向树。\n\n\n（二）图的存储及基本操作\n邻接矩阵 采用一个一维数组存储图中顶点的信息，用一个二维数组存储图中边的信息(即各个顶点之间的关系)，存储顶点之间邻接关系的二维数组称为邻接矩阵。点中的数据使用一维数组保存，一维数组下表代表顶点编号，边使用二维数组保存，边的两个端点即二维数组的两个下标，由于这两个下标有ij和ji两种排列状态，故可以表示有向图。若为无向图时，该矩阵为对称矩阵。二维数组中的值代表有无边或者边的权值\n代码定义如下\ncpp#define MaxVertexNum 100\ntypedef char VertesType;\ntypedef int EdgeType;\ntypedef struct{\n   VertexType vex[MaxVertNum]; //顶点表，存数据\n   EdgeType Edge[MaxVertexNum][MaxVertexNum]; //邻接表\n   int vexnum,arcnum; //图的当前顶点数和弧数\n} MGraph;\n在简单应用中，可以直接使用二维数组存储图，即忽略掉图的顶点信息\n当邻接矩阵的元素仅表示相应边是否存在时，EdgeType可采用值为0和1的枚举类型\n无向图的邻接矩阵是对称矩阵，对规模大的图可以压缩存储\n邻接矩阵表示法的空间复杂度为，其中n为图的顶点数\n\n特点：\n\n无向图的邻接矩阵一定是一个对称矩阵(并且唯一)\n对于无向图，邻接矩阵的第i行(或第i列)非零元素分个数正好是顶点i的度\n对于无向图，邻接矩阵的第i行非零元素的个数正好是顶点i的出度，第i列的非零元素刚好是顶点的入度\n用邻接矩阵存储图，很容易确定图中的任意两个顶点是否有边相连。但是，要确定图中有多少条边，则必须按行、列扫描检测，时间开销巨大。\n稠密图适合使用邻接表表示\n\n\n邻接表\n\n\n（三）图的遍历\n深度优先搜索\n广度优先搜索\n\n（四）图的应用\n拓扑排序\n关键路径\n最短路径\n最小（代价）生成树\n\n\n五、 查找（一）查找的基本概念\n查找：在数据集合中寻找满足某种条件的数据元素的过程称为查找。查找的结果一般分为两种：查找成功和失败\n查找表：用于查找的数据集合称为查找表，它由同一类型的数据元素(或记录)组成  \n静态查找表：若一个静态查找表只有查询指定数据和查找满足某个条件的数据的各种属性，无需动态地修改查找表，适合静态查找表的查找方法有：顺序查找，折半查找，散列查找等\n动态查找表：需要动态地添加和删除的查找表。适合动态查找表的查找方法有：二叉排序树查找，散列查找等\n关键字：数据元素中唯一标识该元素的某一个数据项的值，使用基于关键字的查找，查找结果应该是唯一的。\n平均查找长度：在查找过程中一次查找的长度是指需要比较的关键字次数，而平均查找长度则是所有查找过程中进行关键字的比较次数的平均值，其数学定义为 式中，n是查找表的长度；是查找第i个数据的概率，一般认为每个数据元素的查找概率均等，即；是找到第i个数据元素需要的比较次数。平均查找长度是衡量查找算法效率的最主要指标\n\n（二）顺序查找法（三）折半查找法(二分查找)（五）散列（Hash）表及冲突解决策略\n构造方法\n直接定址法\nH(key) = key 或 H(Key) = a*key + b\n适合关键字分布连续的情况\n\n\n除留余数法\n假定散列表长为m ,取一个不大于m 但最接近或等于m 的质数p ，将关键字按照公式  转换为散列地址，需要选好p ，使得每个关键字通过函数转换后等概率地映射到散列空间上\n\n\n数字分析法\n设关键字是r进制数，而r 个数码在各位上出现的频率不一定相同，可能在某些位上分布的更均匀一些，每种数码出现的机会均等；而在某些位上分布不均匀，只有某几种数码经常出现，此时应选取数码分布较为均匀的若干位作为散列地址，这种发给发适用于已经知道关键字的集合，因为一旦关键字被修改，则需要重新构造一个新的散列函数\n\n\n平方取中法\n取关键字的平方值的中间几位作为散列地址。具体取多少位要视情况而定。这种方法得到的散列地址与关键字的每一位都有关系，所以可以使得散列地址分布比较均匀。适用于关键字的每位取值都不够均匀或者均小于散列地址所需要的位数\n\n\n\n\n冲突解决策略\n开放定址法\n可存放新表项(Entry) 的空闲地址空间既向它的同义词表项开放，又向非同义词表项开放。记为 ，式子中表示散列函数；； 表示散列表长；表示增量序列。\n增量序列确定后，对应的处理方法就是确定的。通常有如下四种方法：\n线性探测法。当，，，，。。。，时，称为线性探测法，这种方法的特点是：冲突发生时，顺序查看表中下一个单元(到达表的末尾时，下一个探测地址就是表首地址0)，直到查找出一个空闲单元(表未填满时一定会找到一个空闲单元)或查遍全表。线性探测法可能使第i个散列地址的同义词存入第i+1个散列地址，这样本应存入第i+1个散列地址的同义词就只能存入i+2个散列地址，从而造成大量元素在相邻散列地址上“聚集”，极大降低了查找效率\n平方探测法(二次探测法)。增量序列 。散列表的长度必须是可以表示为4k+3的素数。平方探测法处理冲突可以避免出现“堆积”问题，缺点是不能探测到所有单元，但至少能探测到一半的单元\n再散列法(双散列法)。，当第一个散列函数发生冲突时，通过第二个散列函数计算该关键字的地址增量 其中i是发生冲突的次数，初始为0。最多经过次探测便可以遍历表中所有的位置\n伪随机散列法。将设置为伪随机数列。\n\n\n在开放定址法中，不能随便物理删除表中元素，若删除元素，则会截断其它具有相同散列地址的元素的查找地址。因此，要删除一个元素时，可以给它做一个删除标记，进行逻辑删除。但是这样就需要定期维护散列表将其中被标记删除的元素进行物理删除\n\n\n拉链法\n为了避免非同义词产生冲突，可以通过把所有同义词存储到一个线性链表中，这个线性链表再由其散列地址唯一标识。适用于对数据进行大量删除和插入操作的情况\n\n\n\n\n\n（六）查找算法的分析及应用\n六、 内排序（一）排序的基本概念排序：指重新排列表中的元素，使表中的元素满足按关键字有序的过程。\n排序算法的稳定性：若待排序表中有两个元素和，其对应关键字相同即，且在排序前在前面，若使用某一排序算法排序后，仍然在前面，则称这个算法使稳定的，否则这个算法就是不稳定的\n在排序过程中根据数据元素是否完全在内存中可以将算法分为两类：内部排序和外部排序\n\n内部排序：指在排序期间所有元素全部放在内存中的排序\n外部排序：指在排序期间元素无法全部同时存放在内存中，必须在排序的过程中根据要求不断地在内、外存之间移动的排序。\n\n（二）直接插入排序java（三）冒泡排序javapublic static void bubbleSort(int[] arr) {\n    int temp = 0;\n    for (int i = arr.length - 1; i &gt; 0; i--) { // 每次需要排序的长度\n        for (int j = 0; j &lt; i; j++) { // 从第一个元素到第i个元素\n            if (arr[j] &gt; arr[j + 1]) {\n                temp = arr[j];\n                arr[j] = arr[j + 1];\n                arr[j + 1] = temp;\n            }\n        }//loop j\n    }//loop i\n}// method bubbleSort（四）简单选择排序javapublic static void selectionSort(int[] arr) {\n    int temp, min = 0;\n    for (int i = 0; i &lt; arr.length - 1; i++) {\n        min = i;\n        // 循环查找最小值\n        for (int j = i + 1; j &lt; arr.length; j++) {\n            if (arr[min] &gt; arr[j]) {\n                min = j;\n            }\n        }\n        if (min != i) {\n            temp = arr[i];\n            arr[i] = arr[min];\n            arr[min] = temp;\n        }\n    }\n}用数组实现的选择排序是不稳定的，用链表实现的选择排序是稳定的。\n（五）希尔排序（shell sort）先将整个待排序的记录序列分割成为若干子序列分别进行直接插入排序，具体算法描述：\n\n选择一个增量序列t1，t2，…，tk，其中ti&gt;tj，tk=1；\n按增量序列个数k，对序列进行 k 趟排序；\n每趟排序，根据对应的增量ti，将待排序列分割成若干长度为m 的子序列，分别对各子表进行直接插入排序。仅增量因子为1 时，整个序列作为一个表来处理，表长度即为整个序列的长度。\n\njavapublic static void shellSort(int[] arr){\n    int temp;\n    for (int delta = arr.length/2; delta&gt;=1; delta/=2){                              //对每个增量进行一次排序\n        for (int i=delta; i&lt;arr.length; i++){              \n            for (int j=i; j&gt;=delta &amp;&amp; arr[j]&lt;arr[j-delta]; j-=delta){ //注意每个地方增量和差值都是delta\n                temp = arr[j-delta];\n                arr[j-delta] = arr[j];\n                arr[j] = temp;\n            }\n        }//loop i\n    }//loop delta\n}（六）快速排序从数列中挑出一个元素，称为”基准”（pivot），然后重新排序数列，所有比基准值小的元素摆放在基准前面，所有比基准值大的元素摆在基准后面（相同的数可以到任何一边）。在这个分区结束之后，该基准就处于数列的中间位置。这个称为分区（partition）操作。\n递归地（recursively）把小于基准值元素的子数列和大于基准值元素的子数列排序。\njavapublic static void quickSort(int[] arr){\n    qsort(arr, 0, arr.length-1);\n}\nprivate static void qsort(int[] arr, int low, int high){\n    if (low &gt;= high)\n        return;\n    int pivot = partition(arr, low, high);        //将数组分为两部分\n    qsort(arr, low, pivot-1);                   //递归排序左子数组\n    qsort(arr, pivot+1, high);                  //递归排序右子数组\n}\nprivate static int partition(int[] arr, int low, int high){\n    int pivot = arr[low];     //基准\n    while (low &lt; high){\n        while (low &lt; high &amp;&amp; arr[high] &gt;= pivot) --high;\n        arr[low]=arr[high];             //交换比基准大的记录到左端\n        while (low &lt; high &amp;&amp; arr[low] &lt;= pivot) ++low;\n        arr[high] = arr[low];           //交换比基准小的记录到右端\n    }\n    //扫描完成，基准到位\n    arr[low] = pivot;\n    //返回的是基准的位置\n    return low;\n}（七）堆排序堆排序(Heapsort)是指利用堆积树（堆）这种数据结构所设计的一种排序算法，它是选择排序的一种。可以利用数组的特点快速定位指定索引的元素。堆排序就是把最大堆堆顶的最大数取出，将剩余的堆继续调整为最大堆，再次将堆顶的最大数取出，这个过程持续到剩余数只有一个时结束。堆排序存在大量的筛选和移动过程，属于不稳定的排序算法。\njavapublic class ArrayHeap {\n    private int[] arr;\n    public ArrayHeap(int[] arr) {\n        this.arr = arr;\n    }\n    private int getParentIndex(int child) {\n        return (child - 1) / 2;\n    }\n    private int getLeftChildIndex(int parent) {\n        return 2 * parent + 1;\n    }\n    private void swap(int i, int j) {\n        int temp = arr[i];\n        arr[i] = arr[j];\n        arr[j] = temp;\n    }\n    /**\n     * 调整堆。\n     */\n    private void adjustHeap(int i, int len) {\n        int left, right, j;\n        left = getLeftChildIndex(i);\n        while (left &lt;= len) {\n            right = left + 1;\n            j = left;\n            if (j &lt; len &amp;&amp; arr[left] &lt; arr[right]) {\n                j++;\n            }\n            if (arr[i] &lt; arr[j]) {\n                swap(array, i, j);\n                i = j;\n                left = getLeftChildIndex(i);\n            } else {\n                break; // 停止筛选\n            }\n        }\n    }\n    /**\n     * 堆排序。\n     * */\n    public void sort() {\n        int last = arr.length - 1;\n        // 初始化最大堆\n        for (int i = getParentIndex(last); i &gt;= 0; --i) {\n            adjustHeap(i, last);\n        }\n        // 堆调整\n        while (last &gt;= 0) {\n            swap(0, last--);\n            adjustHeap(0, last);\n        }\n    }\n\n}（八）归并排序javapublic static void mergeSort(int[] arr){\n    int[] temp =new int[arr.length];\n    internalMergeSort(arr, temp, 0, arr.length-1);\n}\nprivate static void internalMergeSort(int[] arr, int[] temp, int left, int right){\n    //当left==right的时，已经不需要再划分了\n    if (left&lt;right){\n        int middle = (left+right)/2;\n        internalMergeSort(arr, temp, left, middle);          //左子数组\n        internalMergeSort(arr, temp, middle+1, right);       //右子数组\n        mergeSortedArray(arr, temp, left, middle, right);    //合并两个子数组\n    }\n}\n// 合并两个有序子序列\nprivate static void mergeSortedArray(int arr[], int temp[], int left, int middle, int right){\n    int i=left;      \n    int j=middle+1;\n    int k=0;\n    while (i&lt;=middle &amp;&amp; j&lt;=right){\n        temp[k++] = arr[i] &lt;= arr[j] ? arr[i++] : arr[j++];\n    }\n    while (i &lt;=middle){\n        temp[k++] = arr[i++];\n    }\n    while ( j&lt;=right){\n        temp[k++] = arr[j++];\n    }\n    //把数据复制回原数组\n    for (i=0; i&lt;k; ++i){\n        arr[left+i] = temp[i];\n    }\n}（九）基数排序将所有待比较数值（正整数）统一为同样的数位长度，数位较短的数前面补零。然后，从最低位开始，依次进行一次排序。这样从最低位排序一直到最高位排序完成以后, 数列就变成一个有序序列。\njavapublic abstract class Sorter {\n     public abstract void sort(int[] array);\n}\n \npublic class RadixSorter extends Sorter {\n     \n     private int radix;\n     \n     public RadixSorter() {\n          radix = 10;\n     }\n     \n     @Override\n     public void sort(int[] array) {\n          // 数组的第一维表示可能的余数0-radix，第二维表示array中的等于该余数的元素\n          // 如：十进制123的个位为3，则bucket[3][] = {123}\n          int[][] bucket = new int[radix][array.length];\n          int distance = getDistance(array); // 表示最大的数有多少位\n          int temp = 1;\n          int round = 1; // 控制键值排序依据在哪一位\n          while (round &lt;= distance) {\n               // 用来计数：数组counter[i]用来表示该位是i的数的个数\n               int[] counter = new int[radix];\n               // 将array中元素分布填充到bucket中，并进行计数\n               for (int i = 0; i &lt; array.length; i++) {\n                    int which = (array[i] / temp) % radix;\n                    bucket[which][counter[which]] = array[i];\n                    counter[which]++;\n               }\n               int index = 0;\n               // 根据bucket中收集到的array中的元素，根据统计计数，在array中重新排列\n               for (int i = 0; i &lt; radix; i++) {\n                    if (counter[i] != 0)\n                         for (int j = 0; j &lt; counter[i]; j++) {\n                              array[index] = bucket[i][j];\n                              index++;\n                         }\n                    counter[i] = 0;\n               }\n               temp *= radix;\n               round++;\n          }\n     }\n     \n     private int getDistance(int[] array) {\n          int max = computeMax(array);\n          int digits = 0;\n          int temp = max / radix;\n          while(temp != 0) {\n               digits++;\n               temp = temp / radix;\n          }\n          return digits + 1;\n     }\n     \n     private int computeMax(int[] array) {\n          int max = array[0];\n          for(int i=1; i&lt;array.length; i++) {\n               if(array[i]&gt;max) {\n                    max = array[i];\n               }\n          }\n          return max;\n     }\n}（十）各种内排序算法的比较\n","slug":"数据结构","date":"2022-04-08T14:10:10.000Z","categories_index":"基础","tags_index":"Review,数据结构","author_index":"ClaRn"},{"id":"c3b702e5ef74e2906ec0f752e1fc7991","title":"Android 字节码解析","content":"将APK反编译到Smalishellapktool d app.apkDalvik字节码格式shellmove vA, vB","slug":"Android-字节码解析","date":"2022-04-07T16:39:09.000Z","categories_index":"开发","tags_index":"Android","author_index":"ClaRn"},{"id":"b9663f58f18133b35bfe243f3e916a80","title":"Hello World","content":"Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub.\nQuick StartCreate a new postbash$ hexo new &quot;My New Post&quot;More info: Writing\nRun serverbash$ hexo serverMore info: Server\nGenerate static filesbash$ hexo generateMore info: Generating\nDeploy to remote sitesbash$ hexo deployMore info: Deployment\n","slug":"hello-world","date":"2022-04-07T16:12:09.000Z","categories_index":"","tags_index":"","author_index":"ClaRn"}]