[{"id":"a1b53e1281173f553545a82d3e9f99c2","title":"PCA&LR作业","content":"给定两类样本的特征，其中\n类别1：(0,0,0)T,(1,0,0)T,(1,0,1)T,(1,1,0)T{(0,0,0)^T,(1,0,0)^T,(1,0,1)^T,(1,1,0)^T }(0,0,0)T,(1,0,0)T,(1,0,1)T,(1,1,0)T\n类别2：(0,0,1)T,(0,1,0)T,(0,1,1)T,(1,1,1)T{(0,0,1)^T,(0,1,0)^T,(0,1,1)^T,(1,1,1)^T }(0,0,1)T,(0,1,0)T,(0,1,1)T,(1,1,1)T\n\n\n用PCA降维，分别将特征降至1维和2维，并给出降维后每个样本的位置。\n\n计算两类样本均值：\n\nμ=(12,12,12)\\mu = (\\frac{1}{2}, \\frac{1}{2}, \\frac{1}{2})μ=(21​,21​,21​)\n\n\n将每个样本的特征减去样本均值μ\\muμ：\n\n类别1：{(−12,−12,−12)T,(12,−12,−12)T,(12,−12,12)T,(12,12,−12)T}\\{(-\\frac{1}{2},-\\frac{1}{2},-\\frac{1}{2})^T,(\\frac{1}{2},-\\frac{1}{2},-\\frac{1}{2})^T,(\\frac{1}{2},-\\frac{1}{2},\\frac{1}{2})^T,(\\frac{1}{2},\\frac{1}{2},-\\frac{1}{2})^T \\}{(−21​,−21​,−21​)T,(21​,−21​,−21​)T,(21​,−21​,21​)T,(21​,21​,−21​)T}\n类别2：{(−12,−12,12)T,(−12,12,−12)T,(−12,12,12)T,(12,12,12)T}\\{(-\\frac{1}{2},-\\frac{1}{2},\\frac{1}{2})^T,(-\\frac{1}{2},\\frac{1}{2},-\\frac{1}{2})^T,(-\\frac{1}{2},\\frac{1}{2},\\frac{1}{2})^T,(\\frac{1}{2},\\frac{1}{2},\\frac{1}{2})^T \\}{(−21​,−21​,21​)T,(−21​,21​,−21​)T,(−21​,21​,21​)T,(21​,21​,21​)T}\n\n\n计算协方差矩阵\n\nS=XXT=[140001400014]    S=XX^T=\n    \\begin{bmatrix}\n        \\frac{1}{4} &amp; 0 &amp; 0 \\\\\n        0 &amp; \\frac{1}{4} &amp; 0 \\\\\n        0 &amp; 0 &amp; \\frac{1}{4} \\\\\n    \\end{bmatrix}\nS=XXT=⎣⎡​41​00​041​0​0041​​⎦⎤​\n\n计算协方差矩阵的特征值和特征向量：\n\n特征值：α1=14,α2=14,α3=14\\alpha_1 = \\frac{1}{4}, \\alpha_2 = \\frac{1}{4},\\alpha_3 = \\frac{1}{4}α1​=41​,α2​=41​,α3​=41​\n特征向量：ω1=[1,0,0]T,ω2=[0,1,0]T,ω3=[0,0,1]T\\omega_1 = [1, 0, 0]^T, \\omega_2 = [0, 1, 0]^T, \\omega_3 = [0, 0, 1]^Tω1​=[1,0,0]T,ω2​=[0,1,0]T,ω3​=[0,0,1]T\n\n\n将特征降至1维：\n\n选择最大特征值所对应的特征向量ω1=[1,0,0]T\\omega_1 = [1, 0, 0]^Tω1​=[1,0,0]T\n类别1：{−12,12,12,12}\\{-\\frac{1}{2}, \\frac{1}{2}, \\frac{1}{2} ,\\frac{1}{2} \\}{−21​,21​,21​,21​}\n类别2：{−12,−12,−12,12}\\{-\\frac{1}{2}, -\\frac{1}{2}, -\\frac{1}{2} ,\\frac{1}{2} \\}{−21​,−21​,−21​,21​}\n\n\n将特征降至2维：\n\n选择前2大个特征值所对应的特征向量ω1=[1,0,0]T,ω2=[0,1,0]T\\omega_1 = [1, 0, 0]^T, \\omega_2 = [0, 1, 0]^Tω1​=[1,0,0]T,ω2​=[0,1,0]T\n类别1：{(−12,−12),(12,−12),(12,−12),(12,12)}\\{ (-\\frac{1}{2}, -\\frac{1}{2}), (\\frac{1}{2}, -\\frac{1}{2}), (\\frac{1}{2}, -\\frac{1}{2}), (\\frac{1}{2}, \\frac{1}{2}) \\}{(−21​,−21​),(21​,−21​),(21​,−21​),(21​,21​)}\n类别2：{(−12,−12),(−12,12),(−12,12),(12,12)}\\{ (-\\frac{1}{2}, -\\frac{1}{2}), (-\\frac{1}{2}, \\frac{1}{2}), (-\\frac{1}{2}, \\frac{1}{2}), (\\frac{1}{2}, \\frac{1}{2}) \\}{(−21​,−21​),(−21​,21​),(−21​,21​),(21​,21​)}\n\n\n\n\n\n给出每个样本点降至2维后，再重构回3维空间的坐标。\n\n降至2维所使用的特征向量组成的矩阵为W=[100010]W = \\begin{bmatrix}\n    1 &amp; 0 &amp; 0\\\\\n    0 &amp; 1 &amp; 0\n\\end{bmatrix}\nW=[10​01​00​]\n\n则样本点iii重构回三维空间的坐标为i′=iTW+μi&#x27; = i^T W + \\mui′=iTW+μ\n类别1：{(0,0,12),(1,0,12),(1,0,12),(1,1,12)}\\{ (0, 0, \\frac{1}{2}), (1, 0, \\frac{1}{2}), (1, 0, \\frac{1}{2}), (1, 1, \\frac{1}{2}) \\}{(0,0,21​),(1,0,21​),(1,0,21​),(1,1,21​)}\n类别2：{(0,0,12),(0,1,12),(0,1,12),(1,1,12)}\\{ (0, 0, \\frac{1}{2}), (0, 1, \\frac{1}{2}), (0, 1, \\frac{1}{2}), (1, 1, \\frac{1}{2}) \\}{(0,0,21​),(0,1,21​),(0,1,21​),(1,1,21​)}\n\n\n\n\n假设我们采用带如下正则的线性回归，目标函数为：\nJ(w,λ)=12N∑i=1N(wTxi+b−yi)2+λ‖w‖22J(w,λ)=\\frac{1}{2N} ∑_{i=1}^N (w^T x_i+b-y_i )^2 +λ‖w‖_2^2J(w,λ)=2N1​∑i=1N​(wTxi​+b−yi​)2+λ‖w‖22​\n当λλλ从000增加到∞∞∞时，描述以下各项如何变化：\n\n模型的过拟合行为；\n\n目标函数中的正则项为L2正则，当λ\\lambdaλ从000增加到∞∞∞时，www中的分量总和会受到限制，在λ=0\\lambda = 0λ=0时，目标函数中没有对www的约束，容易产生过拟合的结果。当λ\\lambdaλ逐渐增大时，将会对www有一定的约束作用，减轻过拟合行为的发生。当λ\\lambdaλ趋近于∞∞∞时，www将会被限制为无限趋向000，此时模型将无法正常工作。\n\n\nw的值和模的大小；\n\n当λ=0\\lambda = 0λ=0时，www的值和模的大小是不受约束的，随着λ\\lambdaλ的增加，由于www的值和模的大小越大，目标函数的值也会越大，所以www的模也会随着参数更新而减小。当λ→∞\\lambda \\rightarrow \\inftyλ→∞时，由于www的模无限趋近000，www的值也会越来越小。\n\n\n模型的偏差和方差。（注意：这里的偏差不是指b）\n\n当λ=0\\lambda = 0λ=0时，\n\n\n\n\n假设我们想要训练线性模型f(x)=wx+bf(x)=wx+bf(x)=wx+b。我们将使用梯度下降来最小化N个训练样本{xi,yi}i=1N\\{x_i,y_i \\}_{i=1}^N{xi​,yi​}i=1N​上的误差平方和：\nJ(w,b)=12∑i=1N(wxi+b−yi)2J(w,b)=\\frac{1}{2} ∑_{i=1}^N(wx_i+b-y_i )^2 \nJ(w,b)=21​i=1∑N​(wxi​+b−yi​)2\n计算目标函数损失J(w,b)J(w,b)J(w,b)相对于www和bbb的偏导数。\n\n假设我们采用不同的验证集划分方式： 2折交叉验证、10折交叉验证、留一交叉验证、单次70%/30%的训练集/验证集划分。\n\n不同的验证集划分方式会对模型性能产生什么影响？（如训练误差、泛化误差）\n哪种方式得到的验证误差会提供 在“未见过的测试集”上误差的最佳近似？\n原始数据集有多大有影响吗？对于一个非常大或非常小的数据集，你会得到不同的结论吗？\n就计算而言，哪种方式最快？\n\n","slug":"PCA&LR作业","date":"2023-11-18T19:45:25.000Z","categories_index":"基础,机器学习,作业","tags_index":"作业,模式识别,机器学习","author_index":"ClaRn"},{"id":"31d8cdd5baa8bcd02cb907b9fac066d4","title":"特征工程","content":" 数据预处理\n数据预处理包括噪声的清晰和数据变换。\n特征类型包括：\n\n连续数值型特征\n\n多项式扩展\nlog变换（log(x+1)log(x+1)log(x+1)）\n区间量化\n二值化\n缩放\n规范化\n\n\n离散特征/类别型特征\n\n0/1编码\n标签编码\n独热码\n计数编码\n\n\n地点型特征\n时间型特征\n\n 特征构造\n特征构造是从原始数据中构造新的特征的过程，通常需要手工创建。\n 特征抽取\n特征抽取的目的是从原始数据抽取新特征，使算法自动执行。\n 数据降维\n数据降维/嵌入是指将原始的高维数据映射到低维空间。高维度复杂数据的内在维度可能比较小，或者和任务相关的维度较小，所以荣誉的数据通常是可以被压缩的。\n 降维方法\n降低维度的方法通常有两种：\n\n特征选择：选取已有特征的一个子集\n特征抽取：组合现有的特征来构建新特征\n\n PCA降维\n 主成分分析\n主成分分析是将高位空间线性投影到一个低维空间，同时我们希望这个低维空间能够表征高维度空间的绝大部分信息，即信息损失最小。\n 线性降维的一般形式\n数据点： X=(x1,x2,...,xN)∈RD×NX=(x_1, x_2, ..., x_N) \\in R^{D \\times N}X=(x1​,x2​,...,xN​)∈RD×N\n新空间的数据点: Z=(z1,z2,...,zN)∈RD′×NZ=(z_1, z_2, ..., z_N) \\in R^{D&#x27; \\times N}Z=(z1​,z2​,...,zN​)∈RD′×N\n选择D′D&#x27;D′个方向向量: W=(w1,w2,...,wD′)W=(w_1, w_2, ..., w_{D&#x27;})W=(w1​,w2​,...,wD′​)\n将XXX投影到新空间: Z=WTXZ=W^TXZ=WTX\n PCA的求解\n求解过程：\n输入：X=(x1,x2,...,xN),低维空间的维度D′X=(x_1, x_2, ..., x_N), 低维空间的维度D&#x27;X=(x1​,x2​,...,xN​),低维空间的维度D′\n算法过程：\n\nxi=xi1N∑j=1Nxjx_i = x_i \\frac{1}{N} \\sum^{N}_{j=1} x_jxi​=xi​N1​∑j=1N​xj​ (将特征的数据值减去均值，得到偏移xix_ixi​)\n计算S=XXTS=XX^TS=XXT (协方差矩阵)\n对S做矩阵分解 (求特征值和特征向量)\nD′D&#x27;D′最大特征值对应的特征向量: w1,w2,...,wD′w_1, w_2, ..., w_{D&#x27;}w1​,w2​,...,wD′​\n\n输出：W=(w1,w2,...,wD′)W=(w_1, w_2, ..., w_{D&#x27;})W=(w1​,w2​,...,wD′​)\n 奇异值分解法(SVD)\n当数据原始维度过大时，求解协方差矩阵将变得困难。此时通过奇异值分解法可以快速地求出最大的D个特征值对应的特征向量。\n此时引入另一种PCA的求解方式。\n PCA的求解\n求解过程：\n输入：X=(x1,x2,...,xN),低维空间的维度D′X=(x_1, x_2, ..., x_N), 低维空间的维度D&#x27;X=(x1​,x2​,...,xN​),低维空间的维度D′\n算法过程：\n\nxi=xi1N∑j=1Nxjx_i = x_i \\frac{1}{N} \\sum^{N}_{j=1} x_jxi​=xi​N1​∑j=1N​xj​ (将特征的数据值减去均值，得到偏移xix_ixi​)\n奇异值分解 X=UD×DΣD×NVN×NTX=U_{D \\times D} \\Sigma_{D \\times N} V^T_{N \\times N}X=UD×D​ΣD×N​VN×NT​\nD′D&#x27;D′个奇异值对应的左奇异向量：μ1,μ2,...,μD′\\mu_1, \\mu_2, ..., \\mu_{D&#x27;}μ1​,μ2​,...,μD′​\n\n输出：U=(μ1,μ2,...,μD′)U=(\\mu_1, \\mu_2, ..., \\mu_{D&#x27;})U=(μ1​,μ2​,...,μD′​)\n 特征选择\n特征选择的方式如下：\n\n手工特征选择\n随机特征选择：随机采样，从DDD维中随机选择D′D&#x27;D′维\n过滤式选择：设计一个相关统计量来度量特征的重要性\n\n相关系数（回归问题）\n互信息（单个特征和分类标签的互信息）\nK2\\Kappa^2K2统计量（单个特征和分类标签之间的独立性）\n信息增益（当特征出现或者不出现时，预测的熵减少）\n方差、information value、…\n\n\n包裹式特征选择：用最终要用的学习器的性能评价特征的重要性\n嵌入式特征选择：与模型训练一起完成，比如基于L1正则（比如Lasso回归或Logistic回归，SVM）的特征选择和基于树（比如决策树）的特征选择\n\n Addition\n 协方差矩阵的计算\n 协方差\n协方差用于衡量随机变量之间的相关程度。\n设X、YX、YX、Y是定义在Ω\\OmegaΩ上的两个实数随机变量，则有：\n协方差cov(X,Y)=E[(X−μ)(Y−v)]=1n−1∑i=1n(xi−μ)(yi−v)=E(XY)−μv，E(X)=μ,E(Y)=v协方差 cov(X,Y)=E[(X-\\mu)(Y-v)]= \\frac{1}{n-1} \\sum^{n}_{i=1}(x_i - \\mu)(y_i - v)=E(XY) - \\mu v ，\\\\\nE(X)=\\mu, E(Y)=v\n协方差cov(X,Y)=E[(X−μ)(Y−v)]=n−11​i=1∑n​(xi​−μ)(yi​−v)=E(XY)−μv，E(X)=μ,E(Y)=v\n在实际应用中，样本数量通常会非常巨大，所以实际计算时会用1n\\frac{1}{n}n1​来近似1n−1\\frac{1}{n-1}n−11​，此时原式变为：$ cov(X,Y)= \\frac{1}{n} \\sum^{n}_{i=1}(x_i - \\mu)(y_i - v)$\n 协方差矩阵\n协方差矩阵是一组随机变量之间任意两个随机变量之间的协方差所组成的方阵。\n若有X=(x1,x2,…,xm),Y=(y1,y2,…,yn)X=(x_1, x_2, \\dots, x_m), Y=(y_1, y_2, \\dots, y_n)X=(x1​,x2​,…,xm​),Y=(y1​,y2​,…,yn​)\n则XXX和YYY之间的协方差矩阵为:\nS=[Cov(x1,y1)Cov(x1,y2) ⁣⋯Cov(x1,yn)Cov(x2,y1)Cov(x2,y2) ⁣⋯Cov(x2,yn)⋮⋮⋱⋮Cov(xm,y1)Cov(xm,y2) ⁣⋯Cov(xm,yn)]S=\n\\begin{bmatrix}\nCov(x_1, y_1) &amp; Cov(x_1, y_2) &amp; \\dotsi &amp; Cov(x_1, y_n)\\\\ \nCov(x_2, y_1) &amp; Cov(x_2, y_2) &amp; \\dotsi &amp; Cov(x_2, y_n)\\\\ \n\\vdots &amp; \\vdots &amp; \\ddots &amp; \\vdots \\\\ \nCov(x_m, y_1) &amp; Cov(x_m, y_2) &amp; \\dotsi &amp; Cov(x_m, y_n)\\\\ \n\\end{bmatrix}\nS=⎣⎢⎢⎢⎡​Cov(x1​,y1​)Cov(x2​,y1​)⋮Cov(xm​,y1​)​Cov(x1​,y2​)Cov(x2​,y2​)⋮Cov(xm​,y2​)​⋯⋯⋱⋯​Cov(x1​,yn​)Cov(x2​,yn​)⋮Cov(xm​,yn​)​⎦⎥⎥⎥⎤​\n另一种更快速的计算方式是，将样本I=(x,y, ⁣⋯ ,z)TI=(x, y, \\dotsi, z)^TI=(x,y,⋯,z)T与其转置相乘并记为s=IITs=II^Ts=IIT(sss是一个矩阵)，并将sss与所有样本的sis_isi​累加后乘以1n−1\\frac{1}{n-1}n−11​，记为S=XXTS=XX^TS=XXT。\n","slug":"特征工程","date":"2023-11-18T01:17:02.000Z","categories_index":"基础,机器学习","tags_index":"模式识别,机器学习","author_index":"ClaRn"},{"id":"2de89c6bdcc1a7d65b885893c5d238e0","title":"LZ77编码和类LZW压缩算法","content":" LZ77编码\n","slug":"LZ77编码和类LZW压缩算法","date":"2023-11-17T08:26:11.000Z","categories_index":"","tags_index":"压缩算法","author_index":"ClaRn"},{"id":"80dc6c398842f9a2e7cabf21fa1c2234","title":"马尔可夫链和隐马尔可夫模型","content":" 马尔可夫性质\n马尔可夫链是由一个条件分布来表示的P(Xn+1∣XN)P(X_{n+1}|X_N)P(Xn+1​∣XN​) ，这被称为随机过程中的转移概率。马尔可夫链即符合马尔可夫性质的随机变量序列，最简化的马尔可夫链即只有一个X1的状态的转移链。在这些随机变量中，它们的当前状态，将来状态和过去状态是相互独立的。\n 马尔可夫链\n马尔可夫链是基于状态而言的，其性质有些类似有限状态自动机，但是与DFA之类的n有限状态自动机不同的是，在不同状态的转移之间并非是一个特定条件在进行约束，而是一个概率。状态机上所有的概率可以构成一个分布，名叫转移概率分布。\n\n 隐马尔可夫模型\n隐马尔可夫模型引入了“生成概率”的概念，每一个状态都有自己的生成概率分布，可以按照不同的概率产生一组可以被观测到的符号。在隐马尔可夫模型中，状态路径是无法直接看到的。\n在简单的马尔可夫模型（如马尔可夫链），所述状态是直接可见的观察者，因此状态转移概率是唯一的参数。在隐马尔可夫模型中，状态是不直接可见的，但输出依赖于该状态下，是可见的。每个状态通过可能的输出记号有了可能的概率分布。因此，通过一个HMM产生标记序列提供了有关状态的一些序列的信息。注意，“隐藏”指的是，该模型经其传递的状态序列，而不是模型的参数；即使这些参数是精确已知的，我们仍把该模型称为一个“隐藏”的马尔可夫模型。隐马尔可夫模型以它在时间上的模式识别所知，如语音，手写，手势识别，词类的标记，乐谱，局部放电和生物信息学应用。\nhttps://www.coursera.org/learn/sheng-wu-xin-xi-xue/lecture/uekgI/yin-ma-er-ke-fu-mo-xing\n","slug":"马尔可夫链和n隐马尔可夫模型","date":"2023-04-26T04:16:47.000Z","categories_index":"生物信息学,人工智能,基础","tags_index":"生物信息学,算法,人工智能","author_index":"ClaRn"},{"id":"250cf64c9de21149319ed296b52cadd2","title":"Smith-Waterman算法和Needleman-Wunsch算法","content":" 简介\nSmith-Waterman算法和Needleman-Wunsch算法都是生物信息学领域非常经典的算法，主要用于基因或者蛋白质序列的比对。\nNeeleman-Wunsch算法是基于生物信息学知识来匹配蛋白序列或者基因序列的算法，是将动态规划算法应用于生物序列的比较的早期实践之一。\nSmith-Waterman算法是Needleman-Wunsch算法的延伸，相比于Needleman算法主要聚焦于一整条序列的全局比对，Smith算法更多的用于找寻两个序列中具有高度相似度的片段。\n Needleman-Wunsch算法原理\nNW算法主要用于对比两个序列并得到这两个序列的全部序列匹配。\n假设两个待比对序列为：AAG 和 AGC ，且不同的碱基对应的分值如下表所示，空值的罚分为线性距离，值为-5 。\n\n\n\n\nA\nC\nG\nT\n\n\n\n\nA\n2\n-7\n-5\n-7\n\n\nC\n-7\n2\n-7\n-5\n\n\nG\n-5\n-7\n2\n-7\n\n\nT\n-7\n-5\n-7\n2\n\n\n\n即DP矩阵中计算分数的公式为：\nbeginequationF(0,0)=0，endequation\\\\begin{equation}\nF(0,0)=0 ，\n\\\\end{equation}\nbeginequationF(0,0)=0，endequation\n\\\\begin{equation}\nF(i,j)= max \n\\\\left \\\\{\n    \\begin{array}{lr}\n    F(i-1,j-1)+s(x_i, y_j), \\\\\\\\\n    F(i-1,j)+d, \\\\\\\\\n    F(i,j-1)+d, \\\\\\\\\n    \\end{array}\n\\\\right.\n\\\\end{equation}\n\n计算所得结果如下图：\n然后回溯得到对比结果： \n关于回溯：在北大的生物信息学导论课程中并没有提及回溯的具体方式，不过可以参考下面这篇博客：https://blog.csdn.net/yohjob/article/details/89144032\n Smith-Waterman算法\nSmith-Waterman算法与Needleman-Wunsch算法差别并不大，主要存在的差异是DP矩阵的计算公式，Smith-Waterman算法给公式的值规定了最小值从而突出局部特征。公式如下所示：\nbeginequationF(0,0)=0，endequation\\\\begin{equation}\nF(0,0)=0 ，\n\\\\end{equation}\nbeginequationF(0,0)=0，endequation\n\\\\begin{equation}\nF(i,j)= max  \\\\left\\\\{\n    \\\\begin{array}{lr}\n    F(i-1,j-1)+s(x_i, y_j), \\\\\\\\\n    F(i-1,j)+d, \\\\\\\\\n    F(i,j-1)+d, \\\\\\\\\n    0 , \\\\\\\\\n    \\\\end{array}\n\\\\right.\n\\\\end{equation}\n\n","slug":"Smith-Waterman算法和Needleman-Wunsch算法","date":"2023-04-25T21:41:09.000Z","categories_index":"生物信息学,基础","tags_index":"生物信息学,算法,动态规划","author_index":"ClaRn"},{"id":"ffa3c8772fdf3309434ff546ef79c450","title":"图像特征","content":" SIFT、HOG特征\n SIFT特征\nScale Invariant Feature Transform ，又称尺度不变特征变换。SIFT特征对旋转、尺度缩放、亮度变化等保持不变性，是一种非常稳定的局部特征。\n HOG特征\nHistogram of Oriented Gradient ，又称方向梯度直方图特征，是一种在计算机视觉和图像处理中用来进行物体检测的特征描述子。HOG特征通过计算和统计图像局部区域的梯度方向直方图来构成特征。\n SIFT、HOG特征的计算过程\n SIFT特征的计算过程\n\n生成高斯差分金字塔(DOG金字塔)，尺度空间构建\n空间极值点检测(关键点的初步查探)\n稳定关键点的精确定位\n稳定关键点方向信息分配\n关键点描述\n特征点匹配\n\n HOG特征的计算过程\n\n灰度图Gamma校正(不必须)\n梯度计算\n8x8Cell梯度直方图划分\n16x16Block归一化，统计Cell梯度直方图\n计算HOG特征描述\n\n","slug":"图像特征","date":"2023-04-02T13:09:32.000Z","categories_index":"图形图像","tags_index":"图像处理,OpenCV","author_index":"ClaRn"},{"id":"e14beeee054107e61818821b5c2d1c74","title":"进程同步经典问题","content":" 信号量\n信号量机制是一种用于解决互斥和同步问题的机制，包括两个原语wait(S)和signal(S)，也可以记为P操作和V操作。\n 管程\n使用一个数据结构S来描述共享资源数，并包含对该数据结构的一组操作。\n 生产者-消费者问题\nsemaphore mutex = 1;\nsemaphore empty = n;\nsemaphore full = 0;\nproducer () &#123;\n    while(1) &#123;\n        // ...produce data\n        P(empty);\n        P(mutex);\n        // ...add data to buffer\n        V(mutex);\n        V(full);\n    &#125;\n&#125;\n\nconsumer() &#123;\n    while(1) &#123;\n        P(full);\n        P(mutex);\n        // ...get data from buffer\n        V(mutex);\n        V(empty);\n        // ...consume data\n    &#125;\n&#125;\n\n 读者-写者问题\nint count = 0; // 读者数量\nsemaphore mutex=1;\nsemaphore rw=1;\nsemaphore w=1; \n// w是用来保证写优先的\n// 如果没有将会导师读优先，写进程会存在“饿死”现象 \n\nwriter() &#123;\n    while(1) &#123;\n        P(w);\n        P(rw);\n        // ...writing\n        V(rw);\n        V(w);\n    &#125;\n&#125;\n\nreader() &#123;\n    while(1) &#123;\n        P(w);\n        P(mutex);\n        if (count == 0)\n            P(rw);\n        count ++;\n        V(mutex);\n        V(w);\n        // ...reading\n        P(mutex);\n        count --;\n        if (count == 0)\n            V(rw);\n        V(mutex);\n    &#125;\n&#125;\n\n","slug":"进程同步经典问题","date":"2023-03-25T13:53:16.000Z","categories_index":"","tags_index":"操作系统,Review","author_index":"ClaRn"},{"id":"cfd4ec52764f9243a80a5ef9b48d3349","title":"软件工程中的开发模型","content":" 软件开发生命周期（software development lifecycle (SDLC) ）\n软件的产生直到报废的生命周期，包括：问题定义、可行性分析、需求分析、总体设计、详细设计、编码、测试、运行维护等阶段。\n 软件开发模型\n 1、瀑布模型\n瀑布模型也称为生命周期发，是结构化方法中最常用的开发模型，可以分为软件计划、需求分析、软件设计、程序编码、软件测试和运行维护几个阶段。适合需求明确或变更少的项目\n 2、增量模型\n增量模型融合了瀑布模型的基本成分和原型实现的迭代特征，是第三种原型化开发方法，但它不是“抛弃式”的，也不是“渐进式”的。**增量模型把软件产品划分为一系列的增量构件，第一个增量往往是核心的产品，即第一个增量实现了基本的需求。**客户对每一个增量的使用和评估都作为下一个增量发布的新特征和功能，这个过程在每一个增量发布后不断重复，直到产生了最终的完善产品。增量模型与原型实现模型和其他演化方法一样，本质上是迭代的，但与原型实现不一样的是其强调每一个增量均发布一个可操作产品。增量模型将功能细化、分别开发的方法适应于需求经常改变的软件开发过程\n 3、螺旋模型\n螺旋模型以原型为基础，每一次螺旋都要经过制订计划、风险分析、实施工程及客户评价等活动，并开发原型的一个新版本，经过若干次螺旋上升的过程得到最终的系统。\n 4、喷泉模型\n喷泉模型是一种以用户需求为动力，以对象为驱动地模型，主要用于描述面向对象的软件开发过程，该模型认为软件开发过程自下而上的，各阶段是相互迭代和无间隙的。无间隙是指在开发活动中，分析、设计和编码之间不存在明显的边界。\n 5、V模型\nV 形模型也称为 V 模型或验证与验证模型，是瀑布方法的扩展。使用 V 模型时，进度并不会直线移动，而是在实施和开发后逐渐上升。\n对于 V 型 SDLC 项目，早期测试介入是与瀑布模型相比的主要区别。每个开发阶段都有一个并行测试阶段，这有助于在继续下一步之前验证和验证每个步骤。\n 快速原型模型\n快速原型是利用原型辅助软件开发的一种新思想。\n经过简单快速分析，快速建造一个可以运行的软件原型，以便理解和澄清问题，使开发人员与用户达成共识，最终在确定的用户需求基础上开发客户满意的软件产品。\n原型可以为三类：\n\n探索型原型：主要用于需求分析阶段，目的是要弄清用户的需求，并探索各种方案的可行性。它主要针对开发目标模糊，用户与开发人员对项目都缺乏经验的情况，通过对原型的开发来明确用户的需求\n实验型原型：主要用于设计阶段，考核实现方案是否合适，能否实现。对于大型系统，若对设计方案心中没有把握时，可通过这种原型来证实设计方案的正确性\n演化型原型：主要用于及早向用户提交一个原型系统，该原型系统或者包含系统的框架，或者包含系统的主要功能，在得到用户的认可后，将原型系统不断扩充演变为最终的软件系统\n\n 敏捷模型\n敏捷（Agile） SDLC 模型是迭代和增量方法的组合，致力于通过早期交付工作软件来适应灵活的需求并满足用户和客户的需求。敏捷项目中的需求和解决方案可能会在开发过程中发展。\n通过敏捷开发，该产品被分为小的增量构建，并以迭代方式交付。将所有任务划分为较小的时间范围，以便为每个版本准备工作功能。最终产品版本包含所有必需的功能。敏捷仍然是技术行业中使用最广泛的SDLC。\n常见的敏捷开发方法：\n\n极限编程(XP)\n自适应软件开发\n水晶方法\n特性驱动开发\nscrum\n\n","slug":"软件工程","date":"2023-03-23T16:41:13.000Z","categories_index":"基础","tags_index":"Review,软件工程","author_index":"ClaRn"},{"id":"fba5abef53d9d5ea6aea61fb0369866c","title":"编译原理考点","content":" 编译原理作业：\n\n正则表达式生成NFA/DFA\nLL1 词法分析\nLR 词法分析\n\n 编译程序的功能组织结构图\n\n‘词法分析器→语法分析器→语义分析器→中间代码生成器→代码优化器→目标代码’\n语法分析树和抽象语法树不是一个玩意儿(问题不大)\n词法分析\n\n调度场算法\n\n\n使用栈针对不同运算符的优先级进行处理\n\n\n\n\nChomsky四型文法\n\n0型文法\n\n无限制文法/短语结构文法\n\n设G=（VN，VT，P，S），如果它的每个产生式α→β是这样一种结构：α∈(VN∪VT)*且至少含有一个非终结符，而 β∈(VN∪VT)*，则G是一个0型文法。0型文法也称短语文法。一个非常重要的理论结果是：0型文法的能力相当于图灵机(Turing)。或者说，任 何0型文语言都是递归可枚举的，反之，递归可枚举集必定是一个0型语言。0型文法是这几类文法中，限制最少的一个。0型文法是其它类型文法的母集。\n\n\n\n\n1型文法\n\n上下文有关文法\n\n1型文法也叫上下文有关文法，此文法对应于线性有界自动机。它是在0型文法的基础上每一个α→β,都有|β|&gt;=|α|。这里的|β|表示的是β的长度。\n注意：虽然要求|β|&gt;=|α|，但有一特例：α→ε也满足1型文法。\n如有A-&gt;Ba则|β|=2,|α|=1符合1型文法要求。反之,如aA-&gt;a，则不符合1型文法。\n\n\n\n\n2型文法\n\n上下文无关文法\n\n在1型文法的基础上，每一个α→β都有α是非终结符。\n如A-&gt;Ba,符合2型文法要求。\n如Ab-&gt;Bab虽然符合1型文法要求,但不符合2型文法要求，因为其α=Ab，而Ab不是一个非终结符。\n\n\n\n\n3型文法\n\n正则文法\n\n对应有限状态自动机。\n在2型文法的基础上满足:A→α|αB（右线性）或A→α|Bα（左线性）。\n如有：A-&gt;a,A-&gt;aB,B-&gt;a,B-&gt;cB，则符合3型文法的要求。\n但如果推导 为:A-&gt;ab,A-&gt;aB,B-&gt;a,B-&gt;cB或推导 为:A-&gt;a,A-&gt;Ba,B-&gt;a,B-&gt;cB则不符合3型方法的要求了。\n具体的说，例子 A-&gt;ab,A-&gt;aB,B-&gt;a,B-&gt;cB中的A-&gt;ab不符合3型文法的定义,如果把后面的ab,改成“一个非终结符＋一个终结符”的形式（即为aB）就对了。例子A-&gt;a,A-&gt;Ba,B-&gt;a,B-&gt;cB中如果把B-&gt;cB改为 B-&gt;Bc的形式就对了,因为A→α|αB（右线性）和A→α|Bα（左线性）两套规则不能同时出现在一个语法中,只能完全满足其中的一个,才能算 3型文法。\n\n\n\n\n\n\n正则表达式\n\n| ：或\n* ：匹配0或无限个\n· ：连接\n优先级：*、·、|\n例如：\n\n令 ∑ = {a, b}，则\nL(a|b) = L(a)∪L(b) ={a}∪{b} = {a, b}\nL((a|b)(a|b)) = L(a|b) L(a|b)={a, b}{a, b}= { aa, ab, ba, bb }\nL(a*) = (L(a))*= {a}*= { ε, a, aa, aaa, . . . }\nL((a|b)*) = (L(a|b))* = {a, b}*= { ε, a, b, aa, ab, ba, bb, aaa, . . .}\nL(a|a*b) = { a, b, ab, aab, aaab, . . .}\n\n\n\n\n\n 有穷自动机(FA)\n\n具有有穷个状态数\n\n最长子串匹配原则：输入串的多个前缀与一个或多个模式匹配时，总是选择最长的前缀进行匹配。\n\n\nNFA(非确定的FA)\n\nNFA是不唯一的，但其对应的DFA是唯一的\nε对应的NFA \nr = r1r2对应的NFA \nr = r1|r2 对应的NFA \nr = (r1)*对应的NFA \n\n\nDFA(确定的FA)\n\nDFA每个状态都是一个由NFA状态构成的集合，也就是NFA状态集合的一个子集。例如NFA中状态A可以经由a边到达状态A、B，则DFA中状态A可经由a边到达状态 {A,B} ，这里 {A,B}集合是一个状态。\nNFA→DFA：初始状态ε闭包T，求出后遍历终结符，对每个move(T,a)求ε闭包，求出的闭包为新的状态U，a即当前终结符，意思是T通过a到达U，将U换为T继续执行，直到没有新的U出现。\n如图所示 r=aa*bb*cc* 的无ε边的NFA到DFA的转换：\n\n无ε边的NFA到DFA的转换 \nNFA状态转换表 \n转换后的DFA \n\n\n如图所示为带ε边的NFA到DFA的转换 \n\n\nDFA最小化：\n\n状态合并：将所有状态划分为终结状态和非终结状态，并将终结状态和非终结状态进行合并，合并规则为:二者同为终结状态或非终结状态，且通过指定输入符号可以到达的状态相同。\nε-闭包(ε-closure)\n\nε-closure(s)：能够从NFA状态s开始只通过ε转换到达的NFA状态集合\nε-closure(T)：能够从T中的某个NFA状态s开始，只通过ε转换到达的NFA状态集合\nmove(T, a)：能够从T中的某个状态s出发通过标号为a的转换到达的NFA状态的集合\n\n\n\n\n\n 上下文无关文法\n\n二义性文法判断\n\n能通过不同分析顺序生成两个分析树的文法称为二义性文法\n消除二义性：不修改文法，指定正确的分析树；或修改文法(指定优先级、结合性)\n\n\n短语、简单短句和句柄判断\n\n短语：每颗子树的叶子\n简单短语：每颗简单子树(仅有叶子结点没有根节点)的叶子\n句柄：最左简单子树的叶子(最左边的那个简单子树)\n\n\n\n 自顶向下语法分析 （最左推导：既总是选择每个句型的最左非终结符进行替换）\n\n判定：产生式A → α | β 满足下面的条件：\n\n如果α 和β均不能推导出ε ，则FIRST (α)∩FIRST (β) =Φ(空集)\nα 和β至多有一个能推导出ε\n如果 β →* ε，则FIRST (α)∩FOLLOW(A) =Φ; 如果 α →* ε，则FIRST (β)∩FOLLOW(A) =Φ;\n\n\n消除左递归：(A → A α1 | A α2 | β1 | β2)→(A → β1 A′ | β2 A′;A′ → α1 A′ | α2 A′ | ε)\n间接左递归：将间接左递归文法的定义代入得到直接左递归，再消除\n提取左因子：(S → aAd | aBe)→(S → a S’;S’ → Ad | Be)\nFirst、Follow\n\nFirst：可以从X推导出的所有串首终结符构成的集合;可以存在ε\nFollow：可能在某个句型中紧跟在A后边的终结符a的集合；如果A是某个句型的的最右符号，则将结束符“”添加到FOLLOW(A)中；如果是起始的第一句，则添加“”添加到FOLLOW(A)中；如果是起始的第一句，则添加“”添加到FOLLOW(A)中；如果是起始的第一句，则添加“”\n\n\nLL(1)分析表\n\nSelect：将每条文法拆分为拓广文法，若该条文法A的First为ε，则Select(A)=Follow(A)，否则Select(A)=First(A)\n通过Select集合可以看到不同拓广文法产生式对应的终结符，使用其构建终结符与非终结符相对应的文法分析表即可。(考试记得写编号)\n\n\nLL(1)分析过程\n\n分析栈：第一次为E，之后根据输入队列进行获取输入符号，通过输入符号和栈顶非终结符查找分析表进行文法推导，若为终结符则进行出栈匹配操作。\n\n\n\n 自底向上语法分析 （归约）\n\n拓广文法\n\n就是全写出来，然后在最前面加个S’→S，有手就行\n\n\nLR(0)项目：\n\n加上小圆点的状态示意句柄\n\n\nLR(0)识别活前缀状态机\n\n从第一条增广文法开始往下，列出所有可以推导出的项目，然后写出每个项目移进之后的状态，直到小圆点到了最后再也推导不出来新的状态，就是规约状态。\n\n\nLR方法判断过程\nLR(0)分析表、SLR(1)分析表\n\nLR(0)分析表：\n\n分为两部分：Action和GOTO\n\nACTION：移进项目\nGOTO：跳转到文法\n\n\n\n\nSLR(1)分析表：\n\n如果下一个输入符号a属于移进项目，则移进；若a属于某个规约项目的Follow，则使用该规约项目进行规约\n\n\n\n\nLR分析过程\nLR(1)识别活前缀状态机\nLALR(1)判断\nLALR(1)识别活前缀状态机\nLR(1)分析表、LALR(1)分析表\n\n如果除了展望符外，两个LR(1)项目集是相同的，则称这两个LR(1)项目集是同心的\nLALR(1)状态机即合并同心项后的LR(1)状态机\n\n\nLR分析过程\n\n 语义分析\n\n依赖图(拓扑排序)语义分析\nS属性文法语义分析\nL属性文法语义分析\n\n 中间代码三地址码的四元式、三元式表示\n\n四元式：(op,arg1,arg2,return)\n三元式：x=(t+r)*y → t1=t+r;t2=t1*r;x=t2;\n\n 基于基本块的DAG的中间代码优化\n\n基本块：程序中一段顺序执行的语句序列\n通过每一条三地址码或四元式构建节点，将相关的节点相连，若节点内容一样，在右边加上名字，节点下方为常量值或运算符。\n\n","slug":"编译原理考点","date":"2023-03-15T12:38:09.000Z","categories_index":"基础","tags_index":"Review,编译原理","author_index":"ClaRn"},{"id":"d655af595b90ac0e0949f931f50e7fe8","title":"进程管理","content":" 进程\n 进程的概念和特征\n 进程的概念\n从不同的角度看，进程可以有不同的定义，比较典型的是：\n\n进程是程序的一次执行过程\n进程是一个程序及其数据在处理机上顺序执行时所发生的活动\n进程是具有独立功能的程序在一个数据集合上运行的过程，它是系统进行资源分配和调度的一个独立单位。\n\n 进程的特征\n\n动态性：进程是程序的一次执行，它有创建、活动、暂停、终止的过程，具有一定的生命周期。\n并发性：指多个进程实体同时存在于内存中，能在同一段时间内运行。\n独立性：进程实体是一个能独立运行、独立获取资源和独立接受调度的基本单位。\n异步性：由于进程的制约，使得进程的执行具有间断性，即进程按照各自独立、不可预知的速度往前推进。\n结构性：每个进程都配置一个PCB对其进行描述。从结构上看，进程实体是由程序段、数据段和进程控制块构成的。\n\n 进程的状态\n\n运行态：进程正在处理机上运行\n就绪态：进程获得了除了处理机之外的一切资源，一旦得到处理机就可以立即执行。\n阻塞态：进程因为某一事件而暂停，比如等待输入输出或者某外设资源。\n创建态：进程正在被创建，尚未转到就绪态。\n结束态：进程执行完毕正在从系统中消失。\n\n 进程切换过程\n\n保存处理机上下文\n更新PCB信息\n把进程的PCB移入相应的队列，如就绪、阻塞队列\n选择另一个进程执行\n更新内存管理的数据结构\n恢复处理机上下文\n\n 进程控制块\n进程控制块用于描述一个进程，其中主要包括描述信息、进程控制和管理信息、资源分配清单和处理机相关信息等。处理机对进程的调度是基于进程控制块实现的。\n 进程间通信\n 共享存储\n这是最简单的一种进程间通信的方式，它为两个进程提供了一片公共的内存区域，在这个内存区域中的读写对于进程双方都是可见的。低级的共享存储是对数据结构的共享，而高级的共享存储是对存储区的共享。\n 消息传递\n进程间的数据交换以格式化的消息为单位。包括直接通信方式和间接通信方式。\n 直接通信方式\n发送进程直接将消息发送给接收进程，并且将它挂在接收进程的消息缓冲队列上。接收进程从消息缓冲队列中取得消息。\n 间接通信方式\n发送进程把消息发送给某个中间实体，接收进程从中间实体去的消息，一般又称为信箱通信方式。Android的Binder通信机制类似这种。\n 管道通信\n管道通信实际上是消息传递的一种特殊方式。管道实际上是指的用于连接读进程和写进程之间的一个共享文件，又叫做pipe文件。由于管道通信是基于文件的，该文件实际充当了一个缓冲区的作用，所以管道通信只能实现半双工通信。\n从管道中读取数据也是一次性操作，数据在读取之后就会被抛弃。在Linux中一个管道文件被限制在4KB，一旦管道文件已满，IO操作将被阻塞。\n 多线程\n线程是进程内部的一部分，可以理解为更轻量化的进程。在一个进程内可以拥有多个进程，这些进程拥有自己的专有寄存器和栈空间，但是共享进程内的堆空间。\n进程是机器分配资源的基本单位，线程是机器分配CPU的基本单位。协程是线程内部的更轻量化的线程，除了拥有专有寄存器外，协程之间还共享栈空间。\n线程又分为用户级线程和内核级线程；用户级线程依赖应用程序完成线程的调度和管理，内核级线程中的调度和管理都通过操作系统完成。\n 处理机调度\n 调度层次\n\n作业调度：又称高级调度，主要任务是按照一定的规则从外存中处于后备状态的作业中挑选一个或多个作业，给它们分配内存、输入输出设备等必要的资源，并简历相应的进程。\n内存调度：又称中级调度，主要任务是提高内存利用率和吞吐率。中级调度将决定将那些陷入阻塞状态的进程暂时调入外存，并在处理机以及资源空闲之后将进程调入内存。\n进程调度：又称低级调度，主要任务是按照某种方法和策略将进程从就绪队列中取出，并分配处理机。\n\n 进程调度\n通常有两种进程调度方式：\n\n非剥夺调度方式：如果有更重要的任务进入就绪队列，将会持续执行当前任务直到结束或者发生阻塞。\n剥夺调度方式：如果有更重要的任务进入就绪队列，处理机将会被强制剥夺。\n\n不同的调度算法对于不同方面的特性不同。其中的性能指标是评价调度算法是否适合当前场景的重要参数，常用性能指标有如下几种：\n\nCPU利用率：好的调度算法应该尽可能让CPU利用率高。\n系统吞吐量：表示单位时间内CPU完成作业的数量。长作业需要消耗较长的处理机时间，因此会降低系统的吞吐量。而对于短作业，它们所需要的处理机时间较短，因此能提高系统的吞吐量。\n周转时间：周转时间是指从作业提交到作业完成所经历的时间，是作业等待、在就绪队列中排队、在处理机上运行以及进行输入输出所花费时间的总和。\n作业的周转时间可以用如下公式表示：周转时间=作业完成时间−作业提交时间周转时间 = 作业完成时间 - 作业提交时间\n周转时间=作业完成时间−作业提交时间\n平均周转时间是指多个作业周转时间的平均值：平均周转时间=(作业1的周转时间+⋅⋅⋅+作业n的中转时间)n平均周转时间 = \\frac{(作业1的周转时间 + ··· + 作业n的中转时间)}{n}\n平均周转时间=n(作业1的周转时间+⋅⋅⋅+作业n的中转时间)​\n带权周转时间是指作业周转时间与作业实际运行时间的比值带权周转时间=作业周转时间作业实际运行时间带权周转时间= \\frac{作业周转时间}{作业实际运行时间} \n带权周转时间=作业实际运行时间作业周转时间​\n平均带权周转时间是指多个作业带权周转时间的平均值：平均带权周转时间=(作业1的带权周转时间+⋅⋅⋅+作业n的带权周转时间)n平均带权周转时间=\\frac{(作业1的带权周转时间+···+作业n的带权周转时间)}{n}\n平均带权周转时间=n(作业1的带权周转时间+⋅⋅⋅+作业n的带权周转时间)​\n\n等待时间：指进程处于等处理机状态的时间之和，等待时间越长，用户满意度越低。\n响应时间：指从用户提交请求到系统首次响应所用的时间。\n\n 调度算法\n 先来先服务(FCFS)\n每次从就绪队列中选择最先进入的进程，直到完成或者阻塞。这种算法属于不可剥夺算法，从表面上看对所有进程都是公平的，但是会导致来的晚的短作业等待时间长。\n 短作业优先(SJF)\n短作业优先算法从就绪队列中选择一个或若干个估计运行时间最短的作业。该算法会产生饥饿现象，使得长作业长期得不到执行。同时该算法也不考虑作业的优先级，因此不会保证重要任务被优先执行。\n该算法对作业的选择严重依赖于估计出的运行时间，但估计运行时间并不准确，因此实际运行过程中该算法可能并不能够做到短作业优先。\n 优先级调度\n优先级调度算法从就绪队列中选择优先级最高的一个或几个作业。该算法可分为非剥夺优先级调度算法和剥夺式优先级调度算法。\n根据进程创建后优先级是否可变又可以分为静态优先级和动态优先级。\n 高响应比优先算法\n高响应比优先算法主要用于作业调度，是对FCFS和SJF的一种综合平衡。响应比可以描述为 响应比=等待时间+要求服务时间要求服务时间响应比 = \\frac{等待时间+要求服务时间}{要求服务时间}响应比=要求服务时间等待时间+要求服务时间​ 。对于短作业而言，其要求服务时间短，响应比就越高，可以优先调度；对于长作业而言，等待时间越长，响应比就越高，最终也可以获得处理机资源从而避免了饥饿现象。\n 时间片轮转算法\n时间片轮转算法将进程按FCFS顺序分配时间片，进程在执行完一个时间片后将重新回到队列末尾。\n时间片大小需要由系统的响应时间、就绪队列中的进程数目以及系统的处理能力确定。\n 多级反馈队列算法\n多级反馈队列算法设置了多个就绪队列，每个就绪队列的优先级不同。根据不同优先级队列划分不同长度的时间片，优先级越低，时间片越大。当优先级高的队列中为空时，CPU将被分配给下一级队列中的进程。\n进程在进入内存后，首先进入最高一级的就绪队列中等待执行，若一个时间片后还没有执行完成，将会被放置进入次优先级的就绪队列中。\n若执行过程中有更高优先级的进程加入，CPU将被高优先级的进程抢占。\n 进程同步\n由于进程的异步性导致的进程之间推进速度不可预测，当多个进程需要协同或竞争使用某一资源时，不可避免地需要等待或通知其它进程。这种在同一时刻仅允许一个进程使用的资源又被称为临界资源，在进程中访问临界资源的代码块被称为临界区。\n同步和互斥是进程之间的制约关系。同步是直接制约关系，是指进程之间需要依靠某种顺序执行而必须建立的制约关系，比如生产者消费者；互斥是间接制约关系，是指多个进程之间对于某类资源的争用，比如打印机的使用。\n 临界区互斥方法\n 软件实现的方法\n 单标志法\n// P0进程\nwhile(turn != 0);\ncritical section; // 临界区\nturn = 1;\nremainder section; // 剩余区\n\n// P1进程\nwhile(turn != 1);\ncritical section;\nturn = 0;\nremainder section\n\n该算法的两个进程必须交替进入临界区，否则若一个进程停止执行，另一个进程会陷入死等。\n 双标志法先检查\n// Pi进程\nwhile(flag[j]);\nflag[i] = true;\ncritical section;\nflag[i] = false;\nremainder section;\n\n// Pj进程\nwhile(flag[i]);\nflag[j] = true;\ncritical section;\nflag[j] = false;\nremainder section\n\n当进程并发执行时，若遇到同时先后执行while语句时，将会导致互斥失效。\n 双标志法后检查\n// Pi进程\nflag[i] = true;\nwhile(flag[j]);\ncritical section;\nflag[i] = false;\nremainder section;\n\n// Pj进程\nflag[j] = true;\nwhile(flag[i]);\ncritical section;\nflag[j] = false;\nremainder section\n\n当进程并发执行时，若遇到同时先后执行while语句时，将会导致饥饿现象。\n Peterson’s Algorithm\n// Pi进程\nflag[i] = true;\nturn = j;\nwhile(flag[j]&amp;&amp;turn==j);\ncritical section;\nflag[i] = false;\nremainder section;\n\n// Pj进程\nflag[j] = true;\nturn = i;\nwhile(flag[i]&amp;&amp;turn==i);\ncritical section;\nflag[j] = false;\nremainder section\n\n","slug":"进程管理","date":"2022-04-24T12:42:46.000Z","categories_index":"","tags_index":"操作系统,Review","author_index":"ClaRn"},{"id":"ab80b4e122bbda900a1a6ace41232d32","title":"数据库系统","content":" 数据库（数据仓库）\n数据库是长期储存在计算机内、有组织的、可共享的大量数据的集合\n数据库中的数据按照一定的数据模型组织、描述、存储。具有较小冗余度、较高数据独立性和易扩展性，并且可以为各种用户共享。\n数据库的基本特点：\n\n永久存储\n有组织\n可共享\n\n 数据库管理系统\n用户通过数据库管理系统操作数据库，数据库管理系统将操作系统的接口封装，为用户提供数据的定义、组织、存储、管理、操纵、数据库的事务管理和运行、数据库的建立和维护等工作。\n 数据库系统\n数据库系统内包含数据库、数据库管理系统、应用程序和数据库管理员。\n数据库系统是用于存储、管理、处理和维护数据的系统\n数据库系统与文件系统的区别：数据的结构化\n 数据模型\n概念模型：对数据和信息的建模\n逻辑模型：数据之间的逻辑结构组成的模型\n物理模型：物理机上存储的模型\n Definitions\n\n实体(Entity)：客观存在并可以互相区别的事务\n属性(Attribute)：实体的某一特性\n码(Key)：唯一标识实体的属性集\n实体型(Entity Set)：同一类型实体的集合\n联系(Relationship)：实体之间的联系，通常指不同实体集之间的联系\n\n E-R图\n\n 范式\n\n第一范式(确保每列保持原子性)\n\n第一范式是最基本的范式。如果数据库表中的所有字段值都是不可分解的原子值，就说明该数据库表满足了第一范式。\n第一范式的合理遵循需要根据系统的实际需求来定。\n比如某些数据库系统中需要用到“地址”这个属性，本来直接将“地址”属性设计成一个数据库表的字段就行。但是如果系统经常会访问“地址”属性中的“城市”部分，那么就非要将“地址”这个属性重新拆分为省份、城市、详细地址等多个部分进行存储，这样在对地址中某一部分操作的时候将非常方便。\n\n\n第二范式(确保表中的每列都和主键相关)\n\n第二范式在第一范式的基础之上更进一层。第二范式需要确保数据库表中的每一列都和主键相关，而不能只与主键的某一部分相关（主要针对联合主键而言）。也就是说在一个数据库表中，一个表中只能保存一种数据，不可以把多种数据保存在同一张数据库表中。\n比如要设计一个订单信息表，因为订单中可能会有多种商品，所以要将订单编号和商品编号作为数据库表的联合主键。\n\n\n第三范式(确保每列都和主键列直接相关,而不是间接相关)\n\n第三范式需要确保数据表中的每一列数据都和主键直接相关，而不能间接相关。\n比如在设计一个订单数据表的时候，可以将客户编号作为一个外键和订单表建立相应的关系。而不可以在订单表中添加关于客户其它信息（比如姓名、所属公司等）的字段。\n\n\n\n SQL语句\n 索引\n\nhash索引：O(1)操作，适合单值查询，如 =、in\nbtree索引：适合单值查询和范围查询，如 &lt;、&gt;、between\n\n UNION操作符\nSELECT column_name FROM table1\nUNION\nSELECT column_name FROM table2;\n\nUNION操作符的作用是合并两个或者多个SELECT语句的查询结果。\nUNION操作默认选取不同的值。如果需要允许重复的值，需要使用UNION ALL。\nSELECT column_name FROM table1\nUNION ALL\nSELECT column_name FROM table2;\n\n SELECT INTO语句\nMySQL不支持该语句，但可以用INSERT INTO ... SELECT ...代替。\n下面语句将table1所有的列复制进newtable\nSELECT * INTO newtable FROM table1;\n\n或者也可以将table1中的指定列复制进newtable\nSELECT comun_name INTO newtable FROM table1;\n\n IN操作符\nIN操作符可以让WHERE在多个值中选择。\nSELECT column_name1,column_name2,... \nFROM table1 \nWHERE column IN (value1, value2, ...);\n\n BETWEEN操作符\nBETWEEN操作符可以选取介于两个值之间的数据范围内的值。\nSELECT column_name1, column_name2, ... \nFROM table1 \nWHERE column BETWEEN value1 AND value2;\n\nvalue的值可以是数字、字符或者日期。\n在MySQL中，BETWEEN操作符的选择会包括value1和value2。\n ORDER BY关键字\nORDER BY关键字用于对结果集合进行排序，排序结果可以是升序或者降序。\nSELECT column_name1, column_name2, ...\nFROM table1\nORDER BY column_name1, column_name2, ... ASC;\n\n升序操作为ASC，是默认的；降序操作为DESC。\n当有多个关键字需要排序时，将会按照语句中给出的顺序作为优先级进行排序。\n JOIN连接符\nJOIN连接符用于将两个或是多个表的行结合起来。包括LEFT JOIN, RIGHT JOIN, INNER JOIN, OUTER JOIN。\n\n\nINNER JOIN：如果表中有至少一个匹配，则返回行\nLEFT JOIN：即使右表中没有匹配，也从左表返回所有的行\nRIGHT JOIN：即使左表中没有匹配，也从右表返回所有的行\nFULL JOIN：只要其中一个表中存在匹配，则返回行\n\n CHECK约束\nCHECK约束用于限制列中的值得范围。\nCREATE TABLE Persons\n(\n   P_Id int NOT NULL,\n   LastName varchar(255) NOT NULL,\n   FirstName varchar(255),\n   Address varchar(255),\n   City varchar(255),\n   CHECK (P_Id&gt;0)\n);\n\n或者在ALTER TABLE语句中\nALTER TABLE Persons\nADD CHECK (P_Id&gt;0);\n\n CREATE INDEX语句\n该语句可用于在表中创建索引。在不读取整个表的情况下，索引可以加快数据库查找数据的速度。\n可以使用下列语句创建一个索引\nCREATE INDEX index_name\nON table_name (column_name, ...);\n\n一个索引可以不只联系一个列，可以将多个列共同索引。\n可以使用下列语句创建一个唯一索引\nCREATE UNIQUE INDEX index_name\nON table_name (column_name, ...);\n\n唯一索引不允许有两个相同值的行存在。\n LIKE操作符\nLIKE操作符用于在WHERE子句中搜索列中的指定模式，使用%作为字符通配符，例如%Y将会匹配所有以Y结尾的字符串。\nSELECT column_name, column_name1, ... \nFROM table_name\nWHERE column_name LIKE pattern;\n\n通常情况下，pattern中的通配符有两种：\n\n%：替代0个或多个字符\n_：替代一个字符\n\n但是若要匹配正则表达式，则可以使用如下语句\nSELECT * FROM Websites\nWHERE name REGEXP '^[GFs]';\n\n上述语句将匹配所有以G、F、s开头的列。\n AUTO_INCREMENT\n在MySQL中，创建表时添加AUTO_INCREMENT字段可以让属性自增。\nCREATE TABLE Persons\n(\n   ID int NOT NULL AUTO_INCREMENT,\n   LastName varchar(255) NOT NULL,\n   FirstName varchar(255),\n   Address varchar(255),\n   City varchar(255),\n   PRIMARY KEY (ID)\n);\n\n默认地，AUTO_INCREMENT 的开始值是 1，每条新记录递增 1。\n要让 AUTO_INCREMENT 序列以其他的值起始，可以使用下面的 SQL 语法：\nALTER TABLE Persons AUTO_INCREMENT=100\n\n ALTER TABLE\n该语句可以用于修改已有的表的列。\n\n在表中添加列ALTER TABLE table_name\nADD column_name datatype\n\n\n在表中删除列ALTER TABLE table_name\nDROP COLUMN column_name\n\n\n在表中修改列ALTER TABLE Persons\nALTER COLUMN column_name datatype\n\n\n\n","slug":"数据库系统","date":"2022-04-08T14:18:27.000Z","categories_index":"基础","tags_index":"Review,数据库","author_index":"ClaRn"},{"id":"90140ac06394d08c40bf165531addc6d","title":"操作系统概述","content":" 操作系统的特征\n\n并发：指两个或多个事件在同一时间间隔内发生。\n共享：资源共享，指系统中的资源可供内存中多个并发执行的进程共同使用。\n\n互斥型共享：资源在同一时刻只允许一个进程使用\n同时访问共享：资源可以在同一时刻由多个进程访问\n\n\n虚拟：指吧一个物理上的实体编程若干个逻辑上的对应物\n异步：进程的执行以不可预知的速度推进，在不同的时刻仅有一个进程占有处理机。\n\n 操作系统的目标和功能\n操作系统的主要功能有：\n\n处理机管理\n存储器管理\n设备管理\n文件管理\n操作系统对用户提供命令接口，让用户可以方便、快捷地操作计算机。接口有：\n命令接口：可分为联机命令接口和脱机命令接口\n\n联机命令接口：交互式命令接口，即Shell\n脱机命令接口：批处理命令接口，即批处理脚本\n\n\n程序接口：由一组系统调用组成\n\n 操作系统地发展和分类\n 手工处理阶段\n此时没有真正意义上的操作系统，所有硬件都由用户自行管理。\n 批处理阶段\n批处理系统可分为单道批处理系统和多道批处理系统。\n 单道批处理系统\n系统对作业的处理是成批进行的，但内存中始终只保存一道作业。每当程序在进行IO操作时，CPU将会进行等待。\n 多道批处理系统\n内存中不再只保存一道作业，而是可以允许多个程序同时进入内存，并在当前程序因为IO操作等原因陷入阻塞时，CPU将会转而执行其它程序。\n 分时操作系统\n分时技术指将处理器的运行时间分为很短的时间片，按照时间片将处理器分配给各个作业使用。\n分时操作系统则是使用了分时技术，让多个用户可以通过终端共享同一台主机，由于计算机切换进程的时间极短，每个用户都能获得接近独占机器的体验。\n 实时操作系统\n适合需要快速响应作业的场景，可以分为硬实时系统和软实时系统。\n硬实时系统将会绝对地在规定时间内执行任务，软实时系统可以偶尔违反时间规定。\n 操作系统的运行环境\n 操作系统的运行机制\n 时钟管理\n操作系统通过时钟管理向用户提供标准的系统时间，同时通过时钟中断完成进程的切换。\n 中断机制\n系统内核中用于管理设备、事件、调度等操作的机制。\n 原语\n\n是操作系统中完成一个规定操作的小程序\n处于操作系统的最底层，是最接近硬件的部分\n程序的运行具有原子性，也就是说其执行不能被打断\n程序的运行时间短，且调用频繁\n\n 系统控制的数据结构及处理\n\n进程管理，使用进程控制块(PCB)\n存储器管理\n设备管理\n\n 中断和异常\n 中断\n中断又称外中断，指来自CPU之外的事件的发生，如设备发出的IO中断或时钟发出的时钟中断。\n 异常\n异常也称内中断、例外或者陷入(trap)，指CPU内部发生的如程序非法操作、地址越界、算术溢出、虚存系统缺页以及陷入指令所引发的事件。异常无法被屏蔽，且处理异常依赖于当前运行程序。GBD的Debug就是依赖trap指令实现的调试功能。\n 中断处理的过程\n\n关中断\n保存断点\n中断服务程序寻址\n保护现场和屏蔽字\n开中断\n执行中断服务程序\n关中断\n恢复现场和屏蔽字\n开中断、中断返回\n\n 系统调用\n系统调用的发生需要操作系统完成从用户态到内核态的转换，同时系统调用的函数使用的堆栈也将从用户堆栈切换到系统堆栈。\n用户可以通过trap指令来发起系统调用，trap指令又称为陷入指令或访管指令。访管指令是在用户态执行的，所以并非是特权指令。\n","slug":"操作系统概述","date":"2022-04-08T14:11:31.000Z","categories_index":"基础","tags_index":"操作系统,Review","author_index":"ClaRn"},{"id":"81579b6c641dedc829a2b0058112fc0c","title":"数据结构","content":" 一、 数据结构与算法分析的基本概念\n （一）数据结构的基本概念\n\n数据\n数据是信息的载体，是描述客观事物属性的数字、字符以及所有能输入到计算机中被程序识别和处理的符号的集合\n数据元素\n数据元素是数据的基本单位，一个数据元素由若干个 数据项 组成，数据项是数据元素中不可分割的最小单位。\n数据对象\n数据对象是具有相同性质的数据元素的集合，是数据的一个子集。\n数据类型\n数据类型是一个值的集合和定义在此集合上的一组操作的统称\n\n原子类型：值不可再分的数据类型\n结构类型：值可以再分解为若干分量的数据类型\n抽象数据类型(ADT) ：抽象数据组织以及相关操作，可以用抽象数据类型定义一个完整的数据结构\n\n\n数据结构\n数据结构是相互之间存在一种或多种特定关系的数据元素的集合。数据元素之间的关系被称为结构。数据结构包括：逻辑结构、存储结构、数据运算。\n数据的逻辑结构和存储结构是密不可分的两个方面，一个算法的设计取决于所选定的逻辑结构，而算法的实现依赖于所采用的存储结构。\n数据结构的三要素\n\n数据的逻辑结构\n逻辑结构是指数据元素之间的逻辑关系，即从逻辑关系上描述数据。它与数据的存储无关，是独立于计算机的。数据的逻辑结构分为线性结构和非线性结构，线性表就是典型的线性结构；集合、树、图就是典型的非线性结构。\n\n集合：结构中的数据之间除了“同属于一个集合”之外，没有别的关系\n线性结构：结构中的数据元素之间只存在一对一的关系\n树形结构：结构中的数据元素之间存在一对多的关系\n图或网状结构：结构中的数据元素之间存在多对多的关系\n\n\n数据的存储结构\n存储结构是指数据结构再计算机中的表示，也称物理结构。它包括数据安苏的表示和关系的表示。数据的存储结构是用计算机语言实现的逻辑结构，它依赖于计算机语言。数据的存储结构主要有顺寻存储、链式存储、索引存储和散列存储\n\n顺序存储：把逻辑上相邻的元素存储在物理位置上也相邻的存储单元中，元素之间的关系由存储单元的邻接关系来体现。其优点是可以实现随机存取，每个元素占用最小的存储空间，缺点是只能使用相邻的一整块存储单元，因此可能产生较多外部碎片\n链式存储：不要求逻辑上相邻的元素在物理位置上也相邻，借助指示元素存储地址的指针来表示元素之间的逻辑关系。其优点是不会出现碎片现象，能充分利用所有存储单元；缺点是每个元素因存储指针而占用额外的存储空间，且只能实现顺序存取。\n索引存储：在存储元素信息的同时还建立附加的索引表。索引表中的每项称为索引项，索引项的一般形式是(关键字：地址)。其优点是检索速度快，缺点是附加的索引表额外占用存储空间。另外，增加和删除数据时也要修改索引表，因此比较耗时。\n散列存储(哈希存储)：根据元素的关键字直接计算出该元素的存储地址。其优点是减速、增加和删除节点的操作都很快；缺点是如果散列函数不好，则可能出现元素存储单元冲突，解决冲突则需要许多额外的时间和空间开销。\n\n\n数据的运算\n施加在数据上的运算包括运算的定义和实现。运算的定义是针对逻辑机构，支出运算的功能；运算的实现是针对存储结构的，指出运算的具体操作步骤。\n\n\n\n （二）渐近算法分析方法\n\n\n算法的基本概念\n算法是对特定问题求解的一种描述，它是指令的有限序列，其中的每条指令代表一个或多个操作。此外，一个算法还具有下列五个重要特性：\n\n有穷性：一个算法必须总在执行完有穷步之后结束，且每一步都可再有穷时间内完成。\n确定性：算法中的每条指令必须有确切的含义，对于相同的输入只能得到相同的输出\n可行性：算法中描述的操作的可以通过已有实现的基本运算执行有限次来实现\n输入：输入取自某个特定的对象的集合\n输出：一个算法有一个或多个输出，这些输出是与输入有着某种特定关系的量\n通常一个好的算法应该达到：\n正确性：答案得是对的\n可读性：助于人们理解\n健壮性： 输入非法数据时能作出恰当的反应，没啥bug\n效率与低存储量需求：又快又好地执行\n\n\n\n算法效率的度量\n算法效率的度量是通过时间复杂度和空间复杂度来描述的\n\n\n （三）时间复杂度\n\n\n时间复杂度\n一个语句的频度是指该语句在算法中被重复执行的次数，算法中所有语句频度之和记为T(n)T(n)T(n)，它是该算法问题规模nnn的函数，时间复杂度主要分析T(n)T(n)T(n)的数量级。算法中基本运算(最深层循环内的语句)的频度与T(n)T(n)T(n)同数量级，因此通常采用算法中基本运算的频度f(n)f(n)f(n)(取f(n)f(n)f(n)中增长最快的项，比如f(n)=an3+bn2+cnf(n)=an^3+bn^2+cnf(n)=an3+bn2+cn,则取n3n^3n3)来分析算法的时间复杂度。故算法的时间复杂度记为：$$T(n)=O(f(n))$$。\n算法的时间复杂度不仅取决于问题规模nnn，也取决于待输入数据的性质。\n分析程序的时间复杂性的两条规则：\n\n加法规则 :T(n)=T1(n)+T2(n)=O(f(n))+O(g(n))=O(max(f(n),g(n))T(n)=T_1(n)+T_2(n)=O(f(n))+O(g(n))=O(max(f(n),g(n))T(n)=T1​(n)+T2​(n)=O(f(n))+O(g(n))=O(max(f(n),g(n))\n乘法规则 :T(n)=T1(n)∗T2(n)=O(f(n))∗O(g(n))=O(f(n)∗g(n))T(n)=T_1(n)*T_2(n)=O(f(n))*O(g(n))=O(f(n)*g(n))T(n)=T1​(n)∗T2​(n)=O(f(n))∗O(g(n))=O(f(n)∗g(n))\n常见的渐进时间复杂度有\n\nO(1)&lt;O(log2n)&lt;O(n)&lt;O(nlog2n)&lt;O(n2)&lt;O(n3)&lt;O(2n)&lt;O(n!)&lt;O(nn)\\\\\nO(1)&lt;O(log_2 n)&lt;O(n)&lt;O(nlog_2 n)&lt;O(n^2)&lt;O(n^3)&lt;O(2^n)&lt;O(n!)&lt;O(n^n)\nO(1)&lt;O(log2​n)&lt;O(n)&lt;O(nlog2​n)&lt;O(n2)&lt;O(n3)&lt;O(2n)&lt;O(n!)&lt;O(nn)\n\n\n （四）空间复杂度\n\n\n空间复杂度\n算法的空间复杂度S(n)S(n)S(n)定义为该算法所耗费的存储空间，它是问题规模nnn的函数。记为S(n)=O(g(n))S(n)=O(g(n))S(n)=O(g(n)) 。\n一个程序在执行时除了需要存储空间来存放本身所用的指令、常数、变量和输入数据之外，还需要一些对数据进行操作的工作单元和存储一些为实现计算所需信息的辅助空间。若输入数据所占空间只取决于问题本身，和算法无关，则只需分析除输入和程序之外的额外空间。\n算法原地工作指算法所需的辅助空间为常量，即O(1)O(1)O(1)\n\n\n\n 二、 线性表、栈和队列\n （一）线性表的定义和基本操作的设计\n线性表是具有相同数据类型的n个数据元素的有限序列，其中n为表长，当n=0n=0n=0时线性表是一个空表。若用LLL命名线性表，则其表示为：L=(a1,a2,a3,a4,a5...,ai,...,an)L=(a_1,a_2,a_3,a_4,a_5...,a_i,...,a_n)L=(a1​,a2​,a3​,a4​,a5​...,ai​,...,an​)，式中，a1称为表头元素，a_1称为表头元素，a1​称为表头元素，a_n$称为表为元素，除第一个元素外，所有元素都只有一个直接前驱，除最后一个元素外，所有元素都只有一个直接后驱。\n故线性表的特点如下：\n\n表中元素个数有限\n表中元素具有逻辑上的顺序，元素之间有其先后顺序\n表中元素都是数据元素，每个元素都是单个元素\n表中元素的数据类型都相同，即每个元素占有相同大小的存储空间\n表中元素具有抽象性，即仅讨论元素之间的逻辑关系，而不考虑元素究竟表示什么内容\n\n线性表的基本操作:\n\nInitList(&amp;L):初始化\nLength(&amp;L):求表长\nLocateElem(L,e)：按值查找操作。在表L中查找具有给定关键字值的元素\nGetElem(L,i)：按位查找操作。返回表中第i个位置的元素\nListInsert(&amp;L,i,e)：插入操作。在表L中的第i个位置上插入指定元素e\nListDelete(&amp;L,i,&amp;e)：删除操作。删除表L中第i个位置的怨怒是，并用e返回删除元素的值\nPrintList(L)：输出操作。按前后顺序输出线性表L的所有元素值\nEmpty(L)：判空操作。若L为空表，返回true，否则返回false\nDestroyList(&amp;L)：销毁操作。释放内存空间\n\n （二）线性表的顺序存储结构和链式存储结构实现\n 顺序表的定义:\n线性表的顺序存储又称顺序表。它是用一组地址连续的存储单元一次存储线性表中的数据元素，从而使得逻辑上相邻的两个元素在物理位置上也相邻。第一个元素存储在线性表的起始位置，第i个元素存储在线性表的第i个位置，紧接着便是第i+1个元素，称i为元素aia_iai​在线性表中的位序。因此，顺序表的特点式表中元素的逻辑顺序与其物理顺序相同。\n每个数据元素的存储位置都和线性表的起始位置相差一个和该数据元素的位序成正比的查那个书，因此线性表中的任意数据元素都可以随机存取。通常用高级程序设计语言中的数组来描述线性表的顺序存储结构。\n线性表中的位序是从1开始的，而数组下标式从0开始的\n\n静态分配的线性表的顺序存储类型可以被表述为：\n#define MaxSize 50         //线性表的最大长度\ntypedef struct &#123;\n    ElemType data[MaxSize];//顺序表的元素\n    int length;            //顺序表当前的长度\n&#125;SqList                    //顺序表的类型定义\n\n动态分配的线性表的顺序存储类型可以被表述为：\n#define InitSize 50        //线性表的初始长度\ntypedef struct &#123;\n    ElemType *data         //顺序表的元素\n    int length;            //顺序表当前的长度\n&#125;SqList                    //顺序表的类型定义\n\n动态分配的线性表初始化时需要对data进行内存空间分配，分配空间大小可以动态变化，若空间不足，可以额外申请一块更大的连续内存将数据复制过去后，再释放原内存，但前提是系统内存空间足够。\n顺序表最主要的特点是随机访问，访问指定序号的元素的时间复杂度为O(1)O(1)O(1)\n顺序表的存储密度高，每个节点只存储数据元素，没有额外的指针域。\n 单链表的定义:\n\n\n线性表的链式表示:\n顺序表可以随时存取表彰的任意一个元素，它的存储位置可以用一个简单直观的公式表示，但插入和删除操作需要移动大量元素。链式存储线性表时，不需要使用地址连续的存储单元，即不要求逻辑上相邻的元素在物理位置上也相邻，它通过“链”建立起数据元素之间的逻辑关系，因此插入和删除操作不需要移动怨怒是，而只需要修改指针，但也会失去顺序表可以随机存取的优势。\n\n\n\n线性表的链式存储又称为单链表，它是指通过一组任意的存储单元来存储线性表中的数据元素。为了建立数据元素之间的线性关系，对每个链表节点，除存放元素自身的信息外，还需要存放一个指向其后继的指针。单链表节点描述为：\ntypedef struct LNode&#123;\n    ElemType data;\n    struct LNode *next;\n)LNode,*LinkList;\n\n利用单链表可以解决顺序表需要大量连续存储单元的缺点，但单链表附加指针域，也存在浪费空间的缺点。由于节点的离散存储，所以单链表不支持随机存取。\n通常用头指针来标识一个单链表，如单链表L，头指针为NULL时表示一个空表。此外为了操作方便，在第一个存储数据的节点之前附加一个节点，称为头节点，头节点可以存储单链表长度，也可以不存储任何信息。\n （三）线性表的应用\n （四）栈和队列的基本概念和基本操作的设计\n 栈\n\n栈的定义：栈是只允许在一端进行插入或删除操作的线性表\n栈顶：线性表允许进行删除的那一端\n栈底：固定的，不允许进行插入和删除的一端\n空栈：不含任何元素的空表\n栈的数学性质：$n个不同元素进栈，出栈不同排列组合的个数为 \\frac{1}{(n+1)} C^{n}_{2n} $ 。上述公式称为卡特兰数。\n栈的基本操作\n\nInitStack(&amp;S):初始化\nStackEmpty(S):判断是否为空，若是则返回true，若不是则返回false\nPush(&amp;S,x):进栈，若栈S未满则将x加入使之成为新的栈顶\nPop(&amp;S,&amp;x):出栈，若栈非空，则弹出栈顶元素，并用x返回\nGetTop(S,&amp;x):读取栈顶元素\nDestroyStack(&amp;S):销毁栈\n若题干未限制，则可以直接使用这些基本操作函数\n\n\n\n 队列\n\n队列的定义：队列简称队，是一种操作受限制的线性表，只允许在表的一端插入，另一端进行删除。\n入队(进队)：向表中进行数据插入\n出队(离队)：向表中进行数据删除\n队列的基本操作\n\nInitQueue(&amp;Q):初始化队列\nQueueEmpty(Q):判断是否为空\nEnQueue(&amp;Q,x):入队，若队列Q未满，则将x加入使之成为新的队尾\nDeQueue(&amp;Q,&amp;x):出队，若队列Q非空，删除队头元素，并用x返回。\nGetHead(!,&amp;x):读取队头元素，若队列非空则将队头元素赋值给x\n\n\n\n （五）栈和队列的顺序存储结构和链式存储结构实现\n 栈的存储结构\n\n\n顺序存储结构\n\n实现#define Maxsize 50 //栈中元素的最大个数\ntypedef struct &#123;\n   ElemenType data[MaxSize]; //存放栈中元素\n   int top; //栈顶指针\n&#125; SqStack;\n\n\n栈空条件：top = -1(若栈顶指针指向下一个空闲空间，则top = 0)；栈满条件：top = Maxsize -1; 栈长：top + 1;\n由于顺序栈的入栈操作受到数组上界的约束，当对栈的最大使用空间估计不足时，有可能发生栈上溢。\n\n\n\n链式存储结构\n\n实现typedef struct LinkNode &#123;\n   ElemType data;\n   struct LinkNode *next;\n&#125; *LiStack; //相当于LinkNode*\n\n\n\n\n\n 队列的存储结构\n\n顺序存储\n\n实现#define Maxsize 50\ntypedef struct &#123;\n   ElemType data[Maxsize];\n   int front,rear;\n&#125; SqQueue;\n\n\n初始状态(队空条件)：front == rear == 0;进队操作：队不满时，先将值送到队尾元素，再将队尾指针加1；出队操作:先将值取出，再将队头指针加1\n普通队列不能用rear == Maxsize 判空，会出现假溢出\n循环队列的队列长度：(rear+Maxsize-front)%Maxsize (rear指向的是下一个空余空间，所以在没有超出Maxsize的情况下实际长度是(rear-front)-1)；循环队列的队首指针：front = (front+1)%Maxsize ；循环队列的队尾指针：rear = (rear+1)%Maxsize\n循环队列判断队满\n\n牺牲一个单元，规定rear+1 = front ，即尾指针的下一个单元是头指针时为满；此时队满条件为：(rear+1)%Maxsize = front;队空条件仍为：front == rear;队长为：(rear-front+Maxsize)%Maxsize\n类型中新增表示元素个数的数据成员size，表示队满的条件则为size == Maxsize\n类型中新增tag数据成员，以区分是队满还是队空。tag == 0时，若因删除导致front == rear则为队空；tag == 1时，若因插入导致front == rear，则为队满。\n\n\n\n\n\n （六）栈和队列的应用\n\n 三、 二叉树和树\n （一）二叉树\n\n\n二叉树的定义及其主要特征\n\n二叉树是另一种树形结构，其特点是每个结点至多只有两颗子树（即二叉树中不存在度大于2的结点），并且二叉树的子树有左右之分，其次序不能随意颠倒。\n与树相似，二叉树也以递归的形式定义。二叉树是n(n≥0)n(n \\geq 0)n(n≥0)个结点的有限集合：\n\n或者为空二叉树，即n=0n=0n=0\n或者由一个根节点和两个互不相等的被称为根的左子树和右子树组成。左子树和右子树又分别是一棵二叉树\n\n\n\n二叉树是有序树，若其左、右子树颠倒，则成为另一颗不同的二叉树，即使树中结点只有一棵子树，也要区分它是左子树还是右子树。\n\n满二叉树：\n\n高度为hhh且结点数为2h−12^h -12h−1的二叉树。即树中每层的结点都是满的。\n满二叉树的叶子结点均在最下一层，且除叶子结点外每个节点的度均为2 。\n满二叉树的编号：\n\n从根节点开始（根节点为1），自上到下，从左到右依次排号。\n若编号为iii的子节点有双亲，则双亲编号为i/2(向上取整)i/2(向上取整)i/2(向上取整)，左孩子结点编号为2×i2 \\times i2×i，右孩子的结点编号为2i+12i +12i+1\n\n\n\n\n完全二叉树：\n\n高度为hhh、有nnn个结点的二叉树，当且仅当其每个结点都与高度hhh的满二叉树中编号为1→n1 \\to n1→n的结点一一对应时称为完全二叉树（人话版：所有节点的序号排列都和满二叉树里的排列一样）\n若i≤n/2  (舍去小数取整)i \\leq {n/2 \\ \\ (舍去小数取整)}i≤n/2  (舍去小数取整)，则有结点iii为分支节点，否则必为叶子结点。因为要一一对应的话，就会和满二叉树类似叶子结点几乎分布于最底层。\n叶子结点只可能在层次最大的两层上出现，最大层次中的叶子结点都依次排列在最左侧的位置上。意即从最底层的最左侧开始分布，一直排列到最右侧，排满了就是满二叉树了嗷。\n若有度为1的结点，则只可能有1个，且该结点只有左孩子。\n按层序编号后，一旦出现某节点为叶子结点或只有左孩子，则编号大于该节点的均为叶子结点（上一条性质为原理）\n若nnn为奇数，则每个分支结点都有左孩子和右孩子，若nnn为偶数，则编号最大的分支结点（编号为n/2n/2n/2）只有左孩子，没有右孩子，其余分支结点左右孩子都有。\n\n\n二叉排序树：\n\n左子树上所有结点的关键字均小于根节点的关键字；右子树上所有结点的关键字均大于根节点的关键字；左子树和右子树又各是一颗二叉排序树。\n\n\n平衡二叉树：\n\n树上任意结点的左子树和右子树的深度之差不超过1 。\n\n\n\n\n\n二叉树的顺序存储结构和链式存储结构实现\n\n\n顺序结构存储\n二叉树的顺序存储结构是指用一组地址连续的存储单元依次自上而下、自左向右地存储完全二叉树上地结点，即将完全二叉树上编号为$i$地结点存储在一维数组下标为$i-1$中\n依据二叉树的性质，完全二叉树和满二叉树采用顺序存储更加合适，树中结点的序号可以唯一反应结点的逻辑关系，这样既能节省存储空间，又能利用数组元素的下标值迅速地确定结点在二叉树中的位置。\n但一般的二叉树中的空结点则需要在数组中相应位置进行补0，由此可能造成较大存储空间浪费\n\n\n链式结构存储\n使用结构体或类构建结点：\ntypedef struct BiTNode&#123;\n   ElemType data;\n   struct BiTNode *lchild,*rchild;\n&#125;BiTNode,*BiTree\n\n在含有nnn个结点的二叉链表中，含有n+1n+1n+1个空链域。\n\n\n使用不同存储结构时，实现二叉树的操作算法也会不同，因此要根据实际应用场景选择合适的存储结构\n\n\n二叉树的遍历及应用\n二叉树的遍历指按照某条搜索路径访问树中的每个节点，使得每个节点均被访问一次，而且仅被访问一次。由于二叉树是一种非线性结构，每个节点都可能有两颗子树，因此还需要寻找一种规律，以便使二叉树上的结点能排列在一个线性队列上，进而进行遍历。\n常见的遍历次序有：先序(NLR)、中序(LNR)、后续(LRN)三种遍历算法，其中的序指的是根节点何时被访问，需要注意的是，左节点永远先于右节点被访问。\n 1、 先序遍历\n\n若二叉树为空，则直接返回\n先访问根节点\n先序遍历左子树\n先序遍历右子树\n\n代码如下：\nvoid PerOrder(BiTree T) &#123;\n   if(T != NULL) &#123;\n      visit(T);\n      PerOrder(T-&gt;lchild);\n      PerOrder(T-&gt;rchild);\n   &#125;\n&#125;\n\n 2、 中序遍历\n\n若二叉树为空，直接返回\n中序遍历左子树\n访问根节点\n中序遍历右子树\n\n代码如下：\nvoid InOrder(BiTree T) &#123;\n   if(T != NULL) &#123;\n      InOrder(T-&gt;lchild);\n      visit(T);\n      InOrder(T-&gt;rchild)\n   &#125;\n&#125;\n\n 3、 后序遍历\n\n后序遍历左子树\n后序遍历右子树\n访问根节点\n\n代码如下：\nvoid PostOrder(BiTree T) &#123;\n   if(T != BULL) &#123;\n      PostOrder(T-&gt;lchild);\n      PostOrder(T-&gt;rchild);\n      visit(T);\n   &#125;\n&#125;\n\n\n三种遍历算法中，不管采用哪种遍历算法，每个节点都访问一次且仅访问一次，故时间复杂度都是O(n)O(n)O(n)，在递归遍历中，递归工作栈的深度恰好为树的深度，故最坏情况下遍历算法的空间复杂度为O(n)O(n)O(n)。\n 递归算法和非递归算法的转换\n 中序遍历：\nvoid InOrder2(BiTree T) &#123;\n   InitStack(S);\n   BiTree p = T;\n\n   while(p != NULL||!isEmpty(S)) &#123;\n      if(p != NULL) &#123;\n         //将根节点入栈并在下一个循环访问左节点\n         Push(S,p);\n         p=p-&gt;lchild;\n      &#125; else &#123;\n         //出栈根节点的同时访问根节点\n         Pop(S,p);\n         visit(p);\n         //下一个循环访问右节点\n         p=p-&gt;rchild;\n      &#125;\n   &#125;\n&#125;\n\n 先序遍历：\n先序遍历的实现与中序遍历相似，只需要在入栈时先访问根节点即可\nvoid PreOrder2(BiTree T) &#123;\n   InitStack(S);\n   BiTree p = T;\n\n   while(p != NULL||!isEmpty(S)) &#123;\n      if(p != NULL) &#123;\n         //访问根节点\n         visit(p);\n         //将根节点入栈并在下一个循环访问左节点\n         Push(S,p);\n         p=p-&gt;lchild;\n      &#125; else &#123;\n         //出栈根节点\n         Pop(S,p);\n         //下一个循环访问右节点\n         p=p-&gt;rchild;\n      &#125;\n   &#125;\n&#125;\n\n 后序遍历\n后序遍历算法思想与之前两种不同，需要保证在根节点出栈时右节点已被访问完。\nvoid PostOrder(BiTree T) &#123;\n   InitStack(S);\n   p=T;\n   r=NULL;  //用于记录最近访问过的结点\n   while(p != NULL||!IsEmpty(S)) &#123;\n      if (p) &#123;\n         Push(S,p);\n         //走到最左边\n         p=p-&gt;lchild;\n      &#125; else &#123;\n         //获取根节点\n         Peek(S,p);\n         if(p-&gt;rchild != NULL&amp;&amp;p-&gt;rchild != r) &#123;\n         //走到右边\n         p=p-&gt;rchild;\n         &#125; else &#123;\n         Pop(S,p);\n         visit(p);\n         r=p;\n         p=NULL;\n         &#125;\n      &#125;\n   &#125;\n&#125;\n\n 层次遍历\n需要借助队列实现，每访问一个节点就将该节点的孩子节点输入队列，并将该节点出队\nvoid LevelOrder(BiTree T) &#123;\n   InitQueue(Q);\n   BiTree p;\n   EnQueue(Q,T);\n   while(!IsEmpty(Q)) &#123;\n      DeQueue(Q,p);\n      visit(p);\n      if(p-&gt;lchild != NULL) &#123;\n         EnQueue(Q,p-&gt;lchild);\n      &#125;\n      if(p-&gt;rchild != NULL) &#123;\n         EnQueue(Q,p-&gt;rchild);\n      &#125;\n   &#125;\n&#125;\n\n 由遍历序列构建二叉树\n\n二叉树的先序序列和中序序列可以唯一确定一颗二叉树\n\n先序遍历中第一个结点一定是二叉树的根节点；中序遍历中，根节点必然将中序序列分割为两个子序列，前一个子序列是根节点的左子树的中序序列，后一个子序列是根节点的右子树的中序序列。\n\n\n二叉树的后序序列和中序序列也可以唯一确定一颗二叉树\n二叉树的层序序列和中序序列也可以唯一确定一颗二叉树\n\n除了先序序列和后序序列其余两种任意序列的组合都可以构建出二叉树。构建二叉树需要明确知道根节点和左右子树，而先序序列和后序序列无法确定左右子树。\n\n\n二叉排序（查找. 检索）树\n\n\n平衡的二叉检索树- AVL树\n\n\n堆\n#define DEFAULT_DATA_SIZE 10\n/***\n* 大顶堆\n*/\ntemplate&lt;class T&gt;\nclass Heap\n&#123;\nprivate:\n   /* data */\n   T* _data;\n   size_t _max_size = 0;\n   size_t size = 0;\n\n   size_t _get_left_child_index(size_t index) &#123;\n      return 2*index+1;\n   &#125;\n\n   size_t _get_right_child_index(size_t index) &#123;\n      return 2*index+2;\n   &#125;\n\n   size_t _get_root_index(size_t index) &#123;\n      return (index-1)/2;\n   &#125;\n\n   bool _is_empty() &#123;\n      return size == 0;\n   &#125;\n\n   bool _is_full() &#123;\n      return size == _max_size;\n   &#125;\n\n   void _alloc() &#123;\n      T* tmp = _data;\n      _data = new T[_max_size*2];\n      for (size_t i = 0; i &lt; _max_size; i++)\n      &#123;\n            _data[i] = tmp[i];\n      &#125;\n      _max_size *= 2;\n      delete[] tmp;\n   &#125;\n\n   void _shiftUp(size_t index) &#123;\n      if (index == 0) return;\n      size_t root = _get_root_index(index);\n      if (_data[root] &lt; _data[index])\n      &#123;\n            T tmp = _data[root];\n            _data[root] = _data[index];\n            _data[index] = tmp;\n      &#125;\n\n      _shiftUp(root);\n   &#125;\n\n   void _shiftDown(size_t index) &#123;\n      if (index == size) return;\n      size_t lc = _get_left_child_index(index);\n      size_t rc = _get_right_child_index(index);\n      size_t max = lc &gt; rc ? lc : rc;\n      if (_data[max] &gt; _data[index])\n      &#123;\n            T tmp = _data[max];\n            _data[max] = _data[index];\n            _data[index] = tmp;\n            _shiftDown(lc);\n      &#125;\n   &#125;\n\npublic:\n   explicit Heap(size_t max_size = DEFAULT_DATA_SIZE) &#123;\n      _max_size = max_size;\n      _data = new T[_max_size];\n   &#125;\n\n   ~Heap() &#123;\n      delete[] _data;\n   &#125;\n\n   void insert(T data) &#123;\n      if (_is_full())\n      &#123;\n            _alloc();\n      &#125;\n\n      _data[size] = data;\n      _shiftUp(size);\n      size++;\n   &#125;\n\n   T removeAt(size_t index) &#123;\n      T data = _data[index];\n      _data[index] = _data[--size];\n      _shiftDown(index);\n      return data;\n   &#125;\n\n   T remove() &#123;\n      return removeAt(0);\n   &#125;\n\n   size_t length() &#123;\n      return size;\n   &#125;\n\n   size_t getMaxSize() &#123;\n      return _max_size;\n   &#125;\n\n   std::string toString() &#123;\n      std::string s = \"[\";\n      for (size_t i = 0; i &lt; size; i++)\n      &#123;\n            s += to_string(*(_data+i));\n            if (i != size-1)\n            &#123;\n               s += \" ,\";\n            &#125; else &#123;\n               s += \"] size = \"+to_string(size) + \" max_size = \"+to_string(_max_size);\n            &#125;\n      &#125;\n\n      return s;\n   &#125;\n\n&#125;;\n\n\n\n哈夫曼（Huffman）树和哈夫曼编码\n\n\n （二）树\n\n\n树的定义与术语\n 树的定义\n树是n(n≥0)n(n \\geq 0)n(n≥0)个节点的有限集。当n=0n=0n=0时，称为空树。在任意一颗空树中应满足：\n\n有且只有一个特定称为根的节点\n当n&gt;1n &gt; 1n&gt;1时，其余节点可分为m(m&gt;0)m (m&gt;0)m(m&gt;0)个互不相交的有限集T1,T2,...,TmT_1,T_2,...,T_mT1​,T2​,...,Tm​，其中每个集合本身又是一棵树，并且称为根的子树。\n\n显然，树的定义是递归的，即在书的定义中又用到了自身，树是一种递归的数据结构。树作为一种逻辑结构，同时也是一种分层结构，具有以下两个特点：\n\n树的根节点没有前驱，除根节点外的所有节点有且只有一个前驱。\n树的所有节点可以有零个或多个后继。\n\n树适合于表示具有层次的数据。树中的某个节点（除根节点外）最多只和上一层的一个节点（即其父节点）有直接关系，根节点没有直接上层节点，因此在nnn个节点的树中有n−1n-1n−1条边。而树中每个节点与其下一层的零个或多个节点（即其子女节点）有直接关系。\n 基本术语\n\n树中一个节点的孩子个数称为该节点的度，树中节点的最大度数称为树的度。\n度大于0的节点称为分支节点，度为0的节点称为叶子节点。在分支结点中，每个结点的分支数就是该结点的度。\n结点的深度、高度和层次\n结点的深度是从根节点开始自顶向下逐层累加的\n结点的高度是从叶节点开始自底向上逐层累加的\n树的高度是树中节点的最大层数\n有序树和无序树\n有序树：树中的结点的各子树从左到右是有次序的，不能互换（次序人为规定）\n无序树：否则成为无序树\n路径和路径长度\n路径：由树中这两个结点之间所经过的结点序列构成的\n路径长度：路径所经过的边的数量\n森林是m(m≥0)m(m \\geq 0)m(m≥0)棵互不相交的树的集合。森林的概念与树的概念十分相近，因为只要把树的根节点删去就成了森林。反之，只要给mmm棵独立的树加上一个结点，并把这mmm棵树作为该节点的子树，则森林就变成了树\n\n树具有如下基本性质：\n\n树中的节点数等于所有结点度数之和加1\n度为mmm的树中第iii层上至多有mi−1  (i≥1)m^{i-1} \\ \\ (i \\geq 1)mi−1  (i≥1)\n高度为hhh的mmm叉树最多有(mk−1)/(m−1)(m^k -1)/(m-1)(mk−1)/(m−1)个节点\n具有nnn个结点的mmm叉树的最小高度为log⁡m(n(m−1)+1)\\log_m(n(m-1)+1)logm​(n(m−1)+1)\n\n\n\n树的遍历\n\n\n树的顺序存储结构和链式存储结构实现\n\n\n\n 四、 图\n （一）图的基本概念\n图G由顶点集V和边集E组成，记为G=(V,E)G=(V,E)G=(V,E)，其中V(G)V(G)V(G)表示图G中顶点的有限非空集；E(G)E(G)E(G)表示图中顶点之间的关系（边）集合。\n线性表可以是空表、树可以有空树，但图不能是空图，图中至少有一个节点，但可以没有边\n\n\n有向图\n若E是有向边(弧)的有限集合时，图G为有向图，。弧是顶点的有序对，记为&lt;v,w&gt;，其中v,w是顶点，v称为弧尾，w称为弧头。也称v邻接到w。\n\n\n无向图\n若E是无向边(边)的有限集合时，图G为无向图。边是顶点的无序对，记为(v,w)或(w,v)。可以说w和v互为邻接点。\n\n\n简单图、多重图\n一个图若满足：\n\n不存在重复边\n不存在顶点到自身的边\n\n则称该图为简单图。\n若图中某两个顶点之间的边数大于1，又允许顶点通过一条边和自身关联，则称该图为多重图。\n\n\n完全图（简单完全图）\n对于无向图，|E|的取值范围在0$n(n-1)/2$之间，有$n(n-1)/2$条边的无向图称为完全图，在完全图中任意两个顶点之间都存在边；对于有向图，|E|的取值范围在0n(n−1)n(n-1)n(n−1)之间，有n(n−1)n(n-1)n(n−1)条边的有向图称为完全有向图，有向完全图中任意两个顶点之间都存在方向相反的两条弧。\n\n\n子图\n若存在一个G′=(V′,E′)G&#x27;=(V&#x27;,E&#x27;)G′=(V′,E′)使得V′V&#x27;V′是VVV的子集，E′E&#x27;E′是EEE的子集，则将G′G&#x27;G′称为GGG的子图。若V′=VV&#x27;=VV′=V，则将G′G&#x27;G′称为GGG的生成子图。\n\n\n连通、连通图和连通分量(特指无向图)\n\n\n\n连通：在无向图中，若从顶点v到顶点w有路径存在，则称v和w是连通的。\n连通图：若图中任意两个顶点都是连通的，则称该图为连通图，否则便是非连通图。\n连通分量：无向图中的极大连通子图称为该图的连通分量。(极大连通子图即该图的连通子图且该子图拥有的顶点数无法再增加，若增加就不在连通，且包含所有边)\n\n\n强连通图、强连通分量(特指有向图)\n\n\n强连通：有向图中若v到w和w到v之间都存在路径，则称这两个顶点是强连通的。\n强连通图：有向图中的任意两个结点都是强连通的，则该图称为强连通图。\n强连通分量：有向图中的极大强连通子图。\n\n\n生成树、生成森林\n\n\n生成树：包含图中所有结点的一个极小连通图。若图中有n个顶点，则生成树有n-1条边(极小连通图需要保证的是图的连通且边数最少)(若砍去生成树中的一条边，则该极小连通图退化为非连通图，若加上一条边则会产生一个回路)\n生成森林：非连通图中的连通子图的生成树构成了一片生成森林。\n\n\n顶点的度、出度、入度\n\n\n度：依附于顶点的边的条数，记为TD(v)TD(v)TD(v)。对于具有n个顶点、e条边的无向图，所有顶点的度之和为2e(一条边代表两个度嘛)。有向图的顶点的度为该顶点出度和入度之和。\n入度：在有向图中以顶点v为终点的边的数目，记为ID(v)ID(v)ID(v)\n出度：在有向图中以顶点v为起点的边的数目，记为OD(v)OD(v)OD(v)\n在有向图中所有顶点的出度和等于所有顶点的入度和\n\n\n边的权和网\n\n\n权值：每条边都可以标注具有某种意义的数值，该值称为权值\n网： 边上带有权值的图称为带权图，或网\n\n\n稠密图、稀疏图\n\n\n稀疏图：边数很少的图\n稠密图：边数很多的图\n判断条件：∣E∣&lt;∣V∣log∣V∣|E| &lt; |V|log|V|∣E∣&lt;∣V∣log∣V∣，则为稀疏图\n\n\n路径、路径长度、回路\n\n\n路径:顶点vpv_pvp​到vqv_qvq​之间的一条路径指顶点序列vp,vi1,vi2,...,vin,v1v_p,v_i1,v_i2,...,v_in,v_1vp​,vi​1,vi​2,...,vi​n,v1​\n路径长度：路径上边的数量\n回路：第个顶点和最后一个顶点相同的路径称为回路。若一个图有n个顶点，但有大于n-1条边，则此图一定存在回路。\n\n\n\n距离\n从顶点u出发到v的最短路径长度，若该路径不存在，则距离为无穷∞\n\n\n有向树\n一个顶点的入度为0、其余顶点的入度均为1 的图称为有向树。\n\n\n （二）图的存储及基本操作\n\n\n邻接矩阵\n采用一个一维数组存储图中顶点的信息，用一个二维数组存储图中边的信息(即各个顶点之间的关系)，存储顶点之间邻接关系的二维数组称为邻接矩阵。\n点中的数据使用一维数组保存，一维数组下表代表顶点编号，边使用二维数组保存，边的两个端点即二维数组的两个下标，由于这两个下标有ij和ji两种排列状态，故可以表示有向图。若为无向图时，该矩阵为对称矩阵。二维数组中的值代表有无边或者边的权值\n代码定义如下\n#define MaxVertexNum 100\ntypedef char VertesType;\ntypedef int EdgeType;\ntypedef struct&#123;\n   VertexType vex[MaxVertNum]; //顶点表，存数据\n   EdgeType Edge[MaxVertexNum][MaxVertexNum]; //邻接表\n   int vexnum,arcnum; //图的当前顶点数和弧数\n&#125; MGraph;\n\n\n在简单应用中，可以直接使用二维数组存储图，即忽略掉图的顶点信息\n当邻接矩阵的元素仅表示相应边是否存在时，EdgeType可采用值为0和1的枚举类型\n无向图的邻接矩阵是对称矩阵，对规模大的图可以压缩存储\n邻接矩阵表示法的空间复杂度为O(n2)O(n^2)O(n2)，其中n为图的顶点数\n\n特点：\n\n无向图的邻接矩阵一定是一个对称矩阵(并且唯一)\n对于无向图，邻接矩阵的第i行(或第i列)非零元素分个数正好是顶点i的度\n对于无向图，邻接矩阵的第i行非零元素的个数正好是顶点i的出度，第i列的非零元素刚好是顶点的入度\n用邻接矩阵存储图，很容易确定图中的任意两个顶点是否有边相连。但是，要确定图中有多少条边，则必须按行、列扫描检测，时间开销巨大。\n稠密图适合使用邻接表表示\n\n\n\n邻接表\n\n\n （三）图的遍历\n\n深度优先搜索\n广度优先搜索\n\n （四）图的应用\n\n拓扑排序\n关键路径\n最短路径\n最小（代价）生成树\n\n\n 五、 查找\n （一）查找的基本概念\n\n查找：在数据集合中寻找满足某种条件的数据元素的过程称为查找。查找的结果一般分为两种：查找成功和失败\n查找表：用于查找的数据集合称为查找表，它由同一类型的数据元素(或记录)组成\n静态查找表：若一个静态查找表只有查询指定数据和查找满足某个条件的数据的各种属性，无需动态地修改查找表，适合静态查找表的查找方法有：顺序查找，折半查找，散列查找等\n动态查找表：需要动态地添加和删除的查找表。适合动态查找表的查找方法有：二叉排序树查找，散列查找等\n关键字：数据元素中唯一标识该元素的某一个数据项的值，使用基于关键字的查找，查找结果应该是唯一的。\n平均查找长度：在查找过程中一次查找的长度是指需要比较的关键字次数，而平均查找长度则是所有查找过程中进行关键字的比较次数的平均值，其数学定义为ASL=∑i=1nPiCiASL =  \\sum_{i=1}^{n}P_iC_iASL=∑i=1n​Pi​Ci​ 式中，n是查找表的长度；PiP_iPi​是查找第i个数据的概率，一般认为每个数据元素的查找概率均等，即Pi=1/nP_i = 1/nPi​=1/n；CiC_iCi​是找到第i个数据元素需要的比较次数。平均查找长度是衡量查找算法效率的最主要指标\n\n （二）顺序查找法\n （三）折半查找法(二分查找)\n （五）散列（Hash）表及冲突解决策略\n\n构造方法\n\n直接定址法\n\nH(key) = key 或 H(Key) = a*key + b\n适合关键字分布连续的情况\n\n\n除留余数法\n\n假定散列表长为m ,取一个不大于m 但最接近或等于m 的质数p ，将关键字按照公式H(key)=key%pH(key)=key\\%pH(key)=key%p  转换为散列地址，需要选好p ，使得每个关键字通过函数转换后等概率地映射到散列空间上\n\n\n数字分析法\n\n设关键字是r进制数，而r 个数码在各位上出现的频率不一定相同，可能在某些位上分布的更均匀一些，每种数码出现的机会均等；而在某些位上分布不均匀，只有某几种数码经常出现，此时应选取数码分布较为均匀的若干位作为散列地址，这种发给发适用于已经知道关键字的集合，因为一旦关键字被修改，则需要重新构造一个新的散列函数\n\n\n平方取中法\n\n取关键字的平方值的中间几位作为散列地址。具体取多少位要视情况而定。这种方法得到的散列地址与关键字的每一位都有关系，所以可以使得散列地址分布比较均匀。适用于关键字的每位取值都不够均匀或者均小于散列地址所需要的位数\n\n\n\n\n冲突解决策略\n\n开放定址法\n\n可存放新表项(Entry) 的空闲地址空间既向它的同义词表项开放，又向非同义词表项开放。记为Hi=(H(key)+di)%mH_i=(H(key)+d_i)\\%mHi​=(H(key)+di​)%m ，式子中H(key)H(key)H(key)表示散列函数；i=0,1,2,3,...,k(k≤m−1)i=0,1,2,3,...,k  (k\\leq m-1)i=0,1,2,3,...,k(k≤m−1)；mmm 表示散列表长；did_idi​表示增量序列。\n增量序列确定后，对应的处理方法就是确定的。通常有如下四种方法：\n\n线性探测法。当di=0，1，2，3，。。。，m−1d_i=0，1，2，3，。。。，m-1di​=0，1，2，3，。。。，m−1时，称为线性探测法，这种方法的特点是：冲突发生时，顺序查看表中下一个单元(到达表的末尾m−1m-1m−1时，下一个探测地址就是表首地址0)，直到查找出一个空闲单元(表未填满时一定会找到一个空闲单元)或查遍全表。线性探测法可能使第i个散列地址的同义词存入第i+1个散列地址，这样本应存入第i+1个散列地址的同义词就只能存入i+2个散列地址，从而造成大量元素在相邻散列地址上“聚集”，极大降低了查找效率\n平方探测法(二次探测法)。增量序列di=02,12,−12,22,−22,...,k2,−k2d_i=0^2,1^2,-1^2,2^2,-2^2,...,k^2,-k^2di​=02,12,−12,22,−22,...,k2,−k2(k≤m/2)(k\\leq m/2)(k≤m/2) 。散列表的长度必须是可以表示为4k+3的素数。平方探测法处理冲突可以避免出现“堆积”问题，缺点是不能探测到所有单元，但至少能探测到一半的单元\n再散列法(双散列法)。di=Hash2(key)d_i = Hash_2(key)di​=Hash2​(key)，当第一个散列函数发生冲突时，通过第二个散列函数计算该关键字的地址增量Hi=(H(key)+i∗H2(key))%mH_i=(H(key)+i*H_2(key))\\%mHi​=(H(key)+i∗H2​(key))%m 其中i是发生冲突的次数，初始为0。最多经过m−1m-1m−1次探测便可以遍历表中所有的位置\n伪随机散列法。将did_idi​设置为伪随机数列。\n\n\n在开放定址法中，不能随便物理删除表中元素，若删除元素，则会截断其它具有相同散列地址的元素的查找地址。因此，要删除一个元素时，可以给它做一个删除标记，进行逻辑删除。但是这样就需要定期维护散列表将其中被标记删除的元素进行物理删除\n\n\n拉链法\n\n为了避免非同义词产生冲突，可以通过把所有同义词存储到一个线性链表中，这个线性链表再由其散列地址唯一标识。适用于对数据进行大量删除和插入操作的情况\n\n\n\n\n\n （六）查找算法的分析及应用\n\n 六、 内排序\n （一）排序的基本概念\n排序：指重新排列表中的元素，使表中的元素满足按关键字有序的过程。\n排序算法的稳定性：若待排序表中有两个元素RiR_iRi​和RjR_jRj​，其对应关键字相同即keyi=keyjkey_i = key_jkeyi​=keyj​，且在排序前RiR_iRi​在RjR_jRj​前面，若使用某一排序算法排序后，RiR_iRi​仍然在RjR_jRj​前面，则称这个算法使稳定的，否则这个算法就是不稳定的\n在排序过程中根据数据元素是否完全在内存中可以将算法分为两类：内部排序和外部排序\n\n内部排序：指在排序期间所有元素全部放在内存中的排序\n外部排序：指在排序期间元素无法全部同时存放在内存中，必须在排序的过程中根据要求不断地在内、外存之间移动的排序。\n\n （二）直接插入排序\n\n\n （三）冒泡排序\npublic static void bubbleSort(int[] arr) &#123;\n    int temp = 0;\n    for (int i = arr.length - 1; i &gt; 0; i--) &#123; // 每次需要排序的长度\n        for (int j = 0; j &lt; i; j++) &#123; // 从第一个元素到第i个元素\n            if (arr[j] &gt; arr[j + 1]) &#123;\n                temp = arr[j];\n                arr[j] = arr[j + 1];\n                arr[j + 1] = temp;\n            &#125;\n        &#125;//loop j\n    &#125;//loop i\n&#125;// method bubbleSort\n\n （四）简单选择排序\npublic static void selectionSort(int[] arr) &#123;\n    int temp, min = 0;\n    for (int i = 0; i &lt; arr.length - 1; i++) &#123;\n        min = i;\n        // 循环查找最小值\n        for (int j = i + 1; j &lt; arr.length; j++) &#123;\n            if (arr[min] &gt; arr[j]) &#123;\n                min = j;\n            &#125;\n        &#125;\n        if (min != i) &#123;\n            temp = arr[i];\n            arr[i] = arr[min];\n            arr[min] = temp;\n        &#125;\n    &#125;\n&#125;\n\n用数组实现的选择排序是不稳定的，用链表实现的选择排序是稳定的。\n （五）希尔排序（shell sort）\n先将整个待排序的记录序列分割成为若干子序列分别进行直接插入排序，具体算法描述：\n\n选择一个增量序列t1，t2，…，tk，其中ti&gt;tj，tk=1；\n按增量序列个数k，对序列进行 k 趟排序；\n每趟排序，根据对应的增量ti，将待排序列分割成若干长度为m 的子序列，分别对各子表进行直接插入排序。仅增量因子为1 时，整个序列作为一个表来处理，表长度即为整个序列的长度。\n\npublic static void shellSort(int[] arr)&#123;\n    int temp;\n    for (int delta = arr.length/2; delta&gt;=1; delta/=2)&#123;                              //对每个增量进行一次排序\n        for (int i=delta; i&lt;arr.length; i++)&#123;              \n            for (int j=i; j&gt;=delta &amp;&amp; arr[j]&lt;arr[j-delta]; j-=delta)&#123; //注意每个地方增量和差值都是delta\n                temp = arr[j-delta];\n                arr[j-delta] = arr[j];\n                arr[j] = temp;\n            &#125;\n        &#125;//loop i\n    &#125;//loop delta\n&#125;\n\n （六）快速排序\n从数列中挑出一个元素，称为&quot;基准&quot;（pivot），然后重新排序数列，所有比基准值小的元素摆放在基准前面，所有比基准值大的元素摆在基准后面（相同的数可以到任何一边）。在这个分区结束之后，该基准就处于数列的中间位置。这个称为分区（partition）操作。\n递归地（recursively）把小于基准值元素的子数列和大于基准值元素的子数列排序。\npublic static void quickSort(int[] arr)&#123;\n    qsort(arr, 0, arr.length-1);\n&#125;\nprivate static void qsort(int[] arr, int low, int high)&#123;\n    if (low &gt;= high)\n        return;\n    int pivot = partition(arr, low, high);        //将数组分为两部分\n    qsort(arr, low, pivot-1);                   //递归排序左子数组\n    qsort(arr, pivot+1, high);                  //递归排序右子数组\n&#125;\nprivate static int partition(int[] arr, int low, int high)&#123;\n    int pivot = arr[low];     //基准\n    while (low &lt; high)&#123;\n        while (low &lt; high &amp;&amp; arr[high] &gt;= pivot) --high;\n        arr[low]=arr[high];             //交换比基准大的记录到左端\n        while (low &lt; high &amp;&amp; arr[low] &lt;= pivot) ++low;\n        arr[high] = arr[low];           //交换比基准小的记录到右端\n    &#125;\n    //扫描完成，基准到位\n    arr[low] = pivot;\n    //返回的是基准的位置\n    return low;\n&#125;\n\n （七）堆排序\n堆排序(Heapsort)是指利用堆积树（堆）这种数据结构所设计的一种排序算法，它是选择排序的一种。可以利用数组的特点快速定位指定索引的元素。堆排序就是把最大堆堆顶的最大数取出，将剩余的堆继续调整为最大堆，再次将堆顶的最大数取出，这个过程持续到剩余数只有一个时结束。\n堆排序存在大量的筛选和移动过程，属于不稳定的排序算法。\npublic class ArrayHeap &#123;\n    private int[] arr;\n    public ArrayHeap(int[] arr) &#123;\n        this.arr = arr;\n    &#125;\n    private int getParentIndex(int child) &#123;\n        return (child - 1) / 2;\n    &#125;\n    private int getLeftChildIndex(int parent) &#123;\n        return 2 * parent + 1;\n    &#125;\n    private void swap(int i, int j) &#123;\n        int temp = arr[i];\n        arr[i] = arr[j];\n        arr[j] = temp;\n    &#125;\n    /**\n     * 调整堆。\n     */\n    private void adjustHeap(int i, int len) &#123;\n        int left, right, j;\n        left = getLeftChildIndex(i);\n        while (left &lt;= len) &#123;\n            right = left + 1;\n            j = left;\n            if (j &lt; len &amp;&amp; arr[left] &lt; arr[right]) &#123;\n                j++;\n            &#125;\n            if (arr[i] &lt; arr[j]) &#123;\n                swap(array, i, j);\n                i = j;\n                left = getLeftChildIndex(i);\n            &#125; else &#123;\n                break; // 停止筛选\n            &#125;\n        &#125;\n    &#125;\n    /**\n     * 堆排序。\n     * */\n    public void sort() &#123;\n        int last = arr.length - 1;\n        // 初始化最大堆\n        for (int i = getParentIndex(last); i &gt;= 0; --i) &#123;\n            adjustHeap(i, last);\n        &#125;\n        // 堆调整\n        while (last &gt;= 0) &#123;\n            swap(0, last--);\n            adjustHeap(0, last);\n        &#125;\n    &#125;\n\n&#125;\n\n （八）归并排序\npublic static void mergeSort(int[] arr)&#123;\n    int[] temp =new int[arr.length];\n    internalMergeSort(arr, temp, 0, arr.length-1);\n&#125;\nprivate static void internalMergeSort(int[] arr, int[] temp, int left, int right)&#123;\n    //当left==right的时，已经不需要再划分了\n    if (left&lt;right)&#123;\n        int middle = (left+right)/2;\n        internalMergeSort(arr, temp, left, middle);          //左子数组\n        internalMergeSort(arr, temp, middle+1, right);       //右子数组\n        mergeSortedArray(arr, temp, left, middle, right);    //合并两个子数组\n    &#125;\n&#125;\n// 合并两个有序子序列\nprivate static void mergeSortedArray(int arr[], int temp[], int left, int middle, int right)&#123;\n    int i=left;      \n    int j=middle+1;\n    int k=0;\n    while (i&lt;=middle &amp;&amp; j&lt;=right)&#123;\n        temp[k++] = arr[i] &lt;= arr[j] ? arr[i++] : arr[j++];\n    &#125;\n    while (i &lt;=middle)&#123;\n        temp[k++] = arr[i++];\n    &#125;\n    while ( j&lt;=right)&#123;\n        temp[k++] = arr[j++];\n    &#125;\n    //把数据复制回原数组\n    for (i=0; i&lt;k; ++i)&#123;\n        arr[left+i] = temp[i];\n    &#125;\n&#125;\n\n （九）基数排序\n将所有待比较数值（正整数）统一为同样的数位长度，数位较短的数前面补零。然后，从最低位开始，依次进行一次排序。这样从最低位排序一直到最高位排序完成以后, 数列就变成一个有序序列。\npublic abstract class Sorter &#123;\n     public abstract void sort(int[] array);\n&#125;\n \npublic class RadixSorter extends Sorter &#123;\n     \n     private int radix;\n     \n     public RadixSorter() &#123;\n          radix = 10;\n     &#125;\n     \n     @Override\n     public void sort(int[] array) &#123;\n          // 数组的第一维表示可能的余数0-radix，第二维表示array中的等于该余数的元素\n          // 如：十进制123的个位为3，则bucket[3][] = &#123;123&#125;\n          int[][] bucket = new int[radix][array.length];\n          int distance = getDistance(array); // 表示最大的数有多少位\n          int temp = 1;\n          int round = 1; // 控制键值排序依据在哪一位\n          while (round &lt;= distance) &#123;\n               // 用来计数：数组counter[i]用来表示该位是i的数的个数\n               int[] counter = new int[radix];\n               // 将array中元素分布填充到bucket中，并进行计数\n               for (int i = 0; i &lt; array.length; i++) &#123;\n                    int which = (array[i] / temp) % radix;\n                    bucket[which][counter[which]] = array[i];\n                    counter[which]++;\n               &#125;\n               int index = 0;\n               // 根据bucket中收集到的array中的元素，根据统计计数，在array中重新排列\n               for (int i = 0; i &lt; radix; i++) &#123;\n                    if (counter[i] != 0)\n                         for (int j = 0; j &lt; counter[i]; j++) &#123;\n                              array[index] = bucket[i][j];\n                              index++;\n                         &#125;\n                    counter[i] = 0;\n               &#125;\n               temp *= radix;\n               round++;\n          &#125;\n     &#125;\n     \n     private int getDistance(int[] array) &#123;\n          int max = computeMax(array);\n          int digits = 0;\n          int temp = max / radix;\n          while(temp != 0) &#123;\n               digits++;\n               temp = temp / radix;\n          &#125;\n          return digits + 1;\n     &#125;\n     \n     private int computeMax(int[] array) &#123;\n          int max = array[0];\n          for(int i=1; i&lt;array.length; i++) &#123;\n               if(array[i]&gt;max) &#123;\n                    max = array[i];\n               &#125;\n          &#125;\n          return max;\n     &#125;\n&#125;\n\n （十）各种内排序算法的比较\n\n","slug":"数据结构","date":"2022-04-08T14:10:10.000Z","categories_index":"基础","tags_index":"Review,数据结构","author_index":"ClaRn"},{"id":"c3b702e5ef74e2906ec0f752e1fc7991","title":"Android 字节码解析","content":" 将APK反编译到Smali\napktool d app.apk\n\n Dalvik字节码格式\nmove vA, vB\n\n","slug":"Android-字节码解析","date":"2022-04-07T16:39:09.000Z","categories_index":"开发","tags_index":"Android","author_index":"ClaRn"},{"id":"b9663f58f18133b35bfe243f3e916a80","title":"Hello World","content":"Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub.\n Quick Start\n Create a new post\n$ hexo new \"My New Post\"\n\nMore info: Writing\n Run server\n$ hexo server\n\nMore info: Server\n Generate static files\n$ hexo generate\n\nMore info: Generating\n Deploy to remote sites\n$ hexo deploy\n\nMore info: Deployment\n","slug":"hello-world","date":"2022-04-07T16:12:09.000Z","categories_index":"","tags_index":"","author_index":"ClaRn"}]