{"title":"AlphaGenome：多分辨率基因组模型","uid":"622fbcd79d3811e5898cc0046d22e71d","slug":"AlphaGenome：多分辨率基因组模型","date":"2025-11-13T07:02:30.000Z","updated":"2025-11-13T15:41:57.875Z","comments":true,"path":"api/articles/AlphaGenome：多分辨率基因组模型.json","keywords":"记录, 学习, ClaRnS","cover":"/gallery/ml.png","content":"<h1 id=\"Abstract\"><a href=\"#Abstract\" class=\"headerlink\" title=\"Abstract\"></a>Abstract</h1><p>AlphaGenome 模型将长 DNA 序列作为输入（多达 100 万个字母，也称为碱基对），并预测其调控活动的数千种分子特性。它还可以通过比较变异序列和未变异序列的预测结果，对基因变异或突变的影响进行评分。</p>\n<p>预测的属性包括基因在不同细胞类型和组织中的起始和终止位置、基因的拼接位置、产生的 RNA 数量，以及哪些 DNA 碱基可被访问、相互靠近或被某些蛋白质结合。训练数据来自大型公共联盟，包括 ENCODE、GTEx、4D Nucleome 和 FANTOM5，它们通过实验测量了这些属性，涵盖了数百种人类和小鼠细胞类型和组织的重要基因调控模式。</p>\n<p>AlphaGenome 架构使用卷积层初步检测基因组序列中的简短模式，使用变换器在序列的所有位置传递信息，最后使用一系列层将检测到的模式转化为不同模式的预测结果。在训练过程中，针对单个序列的计算分布在多个相互连接的张量处理单元（TPU）上。</p>\n<p>该模型建立在 Enformer 的基础上，是对 AlphaMissense 的补充，后者专门对蛋白质编码区域内的变异影响进行分类。这些区域占基因组的 2%。剩下的 98% 被称为非编码区，对于协调基因活动至关重要，其中包含许多与疾病相关的变异。AlphaGenome 为解读这些广阔的序列及其中的变异提供了一个新的视角。</p>\n<h1 id=\"Model\"><a href=\"#Model\" class=\"headerlink\" title=\"Model\"></a>Model</h1><p>AlphaGenome 模型使用编解码器结构，通过将碱基进行先升维再降维的方式进行特征提取。模型的主要组成部分为：</p>\n<ul>\n<li>DNA embedder</li>\n<li>Downres block</li>\n<li>Transformer tower</li>\n<li>Upres block</li>\n<li>Output embedder</li>\n</ul>\n<p><img src=\"/../gallery/ml/alphagenome.png\" alt=\"AlphaGenome\"></p>\n<p>升维(Downres)和降维(Upres)组件的基础单元均为1D卷积层。由于卷积网络对数据维度提升后会减少数据长度，因此被描述为分辨率降低(Downres)，反之为分辨率提升(Upres)。</p>\n<p><img src=\"/../gallery/ml/alphagenome_convblock.png\" alt=\"Conv Block\"></p>\n<p>升维和降维组件的之间存在残差连接，保证在提升分辨率的过程中不会由于池化操作丢失信息。每一个升维组件都与对应的降维组件进行连接。</p>\n<p><img src=\"/../gallery/ml/alphagenome_DownResUpRes.png\" alt=\"Down Res and Up Res Block\"></p>\n<p>Transformer tower是模型理解力的核心。 通过多个注意力机制组成的残差网络构建多个分辨率的输出。同时将原始的1D输入通过Pair update block提升至2D输出。</p>\n<p><img src=\"/../gallery/ml/alphagenome_TransformerTower.png\" alt=\"Transformer Tower\"></p>\n<p>DNA embedder是与Downres相似的卷积结构，在卷积核尺寸上存在差别。Output embedder将多个分辨率的输出混合增强后进行输出，由Dense网络组成。 </p>\n<p><img src=\"/../gallery/ml/alphagenome_output.png\" alt=\"Output Embedder\"></p>\n<p>此外，模型采用多头书簇合机制，每一个头由Dense网络组成，并添加了对上层输出的碱基互补链的处理。针对不同的下游任务，每一个输出头都有一个定制的损失函数进行训练。</p>\n<p><img src=\"/../gallery/ml/alphagenome_SpliceJunctionHead.png\" alt=\"Splice Junction Head\"></p>\n<h1 id=\"Evo2-AlphaGenome\"><a href=\"#Evo2-AlphaGenome\" class=\"headerlink\" title=\"Evo2 && AlphaGenome\"></a>Evo2 &amp;&amp; AlphaGenome</h1><table>\n<thead>\n<tr>\n<th align=\"center\"></th>\n<th align=\"center\"><strong>Evo 2</strong></th>\n<th align=\"center\"><strong>AlphaGenome</strong></th>\n</tr>\n</thead>\n<tbody><tr>\n<td align=\"center\"><strong>基础模型</strong></td>\n<td align=\"center\">StripeHyena2</td>\n<td align=\"center\">CNN+Transformer+CNN+多输出头</td>\n</tr>\n<tr>\n<td align=\"center\"><strong>训练数据</strong></td>\n<td align=\"center\">OpenGenome2, 包含真核生物和原核生物</td>\n<td align=\"center\">人类和老鼠的参考基因组以及注解</td>\n</tr>\n<tr>\n<td align=\"center\"><strong>训练方式</strong></td>\n<td align=\"center\">预训练+微调</td>\n<td align=\"center\">预训练+蒸馏</td>\n</tr>\n<tr>\n<td align=\"center\"><strong>训练框架</strong></td>\n<td align=\"center\">nvidia bionemo</td>\n<td align=\"center\">JAX+Haiku</td>\n</tr>\n<tr>\n<td align=\"center\"><strong>碱基分词方式</strong></td>\n<td align=\"center\">单碱基分词</td>\n<td align=\"center\">单碱基分词</td>\n</tr>\n<tr>\n<td align=\"center\"><strong>最大序列长度</strong></td>\n<td align=\"center\">1024， 8192</td>\n<td align=\"center\">1 Mbp</td>\n</tr>\n</tbody></table>\n","feature":true,"text":"AbstractAlphaGenome 模型将长 DNA 序列作为输入（多达 100 万个字母，也称为碱基对），并预测其调控活动的数千种分子特性。它还可以通过比...","permalink":"/post/AlphaGenome：多分辨率基因组模型","photos":[],"count_time":{"symbolsCount":"1.4k","symbolsTime":"1 mins."},"categories":[{"name":"机器学习","slug":"机器学习","count":4,"path":"api/categories/机器学习.json"},{"name":"LLM","slug":"机器学习/LLM","count":4,"path":"api/categories/机器学习/LLM.json"}],"tags":[{"name":"机器学习","slug":"机器学习","count":11,"path":"api/tags/机器学习.json"},{"name":"人工智能","slug":"人工智能","count":5,"path":"api/tags/人工智能.json"}],"toc":"<ol class=\"toc\"><li class=\"toc-item toc-level-1\"><a class=\"toc-link\" href=\"#Abstract\"><span class=\"toc-text\">Abstract</span></a></li><li class=\"toc-item toc-level-1\"><a class=\"toc-link\" href=\"#Model\"><span class=\"toc-text\">Model</span></a></li><li class=\"toc-item toc-level-1\"><a class=\"toc-link\" href=\"#Evo2-AlphaGenome\"><span class=\"toc-text\">Evo2 &amp;&amp; AlphaGenome</span></a></li></ol>","author":{"name":"ClaRn","slug":"blog-author","avatar":"/gallery/avatar.jpg","link":"/","description":"当你在浪费时间的事情里获得了快乐，那就不是在浪费时间。 ——罗素","socials":{"github":"https://github.com/iYIYiYIYi","twitter":"","stackoverflow":"","wechat":"","qq":"","weibo":"","zhihu":"","csdn":"","juejin":"","customs":{}}},"mapped":true,"hidden":false,"prev_post":{},"next_post":{"title":"DeepSeek-OCR：基于光学的文本数据压缩","uid":"a8520b94cebc535073bd27494d823aad","slug":"DeepSeek-OCR：基于光学的文本数据压缩","date":"2025-11-12T06:04:56.000Z","updated":"2025-11-12T15:05:01.698Z","comments":true,"path":"api/articles/DeepSeek-OCR：基于光学的文本数据压缩.json","keywords":"记录, 学习, ClaRnS","cover":"/gallery/ml.png","text":"Abstract在DeepSeek3B-MoE-A570M作为解码器的基础上，设计了一个名为DeepEncoder的OCR编码器模型，通过2D光学映射的方式进行...","permalink":"/post/DeepSeek-OCR：基于光学的文本数据压缩","photos":[],"count_time":{"symbolsCount":"1.8k","symbolsTime":"2 mins."},"categories":[{"name":"机器学习","slug":"机器学习","count":4,"path":"api/categories/机器学习.json"},{"name":"LLM","slug":"机器学习/LLM","count":4,"path":"api/categories/机器学习/LLM.json"}],"tags":[{"name":"机器学习","slug":"机器学习","count":11,"path":"api/tags/机器学习.json"},{"name":"人工智能","slug":"人工智能","count":5,"path":"api/tags/人工智能.json"},{"name":"大语言模型","slug":"大语言模型","count":3,"path":"api/tags/大语言模型.json"}],"author":{"name":"ClaRn","slug":"blog-author","avatar":"/gallery/avatar.jpg","link":"/","description":"当你在浪费时间的事情里获得了快乐，那就不是在浪费时间。 ——罗素","socials":{"github":"https://github.com/iYIYiYIYi","twitter":"","stackoverflow":"","wechat":"","qq":"","weibo":"","zhihu":"","csdn":"","juejin":"","customs":{}}},"feature":true}}