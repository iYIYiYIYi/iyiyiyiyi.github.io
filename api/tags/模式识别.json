{"name":"模式识别","slug":"模式识别","count":5,"postlist":[{"title":"对数几率回归(Logistic Regression)","uid":"ae6525a3e493be521850258ed1ec57e9","slug":"对数几率回归","date":"2023-11-23T05:17:24.000Z","updated":"2023-11-23T15:35:51.379Z","comments":true,"path":"api/articles/对数几率回归.json","keywords":"记录, 学习, ClaRnS","cover":"/gallery/ml.png","text":"对数几率回归模型分类任务中，在给定输入的情况下，概率密度函数为： 线性模型中，期望表示给定的情况下，的概率，取值为区间 使用sigmoid函数将的范围转换到，s...","permalink":"/post/对数几率回归","photos":[],"count_time":{"symbolsCount":109,"symbolsTime":"1 mins."},"categories":[{"name":"基础","slug":"基础","count":26,"path":"api/categories/基础.json"},{"name":"机器学习","slug":"基础/机器学习","count":5,"path":"api/categories/基础/机器学习.json"}],"tags":[{"name":"模式识别","slug":"模式识别","count":5,"path":"api/tags/模式识别.json"},{"name":"机器学习","slug":"机器学习","count":5,"path":"api/tags/机器学习.json"}],"author":{"name":"ClaRn","slug":"blog-author","avatar":"/gallery/avatar.jpg","link":"/","description":"当你在浪费时间的事情里获得了快乐，那就不是在浪费时间。 ——罗素","socials":{"github":"https://github.com/iYIYiYIYi","twitter":"","stackoverflow":"","wechat":"","qq":"","weibo":"","zhihu":"","csdn":"","juejin":"","customs":{}}},"feature":true},{"title":"回归任务","uid":"5a4ab85065f9d4565d494efb3b62b3fd","slug":"回归任务","date":"2023-11-21T23:50:02.000Z","updated":"2023-11-26T09:19:10.706Z","comments":true,"path":"api/articles/回归任务.json","keywords":"记录, 学习, ClaRnS","cover":"/gallery/ml.png","text":"回归任务在监督学习中，给定数据，其中为训练样本数目，为样本索引，为第个样本的输入特征，为对应的输出/响应。 当时，该监督学习任务为一个回归任务。根据训练样本，学...","permalink":"/post/回归任务","photos":[],"count_time":{"symbolsCount":810,"symbolsTime":"1 mins."},"categories":[{"name":"基础","slug":"基础","count":26,"path":"api/categories/基础.json"},{"name":"机器学习","slug":"基础/机器学习","count":5,"path":"api/categories/基础/机器学习.json"}],"tags":[{"name":"模式识别","slug":"模式识别","count":5,"path":"api/tags/模式识别.json"},{"name":"机器学习","slug":"机器学习","count":5,"path":"api/tags/机器学习.json"}],"author":{"name":"ClaRn","slug":"blog-author","avatar":"/gallery/avatar.jpg","link":"/","description":"当你在浪费时间的事情里获得了快乐，那就不是在浪费时间。 ——罗素","socials":{"github":"https://github.com/iYIYiYIYi","twitter":"","stackoverflow":"","wechat":"","qq":"","weibo":"","zhihu":"","csdn":"","juejin":"","customs":{}}}},{"title":"Logistic回归&SVM作业","uid":"12c939ce01f114334baac440d0498eaf","slug":"Logistic回归&SVM作业","date":"2023-11-21T07:09:37.000Z","updated":"2023-11-22T03:57:03.060Z","comments":true,"path":"api/articles/Logistic回归&SVM作业.json","keywords":"记录, 学习, ClaRnS","cover":"/gallery/ml.png","text":" TIP 给定如下4个输入特征的4个样本，采用Logistic回归， 初始化权重，，采用梯度下降，计算每个样本上的梯度； 轮梯度下降后，得到参数估计为，。给定测...","permalink":"/post/Logistic回归&SVM作业","photos":[],"count_time":{"symbolsCount":738,"symbolsTime":"1 mins."},"categories":[{"name":"基础","slug":"基础","count":26,"path":"api/categories/基础.json"},{"name":"机器学习","slug":"基础/机器学习","count":5,"path":"api/categories/基础/机器学习.json"},{"name":"作业","slug":"基础/机器学习/作业","count":2,"path":"api/categories/基础/机器学习/作业.json"}],"tags":[{"name":"作业","slug":"作业","count":18,"path":"api/tags/作业.json"},{"name":"模式识别","slug":"模式识别","count":5,"path":"api/tags/模式识别.json"},{"name":"机器学习","slug":"机器学习","count":5,"path":"api/tags/机器学习.json"}],"author":{"name":"ClaRn","slug":"blog-author","avatar":"/gallery/avatar.jpg","link":"/","description":"当你在浪费时间的事情里获得了快乐，那就不是在浪费时间。 ——罗素","socials":{"github":"https://github.com/iYIYiYIYi","twitter":"","stackoverflow":"","wechat":"","qq":"","weibo":"","zhihu":"","csdn":"","juejin":"","customs":{}}}},{"title":"PCA&LR作业","uid":"a1b53e1281173f553545a82d3e9f99c2","slug":"PCA&LR作业","date":"2023-11-18T19:45:25.000Z","updated":"2023-11-22T03:47:21.623Z","comments":true,"path":"api/articles/PCA&LR作业.json","keywords":"记录, 学习, ClaRnS","cover":"/gallery/ml.png","text":" TIP 给定两类样本的特征，其中类别：类别： 用PCA降维，分别将特征降至1维和2维，并给出降维后每个样本的位置。 计算两类样本均值： 将每个样本的特征减去样...","permalink":"/post/PCA&LR作业","photos":[],"count_time":{"symbolsCount":"1.7k","symbolsTime":"2 mins."},"categories":[{"name":"基础","slug":"基础","count":26,"path":"api/categories/基础.json"},{"name":"机器学习","slug":"基础/机器学习","count":5,"path":"api/categories/基础/机器学习.json"},{"name":"作业","slug":"基础/机器学习/作业","count":2,"path":"api/categories/基础/机器学习/作业.json"}],"tags":[{"name":"作业","slug":"作业","count":18,"path":"api/tags/作业.json"},{"name":"模式识别","slug":"模式识别","count":5,"path":"api/tags/模式识别.json"},{"name":"机器学习","slug":"机器学习","count":5,"path":"api/tags/机器学习.json"}],"author":{"name":"ClaRn","slug":"blog-author","avatar":"/gallery/avatar.jpg","link":"/","description":"当你在浪费时间的事情里获得了快乐，那就不是在浪费时间。 ——罗素","socials":{"github":"https://github.com/iYIYiYIYi","twitter":"","stackoverflow":"","wechat":"","qq":"","weibo":"","zhihu":"","csdn":"","juejin":"","customs":{}}}},{"title":"特征工程","uid":"31d8cdd5baa8bcd02cb907b9fac066d4","slug":"特征工程","date":"2023-11-18T01:17:02.000Z","updated":"2023-11-21T07:48:30.590Z","comments":true,"path":"api/articles/特征工程.json","keywords":"记录, 学习, ClaRnS","cover":"/gallery/ml.png","text":"数据预处理数据预处理包括噪声的清晰和数据变换。 特征类型包括： 连续数值型特征 多项式扩展 log变换（） 区间量化 二值化 缩放 规范化 离散特征/类别型特征...","permalink":"/post/特征工程","photos":[],"count_time":{"symbolsCount":"1.3k","symbolsTime":"1 mins."},"categories":[{"name":"基础","slug":"基础","count":26,"path":"api/categories/基础.json"},{"name":"机器学习","slug":"基础/机器学习","count":5,"path":"api/categories/基础/机器学习.json"}],"tags":[{"name":"模式识别","slug":"模式识别","count":5,"path":"api/tags/模式识别.json"},{"name":"机器学习","slug":"机器学习","count":5,"path":"api/tags/机器学习.json"}],"author":{"name":"ClaRn","slug":"blog-author","avatar":"/gallery/avatar.jpg","link":"/","description":"当你在浪费时间的事情里获得了快乐，那就不是在浪费时间。 ——罗素","socials":{"github":"https://github.com/iYIYiYIYi","twitter":"","stackoverflow":"","wechat":"","qq":"","weibo":"","zhihu":"","csdn":"","juejin":"","customs":{}}}}]}